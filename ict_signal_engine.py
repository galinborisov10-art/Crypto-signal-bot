"""
üéØ ICT SIGNAL ENGINE
Central ICT Signal Generator - Combines ALL ICT concepts into unified signal generation

Features:
- Integrates Whale Order Blocks detection
- Integrates Liquidity Pools mapping
- Integrates Market Structure analysis
- Integrates Internal Liquidity detection
- Fair Value Gaps detection
- Multi-Timeframe Confluence analysis
- Complete signal generation with entry/SL/TP
- Confidence scoring (0-100%)
- Signal strength levels (WEAK to EXTREME)

Author: galinborisov10-art
Date: 2025-12-12
"""

import pandas as pd
import numpy as np
from typing import List, Dict, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import logging
import json

# Import Entry Gating and Confidence Threshold evaluators (ESB v1.0 ¬ß2.1-2.2)
try:
    from entry_gating_evaluator import evaluate_entry_gating
    ENTRY_GATING_AVAILABLE = True
except ImportError:
    ENTRY_GATING_AVAILABLE = False
    logging.warning("Entry Gating Evaluator not available")

try:
    from confidence_threshold_evaluator import evaluate_confidence_threshold
    CONFIDENCE_THRESHOLD_AVAILABLE = True
except ImportError:
    CONFIDENCE_THRESHOLD_AVAILABLE = False
    logging.warning("Confidence Threshold Evaluator not available")

try:
    from execution_eligibility_evaluator import evaluate_execution_eligibility
    EXECUTION_ELIGIBILITY_AVAILABLE = True
except ImportError:
    EXECUTION_ELIGIBILITY_AVAILABLE = False
    logging.warning("Execution Eligibility Evaluator not available")

try:
    from risk_admission_evaluator import evaluate_risk_admission
    RISK_ADMISSION_AVAILABLE = True
except ImportError:
    RISK_ADMISSION_AVAILABLE = False
    logging.warning("Risk Admission Evaluator not available")

# Import ICT modules
try:
    from order_block_detector import OrderBlockDetector, OrderBlock, OrderBlockType, MitigationBlock
    ORDER_BLOCK_AVAILABLE = True
except ImportError:
    ORDER_BLOCK_AVAILABLE = False
    logging.warning("OrderBlockDetector not available")

try:
    from fvg_detector import FVGDetector, FairValueGap, FVGType
    FVG_AVAILABLE = True
except ImportError:
    FVG_AVAILABLE = False
    logging.warning("FVGDetector not available")

try:
    from ict_whale_detector import WhaleDetector, WhaleOrderBlock
    WHALE_AVAILABLE = True
except ImportError:
    WHALE_AVAILABLE = False
    logging.warning("WhaleDetector not available")

try:
    from liquidity_map import LiquidityMapper, LiquidityZone, LiquiditySweep
    LIQUIDITY_AVAILABLE = True
except ImportError:
    LIQUIDITY_AVAILABLE = False
    logging.warning("LiquidityMapper not available")

try:
    from ilp_detector import InternalLiquidityPoolDetector
    ILP_AVAILABLE = True
except ImportError:
    ILP_AVAILABLE = False
    logging.warning("ILP Detector not available")

try:
    from mtf_analyzer import MultiTimeframeAnalyzer, MTFSignal, Bias
    MTF_AVAILABLE = True
except ImportError:
    MTF_AVAILABLE = False
    logging.warning("MTF Analyzer not available")

try:
    from breaker_block_detector import BreakerBlockDetector, BreakerBlock
    BREAKER_AVAILABLE = True
except ImportError:
    BREAKER_AVAILABLE = False
    logging.warning("BreakerBlockDetector not available")

try:
    from sibi_ssib_detector import SIBISSIBDetector, SIBISSIBZone
    SIBI_SSIB_AVAILABLE = True
except ImportError:
    SIBI_SSIB_AVAILABLE = False
    logging.warning("SIBISSIBDetector not available")

try:
    from zone_explainer import ZoneExplainer
    ZONE_EXPLAINER_AVAILABLE = True
except ImportError:
    ZONE_EXPLAINER_AVAILABLE = False
    logging.warning("ZoneExplainer not available")

try:
    from cache_manager import get_cache_manager
    CACHE_MANAGER_AVAILABLE = True
except ImportError:
    CACHE_MANAGER_AVAILABLE = False
    logging.warning("CacheManager not available")

try:
    from config.config_loader import load_feature_flags, get_flag
    FEATURE_FLAGS_AVAILABLE = True
except ImportError:
    FEATURE_FLAGS_AVAILABLE = False
    logging.warning("Feature flags not available")

# ML Integration
try:
    from ml_engine import MLTradingEngine
    ML_ENGINE_AVAILABLE = True
except ImportError:
    ML_ENGINE_AVAILABLE = False
    logging.warning("MLTradingEngine not available")

try:
    from ml_predictor import MLPredictor, get_ml_predictor
    ML_PREDICTOR_AVAILABLE = True
except ImportError:
    ML_PREDICTOR_AVAILABLE = False
    logging.warning("MLPredictor not available")

# Fibonacci Analyzer
try:
    from fibonacci_analyzer import FibonacciAnalyzer, FibonacciLevel
    FIBONACCI_AVAILABLE = True
except ImportError:
    FIBONACCI_AVAILABLE = False
    logging.warning("FibonacciAnalyzer not available")

# LuxAlgo Combined Analysis
try:
    from luxalgo_ict_analysis import CombinedLuxAlgoAnalysis
    LUXALGO_COMBINED_AVAILABLE = True
except ImportError:
    LUXALGO_COMBINED_AVAILABLE = False
    logging.warning("CombinedLuxAlgoAnalysis not available")

# Chart Generator
try:
    from chart_generator import ChartGenerator
    CHART_GENERATOR_AVAILABLE = True
except ImportError:
    CHART_GENERATOR_AVAILABLE = False
    logging.warning("ChartGenerator not available")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class SignalType(Enum):
    """Signal types"""
    BUY = "BUY"
    SELL = "SELL"
    HOLD = "HOLD"
    STRONG_BUY = "STRONG_BUY"
    STRONG_SELL = "STRONG_SELL"


class SignalStrength(Enum):
    """Signal strength levels"""
    WEAK = 1
    MODERATE = 2
    STRONG = 3
    VERY_STRONG = 4
    EXTREME = 5


class MarketBias(Enum):
    """Market bias"""
    BULLISH = "BULLISH"
    BEARISH = "BEARISH"
    NEUTRAL = "NEUTRAL"
    RANGING = "RANGING"


def get_tp_multipliers_by_timeframe(timeframe: str) -> tuple:
    """
    Get optimized TP multipliers based on timeframe volatility
    
    Strategy:
    - Lower TFs (1h, 2h): (1, 3, 5) - Quick validation, conservative targets
    - Higher TFs (4h, 1d): (2, 4, 6) - Capture trends, aggressive targets
    
    Reasoning:
    - 1h/2h: Faster moves, quicker reversals ‚Üí Need fast TP hits
    - 4h/1d: Stronger trends, more follow-through ‚Üí Can hold for bigger TPs
    
    Args:
        timeframe: Candle timeframe (e.g., '1h', '4h', '1d')
        
    Returns:
        tuple: (tp1_mult, tp2_mult, tp3_mult)
        
    Examples:
        >>> get_tp_multipliers_by_timeframe('1h')
        (1.0, 3.0, 5.0)
        >>> get_tp_multipliers_by_timeframe('4h')
        (2.0, 4.0, 6.0)
    """
    tf = timeframe.lower().strip()
    
    # Short-term: Conservative targets (1, 3, 5)
    if tf in ['15m', '30m', '1h', '2h']:
        logger.info(f"üìä Using conservative TPs (1,3,5) for {timeframe}")
        return (1.0, 3.0, 5.0)
    
    # Medium/Long-term: Aggressive targets (2, 4, 6)
    elif tf in ['4h', '6h', '8h', '12h', '1d', '3d', '1w']:
        logger.info(f"üìä Using aggressive TPs (2,4,6) for {timeframe}")
        return (2.0, 4.0, 6.0)
    
    # Default: Conservative (safer)
    else:
        logger.warning(f"‚ö†Ô∏è Unknown timeframe {timeframe}, defaulting to conservative TPs (1,3,5)")
        return (1.0, 3.0, 5.0)


@dataclass
class ICTSignal:
    """
    Complete ICT Trading Signal
    
    Attributes:
        timestamp: Signal generation time
        symbol: Trading pair (e.g., "BTC/USDT")
        timeframe: Primary timeframe
        signal_type: BUY/SELL/HOLD/STRONG_BUY/STRONG_SELL
        signal_strength: 1-5 (WEAK to EXTREME)
        entry_price: Recommended entry price
        sl_price: Stop loss price
        tp_prices: List of take profit targets [TP1, TP2, TP3]
        confidence: Confidence score (0-100)
        risk_reward_ratio: Risk/reward ratio
        whale_blocks: List of whale order blocks
        liquidity_zones: List of liquidity zones
        order_blocks: List of standard order blocks
        fair_value_gaps: List of FVGs
        internal_liquidity: Internal liquidity pools
        bias: Market bias (BULLISH/BEARISH/NEUTRAL)
        structure_broken: Whether structure was broken
        displacement_detected: Whether displacement was detected
        mtf_confluence: Multi-timeframe confluence score
        reasoning: Human-readable explanation
        warnings: List of warnings/caveats
    """
    timestamp: datetime
    symbol: str
    timeframe: str
    signal_type: SignalType
    signal_strength: SignalStrength
    entry_price: float
    sl_price: float
    tp_prices: List[float]
    confidence: float
    risk_reward_ratio: float
    
    # ICT Components
    whale_blocks: List[Dict] = field(default_factory=list)
    liquidity_zones: List[Dict] = field(default_factory=list)
    liquidity_sweeps: List[Dict] = field(default_factory=list)
    order_blocks: List[Dict] = field(default_factory=list)
    fair_value_gaps: List[Dict] = field(default_factory=list)
    internal_liquidity: List[Dict] = field(default_factory=list)
    breaker_blocks: List[Dict] = field(default_factory=list)
    mitigation_blocks: List[Dict] = field(default_factory=list)
    sibi_ssib_zones: List[Dict] = field(default_factory=list)
    
    # New Components
    fibonacci_data: Dict = field(default_factory=dict)
    luxalgo_sr: Dict = field(default_factory=dict)
    luxalgo_ict: Dict = field(default_factory=dict)
    luxalgo_combined: Dict = field(default_factory=dict)
    
    # Market Analysis
    bias: MarketBias = MarketBias.NEUTRAL
    structure_broken: bool = False
    displacement_detected: bool = False
    mtf_confluence: int = 0
    htf_bias: str = "NEUTRAL"
    mtf_structure: str = "NEUTRAL"
    mtf_consensus_data: Dict = field(default_factory=dict)  # NEW: MTF consensus breakdown
    
    # Entry Zone (NEW - ICT-Compliant)
    entry_zone: Dict = field(default_factory=dict)  # NEW: Entry zone details
    entry_status: str = "UNKNOWN"  # NEW: Entry zone status (VALID_WAIT/VALID_NEAR/etc)
    
    # Distance Penalty (Soft Constraint)
    distance_penalty: bool = False  # NEW: Whether confidence was reduced due to distance out of range
    
    # ‚úÖ PR #4: Timeframe Hierarchy
    timeframe_hierarchy: Dict = field(default_factory=dict)  # NEW: TF hierarchy info (Structure/Confirmation/Entry)
    
    # Explanation
    reasoning: str = ""
    warnings: List[str] = field(default_factory=list)
    zone_explanations: Dict[str, List[str]] = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        """Convert to dictionary"""
        return {
            'timestamp': self.timestamp.isoformat() if isinstance(self.timestamp, datetime) else str(self.timestamp),
            'symbol': self.symbol,
            'timeframe': self.timeframe,
            'signal_type': self.signal_type.value,
            'signal_strength': self.signal_strength.value,
            'entry_price': self.entry_price,
            'sl_price': self.sl_price,
            'tp_prices': self.tp_prices,
            'confidence': self.confidence,
            'risk_reward_ratio': self.risk_reward_ratio,
            'whale_blocks_count': len(self.whale_blocks),
            'liquidity_zones_count': len(self.liquidity_zones),
            'order_blocks_count': len(self.order_blocks),
            'fvgs_count': len(self.fair_value_gaps),
            'bias': self.bias.value,
            'structure_broken': self.structure_broken,
            'displacement_detected': self.displacement_detected,
            'mtf_confluence': self.mtf_confluence,
            'htf_bias': self.htf_bias,
            'mtf_structure': self.mtf_structure,
            'mtf_consensus_data': self.mtf_consensus_data,
            'reasoning': self.reasoning,
            'warnings': self.warnings
        }


class ICTSignalEngine:
    """
    Central ICT Signal Generation Engine
    
    Combines all ICT concepts into a unified signal generation system:
    - Whale Order Blocks
    - Liquidity Mapping
    - Standard Order Blocks
    - Fair Value Gaps
    - Internal Liquidity Pools
    - Multi-Timeframe Analysis
    """
    
    # Altcoins that use independent analysis mode (bypass BTC HTF bias early exit)
    ALT_INDEPENDENT_SYMBOLS = ["ETHUSDT", "SOLUSDT", "BNBUSDT", "ADAUSDT", "XRPUSDT"]
    
    def __init__(self, config: Optional[Dict] = None):
        """
        Initialize ICT Signal Engine
        
        Args:
            config: Configuration parameters
        """
        self.config = config or self._get_default_config()
        
        # Load feature flags
        if FEATURE_FLAGS_AVAILABLE:
            try:
                feature_flags = load_feature_flags()
                # Merge feature flags into config
                self.config.update({
                    'use_breaker_blocks': feature_flags.get('use_breaker_blocks', True),
                    'use_mitigation_blocks': feature_flags.get('use_mitigation_blocks', True),
                    'use_sibi_ssib': feature_flags.get('use_sibi_ssib', True),
                    'use_zone_explanations': feature_flags.get('use_zone_explanations', True),
                    'use_cache': feature_flags.get('use_cache', True),
                    'cache_ttl_seconds': feature_flags.get('cache_ttl_seconds', 3600),
                    'cache_max_size': feature_flags.get('cache_max_size', 100)
                })
            except Exception as e:
                logger.warning(f"Could not load feature flags: {e}")
        
        # Initialize sub-detectors
        self.ob_detector = OrderBlockDetector() if ORDER_BLOCK_AVAILABLE else None
        self.fvg_detector = FVGDetector() if FVG_AVAILABLE else None
        self.whale_detector = WhaleDetector() if WHALE_AVAILABLE else None
        self.liquidity_mapper = LiquidityMapper() if LIQUIDITY_AVAILABLE else None
        self.ilp_detector = InternalLiquidityPoolDetector() if ILP_AVAILABLE else None
        self.mtf_analyzer = MultiTimeframeAnalyzer() if MTF_AVAILABLE else None
        
        # Initialize new detectors
        use_breaker_blocks = self.config.get('use_breaker_blocks', True)
        self.breaker_detector = BreakerBlockDetector() if BREAKER_AVAILABLE and use_breaker_blocks else None
        
        use_sibi_ssib = self.config.get('use_sibi_ssib', True)
        self.sibi_ssib_detector = SIBISSIBDetector() if SIBI_SSIB_AVAILABLE and use_sibi_ssib else None
        
        # Initialize zone explainer
        use_zone_explanations = self.config.get('use_zone_explanations', True)
        self.zone_explainer = ZoneExplainer() if ZONE_EXPLAINER_AVAILABLE and use_zone_explanations else None
        
        # Initialize Fibonacci Analyzer
        self.fibonacci_analyzer = FibonacciAnalyzer(
            retracement_levels=[0.236, 0.382, 0.5, 0.618, 0.786],
            extension_levels=[1.272, 1.414, 1.618, 2.0, 2.618],
            ote_range=(0.62, 0.79)
        ) if FIBONACCI_AVAILABLE else None
        
        # Initialize LuxAlgo Combined Analysis
        self.luxalgo_combined = CombinedLuxAlgoAnalysis(
            sr_detection_length=15,
            sr_margin=2.0,
            ict_swing_length=10,
            enable_sr=True,
            enable_ict=True
        ) if LUXALGO_COMBINED_AVAILABLE else None
        
        # Initialize Chart Generator
        self.chart_generator = ChartGenerator() if CHART_GENERATOR_AVAILABLE else None
        
        # Initialize cache manager
        use_cache = self.config.get('use_cache', True)
        if CACHE_MANAGER_AVAILABLE and use_cache:
            try:
                cache_max_size = self.config.get('cache_max_size', 100)
                cache_ttl = self.config.get('cache_ttl_seconds', 3600)
                self.cache_manager = get_cache_manager(cache_max_size, cache_ttl)
            except Exception as e:
                logger.warning(f"Could not initialize cache manager: {e}")
                self.cache_manager = None
        else:
            self.cache_manager = None
        
        # Initialize ML engines (if available)
        self.ml_engine = None
        self.ml_predictor = None
        self.use_ml = self.config.get('use_ml', True)

        if self.use_ml:
            if ML_ENGINE_AVAILABLE:
                try:
                    self.ml_engine = MLTradingEngine()
                    logger.info("‚úÖ ML Trading Engine initialized")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è ML Engine initialization failed: {e}")
            
            if ML_PREDICTOR_AVAILABLE:
                try:
                    self.ml_predictor = get_ml_predictor()
                    logger.info("‚úÖ ML Predictor initialized")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è ML Predictor initialization failed: {e}")
        
        # ‚úÖ PR #4: Load timeframe hierarchy configuration
        self.tf_hierarchy = self._load_tf_hierarchy()
        logger.info(f"‚úÖ TF Hierarchy loaded: {len(self.tf_hierarchy.get('hierarchies', {}))} timeframes configured")
        
        logger.info("ICT Signal Engine initialized")
        logger.info(f"Order Blocks: {ORDER_BLOCK_AVAILABLE}")
        logger.info(f"FVG: {FVG_AVAILABLE}")
        logger.info(f"Whale: {WHALE_AVAILABLE}")
        logger.info(f"Liquidity: {LIQUIDITY_AVAILABLE}")
        logger.info(f"ILP: {ILP_AVAILABLE}")
        logger.info(f"MTF: {MTF_AVAILABLE}")
        logger.info(f"Breaker Blocks: {BREAKER_AVAILABLE}")
        logger.info(f"SIBI/SSIB: {SIBI_SSIB_AVAILABLE}")
        logger.info(f"Zone Explainer: {ZONE_EXPLAINER_AVAILABLE}")
        logger.info(f"Cache Manager: {self.cache_manager is not None}")
        logger.info(f"Fibonacci Analyzer: {FIBONACCI_AVAILABLE}")
        logger.info(f"LuxAlgo Combined: {LUXALGO_COMBINED_AVAILABLE}")
        logger.info(f"Chart Generator: {CHART_GENERATOR_AVAILABLE}")
    
    def _get_default_config(self) -> Dict:
        """Get default configuration"""
        return {
            'min_confidence': 60,          # Min 60% confidence (STRICT ICT)
            'min_risk_reward': 3.0,        # Min 1:3 R:R (STRICT ICT)
            'max_sl_distance_pct': 3.0,    # Max 3% SL distance
            'tp_multipliers': [3, 5, 8],   # TP at 3R, 5R, 8R (STRICT ICT)
            'require_mtf_confluence': True, # Require MTF alignment (STRICT ICT)
            'min_mtf_confluence': 0.5,     # Min 50% MTF consensus (STRICT ICT)
            'use_whale_blocks': True,      # Use whale detection
            'use_liquidity': True,         # Use liquidity mapping
            'use_order_blocks': True,      # Use order blocks
            'use_fvgs': True,              # Use FVGs
            'displacement_required': True, # Require displacement
            'min_displacement_pct': 0.5,   # Min 0.5% displacement
            'structure_break_weight': 0.2, # Weight for structure break
            'whale_block_weight': 0.25,    # Weight for whale blocks
            'liquidity_weight': 0.2,       # Weight for liquidity
            'ob_weight': 0.15,             # Weight for order blocks
            'fvg_weight': 0.1,             # Weight for FVGs
            'mtf_weight': 0.1,             # Weight for MTF confluence
            'breaker_block_weight': 0.08,  # Weight for breaker blocks (ESB v1.0 ¬ß4)
            'structure_break_threshold': 1.0,  # 1% threshold for structure break
            'entry_adjustment_pct': 0.5,   # 0.5% entry price adjustment
            
            # ML Configuration
            'use_ml': True,                    # Enable ML optimization
            'ml_min_confidence_boost': -20,    # Min confidence adjustment
            'ml_max_confidence_boost': 20,     # Max confidence adjustment
            'ml_entry_adjustment_max': 0.005,  # Max entry adjustment (0.5%)
            'ml_sl_tighten_max': 0.95,         # Max SL tighten multiplier
            'ml_sl_widen_max': 1.10,           # Max SL widen multiplier
            'ml_tp_extension_max': 1.15,       # Max TP extension (15%)
            'ml_override_threshold': 15,       # Min confidence diff for ML override
        }
    
    def _load_tf_hierarchy(self) -> Dict:
        """
        ‚úÖ PR #4: Load timeframe hierarchy configuration
        
        Returns:
            Dict with TF hierarchy rules for each entry timeframe
        """
        try:
            # Try to load from config file
            from pathlib import Path
            config_path = Path(__file__).parent / 'config' / 'timeframe_hierarchy.json'
            
            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    hierarchy = json.load(f)
                logger.info(f"üìä Loaded TF hierarchy from {config_path}")
                return hierarchy
            else:
                logger.warning("‚ö†Ô∏è TF hierarchy config not found, using defaults")
                return self._get_default_tf_hierarchy()
                
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå JSON decode error in TF hierarchy: {e}")
            return self._get_default_tf_hierarchy()
        except Exception as e:
            logger.error(f"‚ùå Error loading TF hierarchy: {e}")
            return self._get_default_tf_hierarchy()
    
    def _get_default_tf_hierarchy(self) -> Dict:
        """
        Fallback TF hierarchy if config file not available
        
        Returns:
            Default hierarchy configuration
        """
        return {
            "hierarchies": {
                "1h": {
                    "entry_tf": "1h",
                    "confirmation_tf": "2h",
                    "structure_tf": "4h",
                    "htf_bias_tf": "1d"
                },
                "2h": {
                    "entry_tf": "2h",
                    "confirmation_tf": "4h",
                    "structure_tf": "1d",
                    "htf_bias_tf": "1d"
                },
                "4h": {
                    "entry_tf": "4h",
                    "confirmation_tf": "4h",
                    "structure_tf": "1d",
                    "htf_bias_tf": "1w"
                },
                "1d": {
                    "entry_tf": "1d",
                    "confirmation_tf": "1d",
                    "structure_tf": "1w",
                    "htf_bias_tf": "1w"
                }
            },
            "validation_rules": {
                "structure_penalty_if_missing": 0.25,
                "confirmation_penalty_if_missing": 0.15,
                "allow_fallback_tfs": True
            }
        }
    
    def _validate_mtf_hierarchy(
        self,
        entry_tf: str,
        mtf_analysis: Dict,
        confidence: float
    ) -> Tuple[float, List[str], Dict]:
        """
        ‚úÖ PR #4: Validate MTF analysis follows ICT timeframe hierarchy
        
        Validates that the expected Structure TF and Confirmation TF are present.
        Applies penalties (not rejections) if TFs are missing.
        
        Args:
            entry_tf: Entry timeframe (e.g., '1h', '2h', '4h', '1d')
            mtf_analysis: Dictionary of MTF analysis results keyed by timeframe
            confidence: Current confidence score
            
        Returns:
            Tuple of (adjusted_confidence, warnings, hierarchy_info)
        """
        warnings = []
        adjusted_confidence = confidence
        hierarchy_info = {}
        
        try:
            # Get expected hierarchy for this entry TF
            hierarchies = self.tf_hierarchy.get('hierarchies', {})
            hierarchy = hierarchies.get(entry_tf)
            
            if not hierarchy:
                logger.warning(f"‚ö†Ô∏è No TF hierarchy defined for {entry_tf}, skipping validation")
                return adjusted_confidence, warnings, hierarchy_info
            
            # Extract expected TFs
            expected_confirmation_tf = hierarchy.get('confirmation_tf')
            expected_structure_tf = hierarchy.get('structure_tf')
            expected_htf_bias_tf = hierarchy.get('htf_bias_tf')
            
            # Store hierarchy info for signal message
            hierarchy_info = {
                'entry_tf': entry_tf,
                'confirmation_tf': expected_confirmation_tf,
                'structure_tf': expected_structure_tf,
                'htf_bias_tf': expected_htf_bias_tf,
                'description': hierarchy.get('description', '')
            }
            
            # Get validation rules
            rules = self.tf_hierarchy.get('validation_rules', {})
            confirmation_penalty = rules.get('confirmation_penalty_if_missing', 0.15)
            structure_penalty = rules.get('structure_penalty_if_missing', 0.25)
            
            # Get available TFs from MTF analysis
            available_tfs = list(mtf_analysis.keys()) if mtf_analysis else []
            
            logger.info(f"üìä TF Hierarchy Validation for {entry_tf}:")
            logger.info(f"   Expected - Structure: {expected_structure_tf}, Confirmation: {expected_confirmation_tf}")
            logger.info(f"   Available: {available_tfs}")
            
            # VALIDATION 1: Check Confirmation TF
            if expected_confirmation_tf:
                if expected_confirmation_tf in available_tfs:
                    logger.info(f"   ‚úÖ Confirmation TF ({expected_confirmation_tf}) present")
                    hierarchy_info['confirmation_tf_present'] = True
                else:
                    warning_msg = (
                        f"‚ö†Ô∏è Missing Confirmation TF ({expected_confirmation_tf}) "
                        f"- intermediate pattern validation limited"
                    )
                    warnings.append(warning_msg)
                    adjusted_confidence -= confirmation_penalty
                    hierarchy_info['confirmation_tf_present'] = False
                    logger.warning(f"   {warning_msg} (-{confirmation_penalty*100:.0f}%)")
            
            # VALIDATION 2: Check Structure TF
            if expected_structure_tf:
                if expected_structure_tf in available_tfs:
                    logger.info(f"   ‚úÖ Structure TF ({expected_structure_tf}) present")
                    hierarchy_info['structure_tf_present'] = True
                    
                    # Additional check: Structure bias alignment (if data available)
                    structure_data = mtf_analysis.get(expected_structure_tf, {})
                    structure_bias = structure_data.get('bias')
                    
                    if structure_bias:
                        hierarchy_info['structure_bias'] = structure_bias
                        logger.info(f"   üìä Structure bias: {structure_bias}")
                else:
                    warning_msg = (
                        f"‚ö†Ô∏è Missing Structure TF ({expected_structure_tf}) "
                        f"- major trend validation limited"
                    )
                    warnings.append(warning_msg)
                    adjusted_confidence -= structure_penalty
                    hierarchy_info['structure_tf_present'] = False
                    logger.warning(f"   {warning_msg} (-{structure_penalty*100:.0f}%)")
            
            # VALIDATION 3: Check HTF Bias TF (informational only, no penalty)
            if expected_htf_bias_tf:
                if expected_htf_bias_tf in available_tfs:
                    logger.info(f"   ‚úÖ HTF Bias TF ({expected_htf_bias_tf}) present")
                    hierarchy_info['htf_bias_tf_present'] = True
                else:
                    logger.info(f"   ‚ÑπÔ∏è HTF Bias TF ({expected_htf_bias_tf}) not available (optional)")
                    hierarchy_info['htf_bias_tf_present'] = False
            
            # Summary
            if not warnings:
                logger.info("   ‚úÖ TF hierarchy fully compliant")
            else:
                logger.info(f"   ‚ö†Ô∏è TF hierarchy: {len(warnings)} issue(s), confidence adjusted")
            
            return adjusted_confidence, warnings, hierarchy_info
            
        except Exception as e:
            logger.error(f"‚ùå TF hierarchy validation error: {e}")
            import traceback
            traceback.print_exc()
            return confidence, warnings, hierarchy_info
    
    def generate_signal(
        self,
        df: pd.DataFrame,
        symbol: str,
        timeframe: str = "1H",
        mtf_data: Optional[Dict[str, pd.DataFrame]] = None
    ) -> Optional[ICTSignal]:
        """
        Generate ICT signal with UNIFIED analysis sequence
        
        ‚úÖ –ï–î–ù–ê–ö–í–ê –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ—Å—Ç –∑–∞ –í–°–ò–ß–ö–ò —Ç–∞–π–º—Ñ—Ä–µ–º–æ–≤–µ (1w –¥–æ 1m)
        ‚úÖ –ï–î–ù–ê–ö–í–ê –ª–æ–≥–∏–∫–∞ –∑–∞ —Ä—ä—á–Ω–∏ –ò –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏ —Å–∏–≥–Ω–∞–ª–∏
        """
        logger.info(f"üéØ Generating UNIFIED ICT signal for {symbol} on {timeframe}")
        
        # Cache check with distance re-validation
        if self.cache_manager:
            try:
                cached_signal = self.cache_manager.get_cached_signal(symbol, timeframe)
                if cached_signal:
                    # ‚úÖ Re-validate entry distance against current price
                    current_price = df['close'].iloc[-1]
                    
                    # Guard against zero or invalid price
                    if current_price <= 0:
                        logger.warning(
                            f"‚ö†Ô∏è Invalid current price: ${current_price:.4f} - "
                            f"invalidating cache and re-analyzing"
                        )
                        # Don't return cache, continue to full analysis below
                    else:
                        entry_price = cached_signal.entry_price
                        distance_pct = abs(entry_price - current_price) / current_price
                        
                        MAX_ENTRY_DISTANCE_PCT = 0.05  # 5% max (universal limit, consistent with line 2578)
                        if distance_pct > MAX_ENTRY_DISTANCE_PCT:
                            logger.warning(
                                f"‚ö†Ô∏è Cached signal entry too far: {distance_pct*100:.1f}% > 5.0% MAX "
                                f"(entry: ${entry_price:.4f}, current: ${current_price:.4f}) "
                                f"- invalidating cache and re-analyzing"
                            )
                            # Don't return cache, continue to full analysis below
                        else:
                            logger.info(
                                f"‚úÖ Using cached signal for {symbol} {timeframe} "
                                f"(entry {distance_pct*100:.1f}% away - within limits)"
                            )
                            return cached_signal
            except Exception as e:
                logger.warning(f"Cache error: {e}")
        
        if len(df) < 50:
            logger.warning("Insufficient data")
            return None
        
        df = self._prepare_dataframe(df)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê –£–ù–ò–§–ò–¶–ò–†–ê–ù–ê –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–ù–û–°–¢ (12 –°–¢–™–ü–ö–ò) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # –°–¢–™–ü–ö–ê 1: HTF BIAS (1D ‚Üí 4H fallback)
        logger.info("üìä Step 1: HTF Bias")
        htf_bias = self._get_htf_bias_with_fallback(symbol, mtf_data)
        
        # –°–¢–™–ü–ö–ê 2: MTF STRUCTURE (4H)
        logger.info("üìä Step 2: MTF Structure")
        mtf_analysis = self._analyze_mtf_confluence(df, mtf_data, symbol) if mtf_data is not None and isinstance(mtf_data, dict) else None
        
        # ‚úÖ PR #4: –°–¢–™–ü–ö–ê 6b: TIMEFRAME HIERARCHY VALIDATION (NEW)
        logger.info("=" * 60)
        logger.info("STEP 6b: TIMEFRAME HIERARCHY VALIDATION")
        logger.info("=" * 60)
        
        # Initialize variables for hierarchy validation
        tf_warnings = []
        hierarchy_info = {}
        initial_confidence = 80.0  # Starting confidence before validation
        
        # Perform TF hierarchy validation
        validated_confidence, tf_warnings, hierarchy_info = self._validate_mtf_hierarchy(
            entry_tf=timeframe,
            mtf_analysis=mtf_analysis if mtf_analysis else {},
            confidence=initial_confidence
        )
        
        # Store hierarchy info for later use in signal generation
        context_warnings = tf_warnings  # Will be added to signal warnings later
        
        if tf_warnings:
            logger.warning(f"‚ö†Ô∏è TF hierarchy issues: {len(tf_warnings)} warnings")
            for warning in tf_warnings:
                logger.warning(f"   {warning}")
        else:
            logger.info("‚úÖ TF hierarchy validated - full compliance")
        
        logger.info(f"üìä Confidence after TF validation: {validated_confidence:.1f}%")
        
        # –°–¢–™–ü–ö–ê 3: ENTRY MODEL (—Ç–µ–∫—É—â TF)
        logger.info(f"üìä Step 3: Entry Model ({timeframe})")
        
        # –°–¢–™–ü–ö–ê 4: LIQUIDITY MAP (—Å cache fallback)
        logger.info("üìä Step 4: Liquidity Map")
        liquidity_zones = self._get_liquidity_zones_with_fallback(df, symbol, timeframe)
        
        # –°–¢–™–ü–ö–ê 5-7: ICT COMPONENTS
        logger.info("üìä Steps 5-7: ICT Components")
        ict_components = self._detect_ict_components(df, timeframe)
        ict_components['liquidity_zones'] = liquidity_zones  # Add liquidity zones
        
        # STEP 7: Bias Determination - START DIAGNOSTIC LOGGING
        logger.info("üîç Step 7: Bias Determination")
        
        # Calculate bias with diagnostic details
        bias = self._determine_market_bias(df, ict_components, mtf_analysis)
        structure_broken = self._check_structure_break(df)
        displacement_detected = self._check_displacement(df)
        
        # Log bias calculation breakdown
        bullish_obs = [ob for ob in ict_components.get('order_blocks', []) 
                       if hasattr(ob, 'type') and 'BULLISH' in str(ob.type.value)]
        bearish_obs = [ob for ob in ict_components.get('order_blocks', []) 
                       if hasattr(ob, 'type') and 'BEARISH' in str(ob.type.value)]
        bullish_fvgs = [fvg for fvg in ict_components.get('fvgs', []) 
                        if hasattr(fvg, 'is_bullish') and fvg.is_bullish]
        bearish_fvgs = [fvg for fvg in ict_components.get('fvgs', []) 
                        if hasattr(fvg, 'is_bullish') and not fvg.is_bullish]
        
        ob_score = len(bullish_obs) - len(bearish_obs)
        fvg_score = len(bullish_fvgs) - len(bearish_fvgs)
        mtf_bias_str = mtf_analysis.get('htf_bias', 'NEUTRAL') if mtf_analysis else 'NEUTRAL'
        
        logger.info(f"   ‚Üí Bias Calculation Breakdown:")
        logger.info(f"      ‚Ä¢ OB Score: {ob_score} (Bullish: {len(bullish_obs)}, Bearish: {len(bearish_obs)})")
        logger.info(f"      ‚Ä¢ FVG Score: {fvg_score} (Bullish: {len(bullish_fvgs)}, Bearish: {len(bearish_fvgs)})")
        logger.info(f"      ‚Ä¢ MTF Bias: {mtf_bias_str}")
        logger.info(f"      ‚Ä¢ Structure Broken: {structure_broken}")
        logger.info(f"      ‚Ä¢ Displacement Detected: {displacement_detected}")
        logger.info(f"   ‚Üí Final Bias: {bias.value}")
        
        # –°–¢–™–ü–ö–ê 7b: Apply confidence penalty for NEUTRAL/RANGING bias (NO EARLY EXIT)
        # ‚úÖ FIX #1: HTF is now a soft constraint (penalty) instead of hard block
        confidence_penalty = 0.0  # Track penalty for Step 11 confidence calculation
        
        if bias in [MarketBias.NEUTRAL, MarketBias.RANGING]:
            logger.warning(f"‚ö†Ô∏è Step 7b: {symbol} bias is {bias.value} - checking mitigation options")
            
            # Check ALT-independent mode
            if symbol in self.ALT_INDEPENDENT_SYMBOLS:
                logger.info(f"‚ö†Ô∏è {symbol} using ALT-independent mode - analyzing own structure")
                
                # Re-analyze with own ICT components (ignore HTF)
                own_bias = self._determine_market_bias(df, ict_components, mtf_analysis=None)
                
                if own_bias in [MarketBias.NEUTRAL, MarketBias.RANGING]:
                    # Even own structure is non-directional - must generate NO_TRADE
                    logger.warning(f"‚ùå {symbol} own bias still {own_bias.value} - cannot generate directional signal")
                    logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 7b, reason: No directional bias)")
                    
                    context = self._extract_context_data(df, own_bias, symbol)
                    mtf_consensus_data = self._calculate_mtf_consensus(symbol, timeframe, own_bias, mtf_data)
                    
                    return self._create_no_trade_message(
                        symbol=symbol,
                        timeframe=timeframe,
                        reason=f"{symbol} bias is {own_bias.value} (no directional structure)",
                        details=f"Both HTF ({bias.value}) and own structure ({own_bias.value}) are non-directional. Waiting for clearer setup.",
                        mtf_breakdown=mtf_consensus_data.get("breakdown", {}),
                        current_price=context['current_price'],
                        price_change_24h=context['price_change_24h'],
                        rsi=context['rsi'],
                        signal_direction=context['signal_direction'],
                        confidence=None
                    )
                else:
                    logger.info(f"‚úÖ {symbol} own bias is {own_bias.value} (improved from HTF {bias.value})")
                    confidence_penalty = 0.20  # 20% penalty (HTF was unclear, but own structure is clear)
                    bias = own_bias  # Use improved own bias
                    logger.info(f"   ‚Üí Continuing with {bias.value} bias and -20% confidence penalty")
            else:
                # Non-ALT symbols with NEUTRAL/RANGING - convert to NO_TRADE
                logger.warning(f"‚ùå Non-ALT symbol {symbol} with {bias.value} bias - cannot generate directional signal")
                logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 7b, reason: Non-directional bias)")
                
                context = self._extract_context_data(df, bias, symbol)
                mtf_consensus_data = self._calculate_mtf_consensus(symbol, timeframe, bias, mtf_data)
                
                return self._create_no_trade_message(
                    symbol=symbol,
                    timeframe=timeframe,
                    reason=f"Market bias is {bias.value}",
                    details=f"HTF analysis shows {bias.value} conditions. Waiting for directional structure.",
                    mtf_breakdown=mtf_consensus_data.get("breakdown", {}),
                    current_price=context['current_price'],
                    price_change_24h=context['price_change_24h'],
                    rsi=context['rsi'],
                    signal_direction=context['signal_direction'],
                    confidence=None
                )
        else:
            # Directional bias (BULLISH/BEARISH) - no penalty
            confidence_penalty = 0.0
            logger.info(f"‚úÖ Step 7b: Directional bias {bias.value} - no penalty")
        
        # ‚úÖ CONTINUE TO STEP 8 (NO EARLY EXIT FOR DIRECTIONAL BIAS)
        # At this point, bias is guaranteed to be BULLISH or BEARISH
        logger.info(f"‚úÖ PASSED Step 7: Continuing with bias {bias.value} (penalty: {confidence_penalty*100:.0f}%)")
        
        # –°–¢–™–ü–ö–ê 8: ENTRY CALCULATION WITH ICT-COMPLIANT ZONE
        logger.info("üîç Step 8: Entry Zone Validation")
        
        # Get current price
        current_price = df['close'].iloc[-1]
        logger.info(f"   ‚Üí Current Price: ${current_price:.2f}")
        
        # Calculate ICT-compliant entry zone
        bias_str = bias.value if hasattr(bias, 'value') else str(bias)
        fvg_zones = ict_components.get('fvgs', [])
        order_blocks = ict_components.get('order_blocks', [])
        sr_levels = ict_components.get('luxalgo_sr', {})
        
        logger.info(f"   ‚Üí Available ICT Components:")
        logger.info(f"      ‚Ä¢ Order Blocks: {len(order_blocks)}")
        logger.info(f"      ‚Ä¢ FVG Zones: {len(fvg_zones)}")
        sr_count = 0
        if sr_levels and isinstance(sr_levels, dict):
            sr_count = len(sr_levels.get('support_zones', [])) + len(sr_levels.get('resistance_zones', []))
        logger.info(f"      ‚Ä¢ S/R Levels: {sr_count}")
        
        entry_zone, entry_status = self._calculate_ict_compliant_entry_zone(
            current_price=current_price,
            direction=bias_str,
            fvg_zones=fvg_zones,
            order_blocks=order_blocks,
            sr_levels=sr_levels,
            timeframe=timeframe
        )
        
        logger.info(f"   ‚Üí Entry Zone Status: {entry_status}")
        if entry_zone:
            logger.info(f"      ‚Ä¢ Zone Center: ${entry_zone.get('center', 0):.2f}")
            logger.info(f"      ‚Ä¢ Zone Range: ${entry_zone.get('low', 0):.2f} - ${entry_zone.get('high', 0):.2f}")
            logger.info(f"      ‚Ä¢ Source: {entry_zone.get('source', 'UNKNOWN')}")
            logger.info(f"      ‚Ä¢ Quality: {entry_zone.get('quality', 0)}")
        
        # ‚úÖ UPDATED: Only reject for TOO_LATE (timing issue), not NO_ZONE (distance issue)
        # Validate entry zone timing
        if entry_status == 'TOO_LATE':
            logger.info(f"‚ùå BLOCKED at Step 8: Entry zone validation failed (TOO_LATE)")
            logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 8, reason: Price already passed entry zone)")
            context = self._extract_context_data(df, bias)
            # Calculate MTF consensus for detailed breakdown
            mtf_consensus_data = self._calculate_mtf_consensus(symbol, timeframe, bias, mtf_data)
            
            return self._create_no_trade_message(
                symbol=symbol,
                timeframe=timeframe,
                reason=f"Entry zone validation failed: {entry_status}",
                details=f"Current price: ${current_price:.2f}. Price already passed the entry zone.",
                mtf_breakdown=mtf_consensus_data.get("breakdown", {}),
                current_price=context['current_price'],
                price_change_24h=context['price_change_24h'],
                rsi=context['rsi'],
                signal_direction=context['signal_direction'],
                confidence=None
            )
        
        # ‚úÖ NEW: Reject signals with entry zones too far (exceeds universal 5% max)
        if entry_status == 'TOO_FAR':
            logger.info(f"‚ùå BLOCKED at Step 8: Entry zone too far from current price")
            logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 8, reason: Entry distance exceeds 5% universal maximum)")
            context = self._extract_context_data(df, bias)
            mtf_consensus_data = self._calculate_mtf_consensus(symbol, timeframe, bias, mtf_data)
            
            return self._create_no_trade_message(
                symbol=symbol,
                timeframe=timeframe,
                reason=f"Entry zone validation failed: {entry_status}",
                details=f"Entry zone too far from current price (exceeds universal 5% maximum for all timeframes).",
                mtf_breakdown=mtf_consensus_data.get("breakdown", {}),
                current_price=context['current_price'],
                price_change_24h=context['price_change_24h'],
                rsi=context['rsi'],
                signal_direction=context['signal_direction'],
                confidence=None
            )
        
        # ‚úÖ SOFT CONSTRAINT: Handle NO_ZONE case with fallback instead of rejection
        if entry_status == 'NO_ZONE' or entry_zone is None:
            logger.info(f"‚ö†Ô∏è Step 8 Warning: No ICT zone in optimal range, using fallback")
            # ‚úÖ NON-INVASIVE DIAGNOSTIC LOGGING
            logger.warning(f"‚ö†Ô∏è No ICT zone found in optimal range (0.5-5%) for {symbol}")
            logger.info(f"   ‚Üí Creating fallback entry zone at current price ${current_price:.2f}")
            logger.debug(f"   ‚Üí Fallback zone: ¬±1% from current price")
            
            # Diagnostic: Log available ICT components
            sr_count = len(sr_levels.get('support_zones', [])) + len(sr_levels.get('resistance_zones', []))
            logger.debug(f"   ‚Üí Available ICT components:")
            logger.debug(f"      - Order Blocks: {len(order_blocks)}")
            logger.debug(f"      - FVG Zones: {len(fvg_zones)}")
            logger.debug(f"      - S/R Levels: {sr_count}")
            
            # Create fallback entry zone based on current price with small buffer
            fallback_distance = 0.01  # 1% from current price
            if bias_str == 'BEARISH':
                # BEARISH: Entry above current price
                entry_zone = {
                    'source': 'FALLBACK',
                    'low': current_price * (1 + fallback_distance * 0.8),
                    'high': current_price * (1 + fallback_distance * 1.2),
                    'center': current_price * (1 + fallback_distance),
                    'quality': 40,  # Low quality for fallback
                    'distance_pct': fallback_distance * 100,
                    'distance_price': current_price * fallback_distance,
                    'distance_out_of_range': False,  # Within optimal range
                    'distance_comment': None
                }
            else:  # BULLISH
                # BULLISH: Entry below current price
                entry_zone = {
                    'source': 'FALLBACK',
                    'low': current_price * (1 - fallback_distance * 1.2),
                    'high': current_price * (1 - fallback_distance * 0.8),
                    'center': current_price * (1 - fallback_distance),
                    'quality': 40,  # Low quality for fallback
                    'distance_pct': fallback_distance * 100,
                    'distance_price': current_price * fallback_distance,
                    'distance_out_of_range': False,  # Within optimal range
                    'distance_comment': None
                }
            entry_status = 'VALID_FALLBACK'
            logger.info(f"‚úÖ Fallback entry zone created at ${entry_zone['center']:.2f}")
        
        # Log successful entry zone validation
        logger.info(f"‚úÖ PASSED Step 8: Entry zone validated ({entry_status})")
        
        # Extract entry price from entry zone for Step 9
        entry_price = entry_zone.get('center', current_price)
        logger.info(f"   ‚Üí Entry Price: ${entry_price:.2f} (from entry zone)")
        
        # Keep existing entry setup for SL calculation (fallback)
        entry_setup = self._identify_entry_setup(df, ict_components, bias)
        if not entry_setup:
            # Use entry_zone as fallback entry_setup
            entry_setup = {
                'type': f"{bias_str.lower()}_zone",
                'price_zone': (entry_zone['low'], entry_zone['high']),
                'source': entry_zone['source']
            }
        
        # –°–¢–™–ü–ö–ê 9: SL/TP + VALIDATION
        logger.info("üîç Step 9: SL/TP Calculation & Validation")
        sl_price = self._calculate_sl_price(df, entry_setup, entry_price, bias)
        logger.info(f"   ‚Üí Calculated SL: ${sl_price:.2f}")
        
        # ‚úÖ VALIDATE SL (STRICT ICT)
        order_block = entry_setup.get('ob') or (ict_components['order_blocks'][0] if ict_components.get('order_blocks') else None)
        if order_block:
            logger.info(f"   ‚Üí Validating SL against Order Block")
            if hasattr(order_block, 'zone_low'):
                logger.info(f"      ‚Ä¢ OB Range: ${order_block.zone_low:.2f} - ${order_block.zone_high:.2f}")
            
            sl_price, sl_valid = self._validate_sl_position(sl_price, order_block, bias, entry_price)
            
            if not sl_valid or sl_price is None:
                logger.info(f"‚ùå BLOCKED at Step 9: SL cannot be ICT-compliant")
                logger.info(f"   ‚Üí SL validation failed - signal rejected")
                logger.error("‚ùå SL –Ω–µ –º–æ–∂–µ –¥–∞ –±—ä–¥–µ ICT-compliant - —Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê")
                return None
            
            logger.info(f"   ‚Üí SL validated: ${sl_price:.2f}")
        else:
            logger.info(f"‚ùå BLOCKED at Step 9: No Order Block for SL validation")
            logger.error("‚ùå –ù—è–º–∞ Order Block –∑–∞ SL –≤–∞–ª–∏–¥–∞—Ü–∏—è - —Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê")
            return None
        
        # ‚úÖ TP calculation (PR #8 Enhanced: Structure-aware vs Mathematical)
        logger.info("üîç Step 9b: Take Profit Calculation")
        
        fibonacci_data = ict_components.get('fibonacci_data', {})
        bias_str = bias.value if hasattr(bias, 'value') else str(bias)
        
        # Try to use structure-aware TP placement (PR #8)
        try:
            direction = 'LONG' if bias == MarketBias.BULLISH else 'SHORT'
            tp_prices = self._calculate_smart_tp_with_structure_validation(
                entry_price=entry_price,
                sl_price=sl_price,
                direction=direction,
                ict_components=ict_components,
                timeframe=timeframe
            )
            logger.info(f"   ‚Üí Structure-aware TPs: {[f'${tp:.2f}' for tp in tp_prices]}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Structure TP calculation failed: {e}")
            # Fallback to original mathematical TP
            tp_prices = self._calculate_tp_with_min_rr(
                entry_price, sl_price, liquidity_zones, 
                min_rr=3.0, 
                fibonacci_data=fibonacci_data,
                bias=bias_str,
                timeframe=timeframe
            )
            logger.info(f"   ‚Üí Mathematical TPs (fallback): {[f'${tp:.2f}' for tp in tp_prices]}")
        
        logger.info(f"‚úÖ PASSED Step 9: SL/TP calculated and validated")
        
        # –°–¢–™–ü–ö–ê 10: RR CHECK
        logger.info("üîç Step 10: Risk/Reward Validation")
        risk = abs(entry_price - sl_price)
        
        # ‚úÖ FIX: Validate against TP2 (primary target) instead of TP1 (quick profit)
        # This allows TP1 for fast scalping while ensuring TP2 meets quality standards
        # Note: tp_prices array is [TP1, TP2, TP3], so tp_prices[1] is TP2
        if len(tp_prices) >= 2:
            # Use TP2 for quality validation (tp_prices[1] = second element = TP2)
            reward = abs(tp_prices[1] - entry_price)
            tp_label = "TP2"
            logger.info(f"   ‚Üí Validating R:R against TP2 (primary target)")
        elif len(tp_prices) >= 1:
            # Fallback to TP1 if only one TP exists
            reward = abs(tp_prices[0] - entry_price)
            tp_label = "TP1"
            logger.info(f"   ‚Üí Validating R:R against TP1 (single target)")
        else:
            reward = 0
            tp_label = "N/A"
        
        risk_reward_ratio = reward / risk if risk > 0 else 0
        
        logger.info(f"   ‚Üí Risk: ${risk:.2f}")
        logger.info(f"   ‚Üí Reward ({tp_label}): ${reward:.2f}")
        logger.info(f"   ‚Üí R:R Ratio: {risk_reward_ratio:.2f} (1:{risk_reward_ratio:.1f})")
        logger.info(f"   ‚Üí Minimum Required: {self.config['min_risk_reward']:.2f} (1:{self.config['min_risk_reward']:.0f})")
        
        if risk_reward_ratio < self.config['min_risk_reward']:
            logger.info(f"‚ùå BLOCKED at Step 10: R:R {risk_reward_ratio:.2f} < {self.config['min_risk_reward']} (1:{risk_reward_ratio:.1f} < 1:{self.config['min_risk_reward']:.0f})")
            logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 10, reason: Insufficient RR)")
            logger.error(f"‚ùå RR {risk_reward_ratio:.2f} < {self.config['min_risk_reward']} - —Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê")
            context = self._extract_context_data(df, bias)
            return self._create_no_trade_message(
                symbol=symbol,
                timeframe=timeframe,
                reason=f"Risk/Reward –ø–æ–¥ –º–∏–Ω–∏–º—É–º ({risk_reward_ratio:.2f})",
                details=f"–ù–µ–æ–±—Ö–æ–¥–∏–º–∏: RR ‚â•{self.config['min_risk_reward']}. –ù–∞–º–µ—Ä–µ–Ω–∏: {risk_reward_ratio:.2f}",
                mtf_breakdown={},
                current_price=context['current_price'],
                price_change_24h=context['price_change_24h'],
                rsi=context['rsi'],
                signal_direction=context['signal_direction'],
                confidence=None
            )
        
        logger.info(f"‚úÖ PASSED Step 10: RR validated ({risk_reward_ratio:.2f} ‚â• {self.config['min_risk_reward']:.2f} ‚Üí 1:{risk_reward_ratio:.1f} ‚â• 1:{self.config['min_risk_reward']:.0f})")
        
        # BASE CONFIDENCE
        logger.info("üîç Step 11: Confidence Calculation")
        base_confidence = self._calculate_signal_confidence(
            ict_components, mtf_analysis, bias, structure_broken, 
            displacement_detected, risk_reward_ratio
        )
        logger.info(f"   ‚Üí Base Confidence: {base_confidence:.1f}%")
        
        # ============================================
        # LIQUIDITY-BASED CONFIDENCE ADJUSTMENT
        # ============================================
        liquidity_boost = 0.0
        try:
            if ict_components.get('liquidity_zones'):
                logger.info("üíß Applying liquidity-based confidence adjustment")
                current_price = df['close'].iloc[-1]
                
                # Find nearest liquidity zone
                nearest_zone = None
                min_distance = float('inf')
                
                for zone in ict_components['liquidity_zones']:
                    zone_price = zone.price_level if hasattr(zone, 'price_level') else zone.get('price_level', 0)
                    if zone_price > 0:
                        distance = abs(zone_price - current_price) / current_price
                        if distance < min_distance:
                            min_distance = distance
                            nearest_zone = zone
                
                # Boost confidence if near strong liquidity zone
                if nearest_zone and min_distance < 0.02:  # Within 2% of price
                    zone_confidence = nearest_zone.confidence if hasattr(nearest_zone, 'confidence') else nearest_zone.get('confidence', 0)
                    zone_type = nearest_zone.zone_type if hasattr(nearest_zone, 'zone_type') else nearest_zone.get('zone_type', '')
                    
                    liquidity_boost = zone_confidence * 0.05  # Up to 5% boost
                    
                    # Apply boost in same direction as zone type
                    bias_str = bias.value if hasattr(bias, 'value') else str(bias)
                    if (bias_str == 'BULLISH' and zone_type == 'SSL') or \
                       (bias_str == 'BEARISH' and zone_type == 'BSL'):
                        base_confidence = min(base_confidence * (1 + liquidity_boost), 100.0)
                        logger.info(f"üíß Liquidity boost: +{liquidity_boost*100:.1f}% (near {zone_type})")
            
            # Check for recent liquidity sweeps
            if ict_components.get('liquidity_sweeps'):
                logger.info("üí• Checking liquidity sweeps")
                recent_sweeps = []
                for sweep in ict_components['liquidity_sweeps']:
                    sweep_timestamp = sweep.timestamp if hasattr(sweep, 'timestamp') else sweep.get('timestamp')
                    if sweep_timestamp and (df.index[-1] - sweep_timestamp).total_seconds() < 3600*4:  # Last 4 hours
                        recent_sweeps.append(sweep)
                
                if recent_sweeps:
                    last_sweep = recent_sweeps[-1]
                    sweep_type = last_sweep.sweep_type if hasattr(last_sweep, 'sweep_type') else last_sweep.get('sweep_type', '')
                    sweep_strength = last_sweep.strength if hasattr(last_sweep, 'strength') else last_sweep.get('strength', 0)
                    
                    # Boost if sweep aligns with signal direction
                    bias_str = bias.value if hasattr(bias, 'value') else str(bias)
                    if (bias_str == 'BULLISH' and sweep_type == 'SSL_SWEEP') or \
                       (bias_str == 'BEARISH' and sweep_type == 'BSL_SWEEP'):
                        sweep_boost = sweep_strength * 0.03  # Up to 3% boost
                        base_confidence = min(base_confidence * (1 + sweep_boost), 100.0)
                        logger.info(f"üí• Sweep boost: +{sweep_boost*100:.1f}% ({sweep_type})")
                        
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Liquidity confidence adjustment failed: {e}")
        
        # ‚úÖ APPLY CONTEXT-AWARE FILTERS (NEW - Enhances confidence accuracy)
        logger.info("üìä Step 11a: Context-Aware Filtering")
        context_warnings = []
        try:
            # Extract enhanced context (pass symbol for BTC correlation)
            context_data = self._extract_context_data(df, bias, symbol)
            
            # Apply context filters to adjust confidence
            confidence_after_context, context_warnings = self._apply_context_filters(
                base_confidence,
                context_data,
                ict_components
            )
            
            logger.info(f"Context-aware confidence: {base_confidence:.1f}% ‚Üí {confidence_after_context:.1f}%")
            
        except Exception as e:
            logger.warning(f"Context filtering failed, using base confidence: {e}")
            confidence_after_context = base_confidence
            context_warnings = []
        
        # ‚úÖ DISTANCE PENALTY (Soft Constraint - FIX #4)
        logger.info("üìä Step 11b: Distance Penalty Check")
        distance_penalty_applied = False
        
        if entry_zone:
            distance_pct = entry_zone.get('distance_pct', 0)
            
            # ‚úÖ FIX #4: Only penalize very close entries (<0.5%)
            # Entries 0.5-10% are optimal, >10% just get informational warning
            if distance_pct < 0.5:
                logger.warning(f"‚ö†Ô∏è Entry very close to current price ({distance_pct:.1f}%) - low risk/reward potential")
                confidence_after_context = confidence_after_context * 0.9  # Reduce by 10%
                distance_penalty_applied = True
                logger.info(f"Distance penalty applied: confidence reduced by 10% ‚Üí {confidence_after_context:.1f}%")
                context_warnings.append(f"‚ö†Ô∏è Entry very close to current price ({distance_pct:.1f}%) - low risk/reward")
            elif distance_pct > 10.0:
                # Just informational - no penalty
                logger.info(f"‚ÑπÔ∏è Entry {distance_pct:.1f}% from current price - waiting for retracement")
                context_warnings.append(f"‚ÑπÔ∏è Entry {distance_pct:.1f}% from current price - valid ICT retracement setup")
        
        # ‚úÖ HTF BIAS PENALTY (Soft Constraint - FIX #1)
        logger.info("üìä Step 11c: HTF Bias Penalty Check")
        if confidence_penalty > 0:
            logger.warning(f"‚ö†Ô∏è Applying HTF bias penalty: -{confidence_penalty*100:.0f}%")
            confidence_after_context = confidence_after_context * (1 - confidence_penalty)
            logger.info(f"HTF penalty applied: confidence reduced to {confidence_after_context:.1f}%")
            
            # Add warning about HTF bias
            if confidence_penalty >= 0.40:
                context_warnings.append("‚ö†Ô∏è Non-directional bias on both HTF and own structure - high uncertainty")
            elif confidence_penalty >= 0.35:
                context_warnings.append("‚ö†Ô∏è Non-directional HTF bias - reduced confidence")
            elif confidence_penalty >= 0.20:
                context_warnings.append("‚ÑπÔ∏è HTF bias unclear, relying on own structure")
        
        # –°–¢–™–ü–ö–ê 11: ML OPTIMIZATION (–ó–ê–ü–ê–ó–í–ê–ú–ï existing logic)
        logger.info("üìä Step 11: ML Optimization")

        ml_confidence_adjustment = 0.0
        ml_features = {}

        if self.use_ml and (self.ml_engine or self.ml_predictor):
            # Extract ML features
            ml_features = self._extract_ml_features(
                df=df,
                components=ict_components,
                mtf_analysis=mtf_analysis,
                bias=bias,
                displacement=displacement_detected,
                structure_break=structure_broken
            )
            
            # Update ICT confidence in features
            ml_features['ict_confidence'] = base_confidence / 100.0
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # ML MOVED TO FINAL POSITION (PR-ML-8)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # ML now runs AFTER all guards/risk filters as advisory-only layer.
            # See ML Advisory call after line ~1547 (after all evaluations pass).
            # This ensures ML NEVER influences signal direction, only confidence.
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # SHADOW ML PREDICTOR (LOG-ONLY, NO PRODUCTION IMPACT)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            if self.ml_predictor and self.ml_predictor.is_trained:
                try:
                    # Prepare trade data (EXACT SAME format as production ML Predictor)
                    shadow_trade_data = {
                        'entry_price': entry_price,
                        'analysis_data': ml_features,
                        'ict_components': ict_components,
                        'volume_ratio': context_data.get('volume_ratio', 1.0),
                        'volatility': context_data.get('volatility_pct', 1.0),
                        'btc_correlation': context_data.get('btc_correlation', 0.0),
                        'mtf_confluence': mtf_analysis.get('confluence_count', 0) / 5 if mtf_analysis else 0.5,
                        'risk_reward_ratio': risk_reward_ratio,
                        'rsi': context_data.get('rsi', 50.0),
                        'sentiment_score': 50.0,  # Placeholder (same as production)
                        'confidence': base_confidence  # Use base confidence (before ML adjustment)
                    }
                    
                    # Get shadow prediction (NOT USED FOR DECISIONS)
                    shadow_prediction = self.ml_predictor.predict(shadow_trade_data)
                    
                    if shadow_prediction is not None:
                        # Calculate final confidence (production logic, unchanged)
                        final_conf = base_confidence + ml_confidence_adjustment
                        
                        # Determine decision (for logging only, NOT USED)
                        decision = "SIGNAL" if final_conf >= self.config['min_confidence'] else "REJECT"
                        
                        # Log structured data (JSON on one line)
                        shadow_log = json.dumps({
                            "symbol": symbol,
                            "timeframe": timeframe,
                            "ict_confidence": round(base_confidence, 2),
                            "ml_engine_adjustment": round(ml_confidence_adjustment, 2),
                            "final_confidence": round(final_conf, 2),
                            "ml_predictor_confidence": round(shadow_prediction, 2),
                            "delta": round(shadow_prediction - final_conf, 2),
                            "decision": decision
                        })
                        
                        logger.info(f"[SHADOW_ML_PREDICTOR] {shadow_log}")
                        
                except Exception as e:
                    # Shadow error is non-critical - log and continue
                    logger.debug(f"[SHADOW_ML_PREDICTOR] Non-critical error: {e}")
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # END SHADOW MODE
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            # ‚úÖ ML RESTRICTIONS (STRICT ICT) - Step 11.25
            logger.info("üìä Step 11.25: ML ICT Compliance Check")
            
            # 1. ML –º–æ–∂–µ —Å–∞–º–æ –¥–∞ –ø—Ä–∞–≤–∏ SL –ø–æ-–∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–µ–Ω (–ø–æ-–¥–∞–ª–µ—á –æ—Ç entry), –ù–ï –ø–æ-–±–ª–∏–∑–æ
            # (–í —Ç–æ–∑–∏ –∫–æ–¥ SL –Ω–µ —Å–µ –ø—Ä–æ–º–µ–Ω—è –æ—Ç ML, —Ç–∞–∫–∞ —á–µ –ø—Ä–æ–≤–µ—Ä–∫–∞—Ç–∞ –Ω–µ –µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞)
            
            # 2. –ì–∞—Ä–∞–Ω—Ç–∏—Ä–∞–π —á–µ RR –Ω—è–º–∞ –¥–∞ –ø–∞–¥–Ω–µ –ø–æ–¥ 3.0 —Å–ª–µ–¥ ML adjustment
            # (–ü—Ä–æ–≤–µ—Ä–∫–∞—Ç–∞ –µ —Å–ª–µ–¥ –∏–∑—á–∏—Å–ª—è–≤–∞–Ω–µ –Ω–∞ confidence –ø–æ-–¥–æ–ª—É)
            
            # 3. ML confidence adjustment –ù–ï –ú–û–ñ–ï –¥–∞ –Ω–∞—Ä—É—à–∞–≤–∞ –ø—Ä–∞–≤–∏–ª–∞—Ç–∞
            # - –ê–∫–æ confidence —Å—Ç–∞–Ω–µ < 60%, —Å–∏–≥–Ω–∞–ª—ä—Ç –Ω–µ —Å–µ –∏–∑–ø—Ä–∞—â–∞
            # - –ê–∫–æ MTF consensus < 50%, ML –Ω–µ –º–æ–∂–µ –¥–∞ –ø—Ä–æ–º–µ–Ω–∏ —Ç–æ–≤–∞

        # ‚úÖ Pre-ML confidence (before ML advisory layer runs)
        # ML will be applied AFTER all guards at the end of the pipeline
        confidence = confidence_after_context
        confidence = max(0.0, min(100.0, confidence))
        
        logger.info(f"   ‚Üí Confidence (before ML advisory): {confidence:.1f}%")
        
        # –°–¢–™–ü–ö–ê 11.5: MTF CONSENSUS CHECK (STRICT ICT)
        logger.info("üîç Step 11.5: MTF Consensus Validation")
        mtf_consensus_data = self._calculate_mtf_consensus(symbol, timeframe, bias, mtf_data)
        
        logger.info(f"   ‚Üí MTF Consensus: {mtf_consensus_data['consensus_pct']:.1f}%")
        logger.info(f"   ‚Üí Aligned TFs: {mtf_consensus_data['aligned_count']}/{mtf_consensus_data['total_count']}")
        logger.info(f"   ‚Üí Minimum Required: 50%")
        
        # –ê–∫–æ MTF consensus < 50%, confidence = 0 –∏ —Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê
        if mtf_consensus_data['consensus_pct'] < 50.0:
            logger.info(f"‚ùå BLOCKED at Step 11.5: MTF consensus {mtf_consensus_data['consensus_pct']:.1f}% < 50%")
            logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 11.5, reason: Insufficient MTF consensus)")
            logger.error(f"‚ùå MTF consensus {mtf_consensus_data['consensus_pct']:.1f}% < 50% - —Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê")
            # –ò–∑–ø—Ä–∞—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ —Å—ä–æ–±—â–µ–Ω–∏–µ
            context = self._extract_context_data(df, bias)
            return self._create_no_trade_message(
                symbol=symbol,
                timeframe=timeframe,
                reason=f"–õ–∏–ø—Å–∞ –Ω–∞ MTF consensus ({mtf_consensus_data['consensus_pct']:.1f}%)",
                details=f"–ù–µ–æ–±—Ö–æ–¥–∏–º–∏: ‚â•50% aligned TFs. –ù–∞–º–µ—Ä–µ–Ω–∏: {mtf_consensus_data['aligned_count']}/{mtf_consensus_data['total_count']}",
                mtf_breakdown=mtf_consensus_data['breakdown'],
                current_price=context['current_price'],
                price_change_24h=context['price_change_24h'],
                rsi=context['rsi'],
                signal_direction=context['signal_direction'],
                confidence=confidence
            )
        
        logger.info(f"‚úÖ PASSED Step 11.5: MTF consensus validated ({mtf_consensus_data['consensus_pct']:.1f}% ‚â• 50%)")
        
        # Confidence check
        logger.info("üîç Step 11.6: Final Confidence Check")
        logger.info(f"   ‚Üí Final Confidence: {confidence:.1f}%")
        logger.info(f"   ‚Üí Minimum Required: {self.config['min_confidence']}%")
        
        if confidence < self.config['min_confidence']:
            logger.info(f"‚ùå BLOCKED at Step 11.6: Confidence {confidence:.1f}% < {self.config['min_confidence']}%")
            logger.info(f"‚úÖ Generating NO_TRADE (blocked_at_step: 11.6, reason: Low confidence)")
            logger.error(f"‚ùå Confidence {confidence:.1f}% < {self.config['min_confidence']}% - —Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê")
            context = self._extract_context_data(df, bias)
            return self._create_no_trade_message(
                symbol=symbol,
                timeframe=timeframe,
                reason=f"–ù–∏—Å–∫–∞ —É–≤–µ—Ä–µ–Ω–æ—Å—Ç ({confidence:.1f}%)",
                details=f"–ù–µ–æ–±—Ö–æ–¥–∏–º–∏: ‚â•{self.config['min_confidence']}%. –ù–∞–º–µ—Ä–µ–Ω–∏: {confidence:.1f}%",
                mtf_breakdown=mtf_consensus_data['breakdown'],
                current_price=context['current_price'],
                price_change_24h=context['price_change_24h'],
                rsi=context['rsi'],
                signal_direction=context['signal_direction'],
                confidence=confidence
            )
        
        logger.info(f"‚úÖ PASSED Step 11.6: Confidence validated ({confidence:.1f}% ‚â• {self.config['min_confidence']}%)")
        
        # –°–¢–™–ü–ö–ê 12: FINAL SIGNAL GENERATION
        logger.info("üîç Step 12: Final Signal Generation")
        signal_strength = self._calculate_signal_strength(confidence, risk_reward_ratio, ict_components)
        signal_type = self._determine_signal_type(bias, signal_strength, confidence)
        
        logger.info(f"   ‚Üí Signal Type: {signal_type.value}")
        logger.info(f"   ‚Üí Signal Strength: {signal_strength.value}")
        logger.info(f"   ‚Üí Confidence: {confidence:.1f}%")
        
        # =========================================================================
        # ‚úÖ ESB v1.0 ¬ß2.1-2.2: ENTRY GATING & CONFIDENCE THRESHOLD EVALUATION
        # =========================================================================
        logger.info("=" * 60)
        logger.info("STEP 12.1: ENTRY GATING EVALUATION (ESB ¬ß2.1)")
        logger.info("=" * 60)
        
        if ENTRY_GATING_AVAILABLE:
            # Build signal context for Entry Gating evaluation
            signal_context = {
                'symbol': symbol,
                'timeframe': timeframe,
                'direction': signal_type.value if hasattr(signal_type, 'value') else str(signal_type),
                'raw_confidence': confidence,
                
                # Entry Gating fields
                'system_state': self._get_system_state(),
                'breaker_block_active': self._check_breaker_block_active(ict_components, signal_type),
                'active_signal_exists': self._check_active_signal(symbol, timeframe),
                'cooldown_active': self._check_cooldown(symbol, timeframe),
                'market_state': self._get_market_state(symbol),
                'signature_already_seen': self._check_signature(symbol, timeframe, signal_type, datetime.now())
            }
            
            # Evaluate Entry Gating (ESB ¬ß2.1)
            entry_allowed = evaluate_entry_gating(signal_context.copy())  # Use copy to ensure immutability
            
            if not entry_allowed:
                logger.info(f"‚õî Entry Gating BLOCKED: {symbol} {timeframe}")
                logger.debug(f"Entry Gating context: {signal_context}")
                return None  # HARD BLOCK
            
            logger.info(f"‚úÖ PASSED Entry Gating: {symbol} {timeframe}")
        else:
            logger.warning("‚ö†Ô∏è Entry Gating evaluator not available - skipping check")
        
        # =========================================================================
        logger.info("=" * 60)
        logger.info("STEP 12.2: CONFIDENCE THRESHOLD EVALUATION (ESB ¬ß2.2)")
        logger.info("=" * 60)
        
        if CONFIDENCE_THRESHOLD_AVAILABLE:
            # Build signal context for Confidence Threshold evaluation
            # Reuse same context from Entry Gating (only direction and raw_confidence are required)
            confidence_context = {
                'direction': signal_type.value if hasattr(signal_type, 'value') else str(signal_type),
                'raw_confidence': confidence
            }
            
            # Evaluate Confidence Threshold (ESB ¬ß2.2)
            threshold_passed = evaluate_confidence_threshold(confidence_context.copy())  # Use copy to ensure immutability
            
            if not threshold_passed:
                logger.info(f"‚õî Confidence Threshold BLOCKED: {symbol} {timeframe} (confidence: {confidence:.2f})")
                return None  # HARD BLOCK
            
            logger.info(f"‚úÖ PASSED Confidence Threshold: {symbol} {timeframe} (confidence: {confidence:.2f})")
        else:
            logger.warning("‚ö†Ô∏è Confidence Threshold evaluator not available - skipping check")
        
        # =========================================================================
        logger.info("=" * 60)
        logger.info("STEP 12.3: EXECUTION ELIGIBILITY EVALUATION (ESB ¬ß2.3)")
        logger.info("=" * 60)
        
        if EXECUTION_ELIGIBILITY_AVAILABLE:
            # Build execution context for Execution Eligibility evaluation
            execution_context = {
                'symbol': symbol,
                'execution_state': self._get_execution_state(),
                'execution_layer_available': self._check_execution_layer_available(),
                'symbol_execution_locked': self._check_symbol_execution_lock(symbol),
                'position_capacity_available': self._check_position_capacity(symbol, signal_type.value if hasattr(signal_type, 'value') else str(signal_type)),
                'emergency_halt_active': self._check_emergency_halt()
            }
            
            # Evaluate Execution Eligibility (ESB ¬ß2.3)
            execution_allowed = evaluate_execution_eligibility(execution_context.copy())  # Use copy to ensure immutability
            
            if not execution_allowed:
                logger.info(f"‚õî ¬ß2.3 Execution Eligibility BLOCKED: {symbol} {timeframe}")
                logger.debug(f"Execution Eligibility context: {execution_context}")
                return None  # HARD BLOCK
            
            logger.info(f"‚úÖ PASSED Execution Eligibility: {symbol} {timeframe}")
        else:
            logger.warning("‚ö†Ô∏è Execution Eligibility evaluator not available - skipping check")
        
        # =========================================================================
        logger.info("=" * 60)
        logger.info("STEP 12.4: RISK ADMISSION EVALUATION (ESB ¬ß2.4)")
        logger.info("=" * 60)
        
        if RISK_ADMISSION_AVAILABLE:
            # Build risk context for Risk Admission evaluation
            risk_context = {
                'signal_risk': self._get_signal_risk(),
                'total_open_risk': self._get_total_open_risk(),
                'symbol_exposure': self._get_symbol_exposure(symbol),
                'direction_exposure': self._get_direction_exposure(signal_type.value if hasattr(signal_type, 'value') else str(signal_type)),
                'daily_loss': self._get_daily_loss()
            }
            
            # Evaluate Risk Admission (ESB ¬ß2.4)
            risk_admitted = evaluate_risk_admission(risk_context.copy())  # Use copy to ensure immutability
            
            if not risk_admitted:
                logger.info(f"‚õî ¬ß2.4 Risk Admission BLOCKED: {symbol} {timeframe}")
                logger.debug(f"Risk context: {risk_context}")
                return None  # HARD BLOCK
            
            logger.info(f"‚úÖ PASSED Risk Admission: {symbol} {timeframe}")
        else:
            logger.warning("‚ö†Ô∏è Risk Admission evaluator not available - skipping check")
        
        logger.info("=" * 60)
        logger.info("‚úÖ ALL EVALUATIONS PASSED (¬ß2.1-2.4) - PROCEEDING TO SIGNAL CREATION")
        logger.info("=" * 60)
        
        # =========================================================================
        # END ENTRY GATING, CONFIDENCE THRESHOLD, EXECUTION ELIGIBILITY & RISK ADMISSION
        # =========================================================================
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ‚úÖ PR-ML-8: ML ADVISORY LAYER (FINAL POSITION)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ML runs LAST, after all strategy decisions, risk filters, and guards.
        # ML acts ONLY as advisory layer that modifies confidence within bounds.
        # ML NEVER influences signal direction, entry/SL/TP, or overrides guards.
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info("=" * 60)
        logger.info("STEP 12.0: ML ADVISORY LAYER (PR-ML-8)")
        logger.info("=" * 60)
        
        # Strategy signal is now LOCKED - ML cannot change it
        strategy_signal = 'BUY' if bias == MarketBias.BULLISH else 'SELL' if bias == MarketBias.BEARISH else 'HOLD'
        
        if self.use_ml and self.ml_engine and self.ml_engine.model is not None:
            try:
                logger.info(f"ü§ñ Invoking ML Advisory (confidence-only modification)")
                logger.info(f"   Strategy Signal (LOCKED): {strategy_signal}")
                logger.info(f"   Base Confidence: {confidence:.1f}%")
                
                # Call new ML advisory method
                ml_advisory = self.ml_engine.get_confidence_modifier(
                    analysis=ml_features,
                    final_signal=strategy_signal,
                    base_confidence=confidence
                )
                
                # Apply ML modifier to confidence ONLY
                original_confidence = confidence
                confidence = confidence * ml_advisory['confidence_modifier']
                
                # Clamp to valid range
                confidence = max(0.0, min(100.0, confidence))
                
                # Logging
                logger.info(f"   ML Mode: {ml_advisory['mode']}")
                logger.info(f"   ML Confidence: {ml_advisory['ml_confidence']:.1f}%")
                logger.info(f"   Confidence Modifier: {ml_advisory['confidence_modifier']:.3f}x")
                logger.info(f"   Confidence: {original_confidence:.1f}% ‚Üí {confidence:.1f}%")
                
                # Log warnings if any
                if ml_advisory['warnings']:
                    for warning in ml_advisory['warnings']:
                        logger.warning(f"‚ö†Ô∏è {warning}")
                
                logger.info(f"‚úÖ ML Advisory complete (direction unchanged: {strategy_signal})")
                
            except Exception as e:
                logger.error(f"‚ùå ML Advisory error: {e}")
                logger.info(f"‚úÖ Continuing with ICT-only confidence: {confidence:.1f}%")
        else:
            logger.info("‚ÑπÔ∏è ML Advisory not available - using ICT-only confidence")
        
        logger.info("=" * 60)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # END ML ADVISORY LAYER
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        # ‚úÖ FIX 3: STEP 12a - Entry Timing Validation
        logger.info("üîç Step 12a: Entry Timing Validation")
        is_valid, reason = self._validate_entry_timing(
            entry_price, 
            current_price, 
            signal_type,
            bias
        )
        
        if not is_valid:
            logger.error(f"‚ùå BLOCKED at Step 12a: {reason}")
            return None  # Don't send invalid signal
        else:
            logger.info(f"   ‚Üí {reason}")
        
        reasoning = self._generate_reasoning(ict_components, bias, entry_setup, mtf_analysis)
        warnings = self._generate_warnings(ict_components, risk_reward_ratio, df)
        
        # ‚úÖ ADD CONTEXT WARNINGS (if any)
        if context_warnings:
            warnings.extend(context_warnings)
            logger.info(f"Added {len(context_warnings)} context-based warnings")
        
        zone_explanations = {}
        if self.zone_explainer:
            try:
                bias_str = bias.value if hasattr(bias, 'value') else str(bias)
                zone_explanations = self.zone_explainer.generate_all_explanations(ict_components, bias_str)
            except Exception as e:
                logger.error(f"Zone explanations error: {e}")
        
        # CREATE SIGNAL
        signal = ICTSignal(
            timestamp=datetime.now(),
            symbol=symbol,
            timeframe=timeframe,
            signal_type=signal_type,
            signal_strength=signal_strength,
            entry_price=entry_price,
            sl_price=sl_price,
            tp_prices=tp_prices,
            confidence=confidence,
            risk_reward_ratio=risk_reward_ratio,
            whale_blocks=[wb.to_dict() if hasattr(wb, 'to_dict') else wb for wb in ict_components.get('whale_blocks', [])],
            liquidity_zones=[lz.__dict__ if hasattr(lz, '__dict__') else lz for lz in ict_components.get('liquidity_zones', [])],
            liquidity_sweeps=[ls.__dict__ if hasattr(ls, '__dict__') else ls for ls in ict_components.get('liquidity_sweeps', [])],
            order_blocks=[ob.to_dict() if hasattr(ob, 'to_dict') else ob for ob in ict_components.get('order_blocks', [])],
            fair_value_gaps=[fvg.to_dict() if hasattr(fvg, 'to_dict') else fvg for fvg in ict_components.get('fvgs', [])],
            internal_liquidity=[ilp for ilp in ict_components.get('internal_liquidity', [])],
            breaker_blocks=[bb.to_dict() for bb in ict_components.get('breaker_blocks', [])],
            mitigation_blocks=[mb.to_dict() for mb in ict_components.get('mitigation_blocks', [])],
            sibi_ssib_zones=[sz.to_dict() for sz in ict_components.get('sibi_ssib_zones', [])],
            fibonacci_data=ict_components.get('fibonacci_data', {}),
            luxalgo_sr=ict_components.get('luxalgo_sr', {}),
            luxalgo_ict=ict_components.get('luxalgo_ict', {}),
            luxalgo_combined=ict_components.get('luxalgo_combined', {}),
            bias=bias,
            structure_broken=structure_broken,
            displacement_detected=displacement_detected,
            mtf_confluence=mtf_analysis.get('confluence_count', 0) if mtf_analysis else 0,
            htf_bias=htf_bias,
            mtf_structure=mtf_analysis.get('mtf_structure', 'NEUTRAL') if mtf_analysis else 'NEUTRAL',
            mtf_consensus_data=mtf_consensus_data,
            entry_zone=entry_zone,  # NEW: Entry zone details (with distance metadata)
            entry_status=entry_status,  # NEW: Entry zone status
            distance_penalty=distance_penalty_applied,  # ‚úÖ NEW: Distance penalty tracking
            timeframe_hierarchy=hierarchy_info,  # ‚úÖ PR #4: TF hierarchy info
            reasoning=reasoning,
            warnings=warnings,
            zone_explanations=zone_explanations
        )
        
        logger.info("=" * 60)
        logger.info("‚úÖ SIGNAL GENERATION COMPLETE")
        logger.info(f"   Signal Type: {signal_type.value}")
        logger.info(f"   Entry: ${entry_price:.2f}")
        logger.info(f"   SL: ${sl_price:.2f}")
        logger.info(f"   TP1: ${tp_prices[0]:.2f}")
        logger.info(f"   RR: {risk_reward_ratio:.2f}")
        logger.info(f"   Confidence: {confidence:.1f}%")
        logger.info(f"   MTF Consensus: {mtf_consensus_data['consensus_pct']:.1f}%")
        logger.info("=" * 60)
        logger.info(f"‚úÖ Generated {signal_type.value} signal (UNIFIED)")
        
        # Generate chart if chart generator available
        if self.chart_generator:
            try:
                logger.info("üìä Generating ICT chart...")
                chart_bytes = self.chart_generator.generate(
                    df=df,
                    signal=signal,
                    symbol=symbol,
                    timeframe=timeframe
                )
                
                # Store chart data in a temp location for bot retrieval
                # The bot will handle sending it via Telegram
                if chart_bytes:
                    logger.info(f"‚úÖ Chart generated successfully ({len(chart_bytes)} bytes)")
                else:
                    logger.warning("‚ö†Ô∏è Chart generation returned empty bytes")
                    
            except Exception as e:
                logger.error(f"‚ùå Chart generation error: {e}")
        
        if self.cache_manager:
            try:
                self.cache_manager.cache_signal(symbol, timeframe, signal)
            except Exception as e:
                logger.warning(f"Cache error: {e}")
        
        # ‚úÖ LOG FINAL SIGNAL METRICS (for validation)
        logger.info("=" * 60)
        logger.info("üìä FINAL SIGNAL METRICS:")
        logger.info(f"   Base Confidence: {base_confidence:.1f}%")
        logger.info(f"   Context-Adjusted: {confidence:.1f}%")
        logger.info(f"   Distance Penalty Applied: {distance_penalty_applied}")
        if distance_penalty_applied:
            logger.info(f"   Distance: {entry_zone.get('distance_pct', 0):.1f}% (outside optimal 0.5-3% range)")
        logger.info(f"   Signal Type: {signal_type.value if hasattr(signal_type, 'value') else signal_type}")
        logger.info(f"   Warnings: {len(warnings)}")
        if context_warnings:
            logger.info(f"   Context Warnings: {context_warnings}")
        logger.info("=" * 60)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # ‚úÖ PR #8 LAYER 1: NEWS SENTIMENT FILTER (Before final return)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        logger.info("üì∞ Step 12b: News Sentiment Filter (PR #8)")
        
        news_check = self._check_news_sentiment_before_signal(
            symbol=symbol,
            signal_type=signal_type.value if hasattr(signal_type, 'value') else str(signal_type),
            timeframe=timeframe
        )
        
        if not news_check['allow_signal']:
            logger.warning(f"‚ùå BLOCKED at Step 12b: {news_check['reasoning']}")
            logger.info(f"   Sentiment Score: {news_check['sentiment_score']:.0f}")
            if news_check['critical_news']:
                logger.info(f"   Critical News: {len(news_check['critical_news'])} articles")
            return None  # Don't send signal
        
        # Add news sentiment to warnings if there's a mild conflict
        if abs(news_check['sentiment_score']) > 10 and news_check['reasoning']:
            warnings.append(news_check['reasoning'])
            logger.info(f"Added news sentiment warning: {news_check['reasoning']}")
        
        logger.info(f"‚úÖ PASSED Step 12b: News sentiment check ({news_check['sentiment_score']:.0f})")
        
        return signal
    
    def _prepare_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:
        """Prepare dataframe with indicators"""
        df = df.copy()
        
        # Ensure datetime index
        if 'timestamp' in df.columns and not isinstance(df.index, pd.DatetimeIndex):
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df = df.set_index('timestamp')
        
        # Calculate ATR
        df['atr'] = self._calculate_atr(df, period=14)
        
        # Calculate volume metrics (Pure ICT - no MA)
        if 'volume' in df.columns:
            df['volume_median'] = df['volume'].rolling(window=20).median()
            df['volume_ratio'] = df['volume'] / df['volume_median'].replace(0, 1)
        else:
            df['volume'] = 0
            df['volume_median'] = 0
            df['volume_ratio'] = 1.0
        
        return df
    
    def _calculate_atr(self, df: pd.DataFrame, period: int = 14) -> pd.Series:
        """Calculate Average True Range"""
        high = df['high']
        low = df['low']
        close = df['close']
        
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())
        
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        # Note: .mean() here is legitimate - it's part of the standard ATR formula,
        # not a moving average for trading signals (ICT compliant)
        atr = tr.rolling(window=period).mean()
        
        return atr
    
    def _detect_ict_components(
        self,
        df: pd.DataFrame,
        timeframe: str
    ) -> Dict[str, List]:
        """
        Detect all ICT components
        
        Returns dict with:
        - whale_blocks
        - liquidity_zones
        - order_blocks
        - fvgs
        - internal_liquidity
        """
        components = {
            'whale_blocks': [],
            'liquidity_zones': [],
            'order_blocks': [],
            'fvgs': [],
            'internal_liquidity': []
        }
        
        # Detect Order Blocks
        if self.config['use_order_blocks'] and self.ob_detector:
            try:
                order_blocks = self.ob_detector.detect_order_blocks(df, timeframe)
                components['order_blocks'] = order_blocks
                logger.info(f"Detected {len(order_blocks)} order blocks")
            except Exception as e:
                logger.error(f"Order block detection error: {e}")
        
        # Detect Fair Value Gaps
        if self.config['use_fvgs'] and self.fvg_detector:
            try:
                fvgs = self.fvg_detector.detect_fvgs(df, timeframe)
                components['fvgs'] = fvgs
                logger.info(f"Detected {len(fvgs)} FVGs")
            except Exception as e:
                logger.error(f"FVG detection error: {e}")
        
        # Detect Whale Blocks
        if self.config['use_whale_blocks'] and self.whale_detector:
            try:
                whale_blocks = self.whale_detector.detect_whale_blocks(df, timeframe)
                components['whale_blocks'] = whale_blocks
                logger.info(f"Detected {len(whale_blocks)} whale blocks")
            except Exception as e:
                logger.error(f"Whale detection error: {e}")
        
        # Detect Liquidity Zones
        if self.config['use_liquidity'] and self.liquidity_mapper:
            try:
                liquidity_zones = self.liquidity_mapper.detect_liquidity_zones(df)
                components['liquidity_zones'] = liquidity_zones
                logger.info(f"Detected {len(liquidity_zones)} liquidity zones")

                # Detect Liquidity Sweeps
                if liquidity_zones:
                    try:
                        sweeps = self.liquidity_mapper.detect_liquidity_sweeps(df, liquidity_zones)
                        components['liquidity_sweeps'] = sweeps
                        logger.info(f"Detected {len(sweeps)} liquidity sweeps")
                    except Exception as e:
                        logger.error(f"Sweep detection error: {e}")
            except Exception as e:
                logger.error(f"Liquidity detection error: {e}")
        
        # Detect Internal Liquidity Pools
        if self.ilp_detector:
            try:
                ilp_analysis = self.ilp_detector.analyze(df)
                components['internal_liquidity'] = ilp_analysis.get('pools', [])
                logger.info(f"Detected {len(components['internal_liquidity'])} ILPs")
            except Exception as e:
                logger.error(f"ILP detection error: {e}")
        
        # Detect Breaker Blocks
        if self.breaker_detector and components.get('order_blocks'):
            try:
                breaker_blocks = self.breaker_detector.detect_breaker_blocks(
                    df,
                    components['order_blocks']
                )
                components['breaker_blocks'] = breaker_blocks
                logger.info(f"Detected {len(breaker_blocks)} breaker blocks")
            except Exception as e:
                logger.error(f"Breaker block detection error: {e}")
                components['breaker_blocks'] = []
        else:
            components['breaker_blocks'] = []
        
        # Detect Mitigation Blocks  
        if self.ob_detector:
            try:
                mitigation_blocks = self.ob_detector.detect_mitigation_blocks(
                    df,
                    components.get('order_blocks', [])
                )
                components['mitigation_blocks'] = mitigation_blocks
                logger.info(f"Detected {len(mitigation_blocks)} mitigation blocks")
            except Exception as e:
                logger.error(f"Mitigation block detection error: {e}")
                components['mitigation_blocks'] = []
        else:
            components['mitigation_blocks'] = []
        
        # Detect SIBI/SSIB
        if self.sibi_ssib_detector:
            try:
                sibi_ssib_zones = self.sibi_ssib_detector.detect_sibi_ssib(
                    df,
                    components.get('fvgs', []),
                    components.get('liquidity_zones', [])
                )
                components['sibi_ssib_zones'] = sibi_ssib_zones
                logger.info(f"Detected {len(sibi_ssib_zones)} SIBI/SSIB zones")
            except Exception as e:
                logger.error(f"SIBI/SSIB detection error: {e}")
                components['sibi_ssib_zones'] = []
        else:
            components['sibi_ssib_zones'] = []
        
        # Run LuxAlgo Combined Analysis
        if self.luxalgo_combined:
            try:
                luxalgo_result = self.luxalgo_combined.analyze(df)
                
                # Ensure result is valid dict (defensive)
                if not isinstance(luxalgo_result, dict):
                    logger.warning(f"LuxAlgo returned invalid type: {type(luxalgo_result)}, using defaults")
                    luxalgo_result = {
                        "sr_data": {},
                        "ict_data": {},
                        "combined_signal": {},
                        "entry_valid": False,
                        "status": "invalid_return_type"
                    }
                
                components['luxalgo_sr'] = luxalgo_result.get('sr_data', {})
                components['luxalgo_ict'] = luxalgo_result.get('ict_data', {})
                components['luxalgo_combined'] = luxalgo_result.get('combined_signal', {})
                
                # Extract entry_valid and status for observability
                entry_valid = luxalgo_result.get('entry_valid', False)
                status = luxalgo_result.get('status', 'unknown')
                
                # Structured logging (mandatory)
                sr_data = components['luxalgo_sr']
                sr_zones_count = len(sr_data.get('support_zones', [])) + len(sr_data.get('resistance_zones', []))
                logger.info(
                    f"LuxAlgo result: entry_valid={entry_valid}, status={status}, "
                    f"sr_zones={sr_zones_count}"
                )
                
                # ADVISORY MODE: entry_valid is used for confidence, NOT as hard gate
                # (Existing downstream logic should use entry_valid as confidence modifier)
                
            except Exception as e:
                logger.error(f"LuxAlgo Combined analysis error: {e}")
                components['luxalgo_sr'] = {}
                components['luxalgo_ict'] = {}
                components['luxalgo_combined'] = {}
        else:
            components['luxalgo_sr'] = {}
            components['luxalgo_ict'] = {}
            components['luxalgo_combined'] = {}
        
        # Run Fibonacci Analysis
        # Determine bias from existing components
        bias_str = self._determine_bias_from_components(components)
        if self.fibonacci_analyzer:
            try:
                fibonacci_data = self.fibonacci_analyzer.analyze(df, bias_str, lookback=50)
                components['fibonacci_data'] = fibonacci_data
                
                logger.info(f"Fibonacci analysis complete - "
                           f"In OTE: {fibonacci_data.get('in_ote_zone', False)}, "
                           f"Nearest level: {fibonacci_data.get('nearest_level', {}).get('level') if fibonacci_data.get('nearest_level') else None}")
            except Exception as e:
                logger.error(f"Fibonacci analysis error: {e}")
                components['fibonacci_data'] = {}
        else:
            components['fibonacci_data'] = {}
        
        return components
    
    def _analyze_mtf_confluence(
        self,
        primary_df: pd.DataFrame,
        mtf_data: Optional[Dict[str, pd.DataFrame]],
        symbol: str
    ) -> Optional[Dict]:
        """Analyze multi-timeframe confluence"""
        if not self.mtf_analyzer or mtf_data is None or not isinstance(mtf_data, dict):
            return None
        
        try:
            # Get higher timeframes
            htf_df = mtf_data.get('1D') or mtf_data.get('4H')
            mtf_df = mtf_data.get('4H') or mtf_data.get('1H')
            ltf_df = mtf_data.get('1H') or primary_df
            
            if htf_df is None or mtf_df is None or ltf_df is None:
                return None
            
            # Analyze
            signals = self.mtf_analyzer.analyze_multi_timeframe(htf_df, mtf_df, ltf_df, symbol)
            
            if not signals:
                return None
            
            # Get first signal
            signal = signals[0]
            
            return {
                'htf_bias': signal.htf_bias.value,
                'mtf_structure': signal.mtf_structure,
                'ltf_trigger': signal.ltf_trigger,
                'confluence_count': signal.alignment_score * 5,  # Scale to 0-5
                'alignment_score': signal.alignment_score
            }
        except Exception as e:
            logger.error(f"MTF analysis error: {e}")
            return None
    
    def _calculate_mtf_consensus(
        self,
        symbol: str,
        primary_timeframe: str,
        target_bias: MarketBias,
        mtf_data: Optional[Dict[str, pd.DataFrame]] = None
    ) -> Dict:
        """
        ‚úÖ FIX #3: Calculate Multi-Timeframe Consensus (REALISTIC)
        
        Only EXACT bias match counts as aligned
        NEUTRAL = not aligned, not conflicting (excluded from calculation)
        
        –ü—Ä–æ–≤–µ—Ä—è–≤–∞ bias –Ω–∞ –≤—Å–∏—á–∫–∏ timeframes: 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 12h, 1d, 3d, 1w
        
        Returns:
            Dict —Å:
                - consensus_pct: –ø—Ä–æ—Ü–µ–Ω—Ç —Å—ä–≥–ª–∞—Å–Ω–∏ timeframes (0-100)
                - breakdown: –¥–µ—Ç–∞–π–ª–µ–Ω breakdown –ø–æ TF
                - aligned_tfs: —Å–ø–∏—Å—ä–∫ —Å—ä—Å —Å—ä–≥–ª–∞—Å–Ω–∏ TF
                - conflicting_tfs: —Å–ø–∏—Å—ä–∫ —Å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–Ω–∏ TF
                - neutral_tfs: —Å–ø–∏—Å—ä–∫ —Å –Ω–µ—É—Ç—Ä–∞–ª–Ω–∏ TF
        """
        all_timeframes = ['1m', '3m', '5m', '15m', '30m', '1h', '2h', '4h', '6h', '12h', '1d', '3d', '1w']
        
        breakdown = {}
        aligned_count = 0
        conflicting_count = 0
        neutral_count = 0
        total_count = 0
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—ä—Ä–≤–∏—á–Ω–∏—è timeframe
        breakdown[primary_timeframe] = {
            'bias': target_bias.value if hasattr(target_bias, 'value') else str(target_bias),
            'confidence': 100,  # –ü—ä—Ä–≤–∏—á–Ω–∏—è—Ç TF –µ 100% —Å–∏–≥—É—Ä–µ–Ω
            'aligned': True
        }
        aligned_count += 1
        total_count += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—Ä—É–≥–∏ timeframes (–∞–∫–æ –∏–º–∞ –¥–∞–Ω–Ω–∏)
        if mtf_data is not None and isinstance(mtf_data, dict):
            for tf in all_timeframes:
                if tf == primary_timeframe:
                    continue  # –í–µ—á–µ –µ –¥–æ–±–∞–≤–µ–Ω
                
                tf_df = mtf_data.get(tf)
                if tf_df is not None and not tf_df.empty and len(tf_df) >= 20:
                    # ‚úÖ PURE ICT BIAS CALCULATION (no MA/EMA)
                    try:
                        tf_bias, confidence = self._calculate_pure_ict_bias_for_tf(tf_df)
                        
                        # ‚úÖ FIX #3: Only exact match counts as aligned
                        if tf_bias == target_bias:
                            is_aligned = True
                            aligned_count += 1
                        elif tf_bias in [MarketBias.NEUTRAL, MarketBias.RANGING]:
                            is_aligned = False  # Not aligned (but also not conflicting)
                            neutral_count += 1
                        else:
                            is_aligned = False  # Opposite bias
                            conflicting_count += 1
                        
                        breakdown[tf] = {
                            'bias': tf_bias.value if hasattr(tf_bias, 'value') else str(tf_bias),
                            'confidence': round(confidence, 1),
                            'aligned': is_aligned
                        }
                        
                        total_count += 1
                        
                    except Exception as e:
                        logger.warning(f"MTF consensus analysis failed for {tf}: {e}")
                        breakdown[tf] = {
                            'bias': 'NEUTRAL',
                            'confidence': 0,
                            'aligned': False
                        }
                        neutral_count += 1
                        total_count += 1
                else:
                    # –ù—è–º–∞ –¥–∞–Ω–Ω–∏ –∑–∞ —Ç–æ–∑–∏ TF - –Ω–µ —Å–µ –±—Ä–æ–∏
                    breakdown[tf] = {
                        'bias': 'NO_DATA',
                        'confidence': 0,
                        'aligned': False
                    }
                    # Don't increment counters for missing data
        else:
            # –ù—è–º–∞ MTF data - —Å–∞–º–æ primary TF
            pass
        
        # ‚úÖ FIX #3: Consensus = aligned / (aligned + conflicting)
        # NEUTRAL timeframes excluded from calculation
        consensus_denominator = aligned_count + conflicting_count
        
        if consensus_denominator > 0:
            consensus_pct = (aligned_count / consensus_denominator * 100)
        elif aligned_count > 0:
            # All timeframes are aligned (no conflicts, no neutrals) - 100%
            consensus_pct = 100.0
        else:
            # All timeframes are NEUTRAL/RANGING - undefined consensus, use 0%
            # This indicates market indecision across all timeframes
            consensus_pct = 0.0
            logger.warning("All MTF timeframes are NEUTRAL/RANGING - market indecision")
        
        # –ü–æ–¥–≥–æ—Ç–≤–∏ —Å–ø–∏—Å—ä—Ü–∏
        aligned_tfs = [tf for tf, data in breakdown.items() if data.get('aligned', False)]
        conflicting_tfs = [tf for tf, data in breakdown.items() 
                          if not data.get('aligned', False) and data.get('bias') not in ['NEUTRAL', 'RANGING', 'NO_DATA']]
        neutral_tfs = [tf for tf, data in breakdown.items() 
                      if data.get('bias') in ['NEUTRAL', 'RANGING']]
        
        logger.info(f"üìä MTF Consensus: {consensus_pct:.1f}% ({aligned_count} aligned, {neutral_count} neutral, {conflicting_count} conflicting)")
        
        return {
            'consensus_pct': round(consensus_pct, 1),
            'breakdown': breakdown,
            'aligned_tfs': aligned_tfs,
            'conflicting_tfs': conflicting_tfs,
            'neutral_tfs': neutral_tfs,  # ‚úÖ NEW
            'aligned_count': aligned_count,
            'conflicting_count': conflicting_count,  # ‚úÖ NEW
            'neutral_count': neutral_count,  # ‚úÖ NEW
            'total_count': total_count
        }
    
    def _calculate_pure_ict_bias_for_tf(
        self, 
        df: pd.DataFrame
    ) -> Tuple[MarketBias, float]:
        """
        ‚úÖ PURE ICT Bias Calculation for MTF Timeframes - NO MA/EMA!
        
        Uses:
        1. Market Structure (HH+HL vs LH+LL) - 50 points
        2. Order Block direction - 30 points
        3. Price Displacement - 20 points
        
        Args:
            df: DataFrame with OHLCV data
            
        Returns:
            Tuple of (MarketBias, confidence_score)
        """
        if len(df) < 20:
            return MarketBias.NEUTRAL, 0.0
        
        bullish_score = 0
        bearish_score = 0
        max_score = 100
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 1. MARKET STRUCTURE (50 points)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        try:
            highs = df['high'].values
            lows = df['low'].values
            
            # Find swing points (simple method - last 10 candles)
            swing_highs = []
            swing_lows = []
            
            for i in range(5, len(df) - 5):
                # Swing high: higher than 5 candles before and after
                if all(highs[i] > highs[i-j] for j in range(1, 6)) and \
                   all(highs[i] > highs[i+j] for j in range(1, 6)):
                    swing_highs.append(highs[i])
                
                # Swing low: lower than 5 candles before and after
                if all(lows[i] < lows[i-j] for j in range(1, 6)) and \
                   all(lows[i] < lows[i+j] for j in range(1, 6)):
                    swing_lows.append(lows[i])
            
            # Analyze structure
            if len(swing_highs) >= 2 and len(swing_lows) >= 2:
                # Higher Highs + Higher Lows = BULLISH
                if swing_highs[-1] > swing_highs[-2] and swing_lows[-1] > swing_lows[-2]:
                    bullish_score += 50
                # Lower Highs + Lower Lows = BEARISH
                elif swing_highs[-1] < swing_highs[-2] and swing_lows[-1] < swing_lows[-2]:
                    bearish_score += 50
                # Mixed structure = ranging (no points)
        except Exception as e:
            logger.debug(f"Market structure analysis error: {e}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 2. ORDER BLOCKS (30 points)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        try:
            bullish_obs = 0
            bearish_obs = 0
            
            # Check last 15 candles for order block patterns
            for i in range(len(df) - 15, len(df) - 1):
                if i < 1:
                    continue
                
                candle = df.iloc[i]
                next_candle = df.iloc[i + 1]
                
                # Bullish OB: Down candle followed by break of high
                if candle['close'] < candle['open']:
                    if next_candle['close'] > candle['high']:
                        bullish_obs += 1
                
                # Bearish OB: Up candle followed by break of low
                if candle['close'] > candle['open']:
                    if next_candle['close'] < candle['low']:
                        bearish_obs += 1
            
            if bullish_obs > bearish_obs:
                bullish_score += 30
            elif bearish_obs > bullish_obs:
                bearish_score += 30
        except Exception as e:
            logger.debug(f"Order block analysis error: {e}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # 3. DISPLACEMENT (20 points)
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        try:
            # Check last 5 candles for strong directional move
            last_5 = df.tail(5)
            
            total_bullish_body = 0
            total_bearish_body = 0
            
            for idx, candle in last_5.iterrows():
                body = abs(candle['close'] - candle['open'])
                
                if candle['close'] > candle['open']:  # Bullish
                    total_bullish_body += body
                else:  # Bearish
                    total_bearish_body += body
            
            # Require 60% dominance for displacement
            if total_bullish_body > total_bearish_body * 1.6:
                bullish_score += 20
            elif total_bearish_body > total_bullish_body * 1.6:
                bearish_score += 20
        except Exception as e:
            logger.debug(f"Displacement analysis error: {e}")
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # DETERMINE BIAS
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        if bullish_score >= 60 and bullish_score > bearish_score:
            return MarketBias.BULLISH, bullish_score
        elif bearish_score >= 60 and bearish_score > bullish_score:
            return MarketBias.BEARISH, bearish_score
        elif abs(bullish_score - bearish_score) <= 20:
            return MarketBias.RANGING, max(bullish_score, bearish_score)
        else:
            return MarketBias.NEUTRAL, 50.0
    
    def _determine_bias_from_components(self, components: Dict) -> str:
        """
        Helper to determine bias string from components for Fibonacci analysis
        
        Args:
            components: ICT components dictionary
            
        Returns:
            'BULLISH' or 'BEARISH' string
        """
        bullish_count = 0
        bearish_count = 0
        
        # Count bullish/bearish order blocks
        for ob in components.get('order_blocks', []):
            ob_type = str(ob.get('type', '')) if isinstance(ob, dict) else str(getattr(ob, 'type', ''))
            if 'BULLISH' in ob_type.upper():
                bullish_count += 1
            elif 'BEARISH' in ob_type.upper():
                bearish_count += 1
        
        # Count FVGs
        for fvg in components.get('fvgs', []):
            fvg_type = str(fvg.get('type', '')) if isinstance(fvg, dict) else str(getattr(fvg, 'type', ''))
            if 'BULLISH' in fvg_type.upper():
                bullish_count += 1
            elif 'BEARISH' in fvg_type.upper():
                bearish_count += 1
        
        return 'BULLISH' if bullish_count >= bearish_count else 'BEARISH'
    
    def _determine_market_bias(
        self,
        df: pd.DataFrame,
        ict_components: Dict,
        mtf_analysis: Optional[Dict]
    ) -> MarketBias:
        """Determine overall market bias"""
        bullish_score = 0
        bearish_score = 0
        
        
        # Order blocks
        bullish_obs = [ob for ob in ict_components.get('order_blocks', []) 
                       if hasattr(ob, 'type') and 'BULLISH' in str(ob.type.value)]
        bearish_obs = [ob for ob in ict_components.get('order_blocks', []) 
                       if hasattr(ob, 'type') and 'BEARISH' in str(ob.type.value)]
        
        if len(bullish_obs) > len(bearish_obs):
            bullish_score += 1
        elif len(bearish_obs) > len(bullish_obs):
            bearish_score += 1
        
        # FVGs
        bullish_fvgs = [fvg for fvg in ict_components.get('fvgs', []) 
                        if hasattr(fvg, 'is_bullish') and fvg.is_bullish]
        bearish_fvgs = [fvg for fvg in ict_components.get('fvgs', []) 
                        if hasattr(fvg, 'is_bullish') and not fvg.is_bullish]
        
        if len(bullish_fvgs) > len(bearish_fvgs):
            bullish_score += 1
        elif len(bearish_fvgs) > len(bullish_fvgs):
            bearish_score += 1
        
        # MTF bias
        if mtf_analysis:
            htf_bias = mtf_analysis.get('htf_bias', 'NEUTRAL')
            if 'BULLISH' in htf_bias:
                bullish_score += 2
            elif 'BEARISH' in htf_bias:
                bearish_score += 2
        
        # Determine bias
        # ‚úÖ FIX #2: LOWERED THRESHOLD: 2 ‚Üí 1 (easier to get directional bias)
        if bullish_score >= 1 and bullish_score > bearish_score:
            return MarketBias.BULLISH
        elif bearish_score >= 1 and bearish_score > bullish_score:
            return MarketBias.BEARISH
        elif bullish_score == bearish_score > 0:
            # Equal scores but directional components exist
            return MarketBias.NEUTRAL  # Less severe than RANGING
        else:
            # No directional components or conflicting signals
            return MarketBias.RANGING
    
    def _check_structure_break(self, df: pd.DataFrame) -> bool:
        """Check for recent structure break (BOS/CHOCH)"""
        # Simple check: look for break of recent swing high/low
        lookback = 20
        
        if len(df) < lookback:
            return False
        
        recent_high = df['high'].iloc[-lookback:].max()
        recent_low = df['low'].iloc[-lookback:].min()
        current_price = df['close'].iloc[-1]
        
        # Check if recent candles broke structure
        threshold_pct = self.config['structure_break_threshold'] / 100
        for i in range(-5, 0):
            if df['high'].iloc[i] > recent_high * (1 + threshold_pct):
                return True  # Bullish break
            if df['low'].iloc[i] < recent_low * (1 - threshold_pct):
                return True  # Bearish break
        
        return False
    
    def _check_displacement(self, df: pd.DataFrame) -> bool:
        """Check for recent displacement"""
        if len(df) < 5:
            return False
        
        # Check last 3 candles for displacement
        for i in range(-3, 0):
            price_change = abs(df['close'].iloc[i] - df['open'].iloc[i])
            price_change_pct = (price_change / df['open'].iloc[i]) * 100
            
            if price_change_pct >= self.config['min_displacement_pct']:
                return True
        
        return False
    
    def _identify_entry_setup(
        self,
        df: pd.DataFrame,
        ict_components: Dict,
        bias: MarketBias
    ) -> Optional[Dict]:
        """Identify valid entry setup"""
        current_price = df['close'].iloc[-1]
        atr = df['atr'].iloc[-1]
        
        if bias == MarketBias.BULLISH:
            # Look for bullish entry
            
            # Check for bullish order blocks near price
            bullish_obs = [ob for ob in ict_components.get('order_blocks', []) 
                          if hasattr(ob, 'type') and 'BULLISH' in str(ob.type.value)
                          and hasattr(ob, 'is_valid') and ob.is_valid()
                          and ob.bottom * 0.90 <= current_price <= ob. top * 1.15]
            
            if bullish_obs:
                best_ob = max(bullish_obs, key=lambda x: x.strength)
                return {
                    'type': 'bullish_ob',
                    'ob': best_ob,
                    'price_zone': (best_ob.bottom, best_ob.top)
                }
            
            # Check for bullish FVGs
            bullish_fvgs = [fvg for fvg in ict_components.get('fvgs', []) 
                           if hasattr(fvg, 'is_bullish') and fvg.is_bullish
                           and hasattr(fvg, 'is_valid') and fvg.is_valid()
                           and fvg.bottom * 0.90 <= current_price <= fvg.top * 1.15]
            
            if bullish_fvgs:
                best_fvg = max(bullish_fvgs, key=lambda x: x.strength)
                return {
                    'type': 'bullish_fvg',
                    'fvg': best_fvg,
                    'price_zone': (best_fvg.bottom, best_fvg.top)
                }
        
        elif bias == MarketBias.BEARISH:
            # Look for bearish entry
            
            # Check for bearish order blocks near price
            bearish_obs = [ob for ob in ict_components.get('order_blocks', []) 
                          if hasattr(ob, 'type') and 'BEARISH' in str(ob.type.value)
                          and hasattr(ob, 'is_valid') and ob.is_valid()
                          and ob.bottom * 0.95 <= current_price <= ob.top]
            
            if bearish_obs:
                best_ob = max(bearish_obs, key=lambda x: x.strength)
                return {
                    'type': 'bearish_ob',
                    'ob': best_ob,
                    'price_zone': (best_ob.bottom, best_ob.top)
                }
            
            # Check for bearish FVGs
            bearish_fvgs = [fvg for fvg in ict_components.get('fvgs', []) 
                           if hasattr(fvg, 'is_bullish') and not fvg.is_bullish
                           and hasattr(fvg, 'is_valid') and fvg.is_valid()
                           and fvg.bottom * 0.85 <= current_price <= fvg.top * 1.10]
            
            if bearish_fvgs:
                best_fvg = max(bearish_fvgs, key=lambda x: x.strength)
                return {
                    'type': 'bearish_fvg',
                    'fvg': best_fvg,
                    'price_zone': (best_fvg.bottom, best_fvg.top)
                }
        
        return None
    
    def _calculate_entry_price(
        self,
        df: pd.DataFrame,
        entry_setup: Dict,
        bias: MarketBias
    ) -> float:
        """Calculate optimal entry price"""
        current_price = df['close'].iloc[-1]
        price_zone = entry_setup.get('price_zone', (current_price, current_price))
        
        # Enter at middle of zone or current price
        adjustment = self.config['entry_adjustment_pct'] / 100
        if bias == MarketBias.BULLISH:
            # Enter near bottom of bullish zone
            entry = price_zone[0] * (1 + adjustment)
        else:
            # Enter near top of bearish zone
            entry = price_zone[1] * (1 - adjustment)
        
        return entry
    
    def _calculate_ict_compliant_entry_zone(
        self,
        current_price: float,
        direction: str,  # 'BULLISH' or 'BEARISH'
        fvg_zones: List,
        order_blocks: List,
        sr_levels: Dict,
        timeframe: str
    ) -> Tuple[Optional[Dict], str]:
        """
        Calculate ICT-compliant entry zone based on price structure.
        
        ‚úÖ UPDATED: Soft constraint approach - zones at any distance are accepted
        
        CRITICAL RULES:
        1. BEARISH (SELL): Entry zone MUST be ABOVE current price
           - Search for: Bearish FVG, Bearish OB, or Resistance level
           - Zone must be > current_price * 1.005 (at least 0.5% above)
        
        2. BULLISH (BUY): Entry zone MUST be BELOW current price
           - Search for: Bullish FVG, Bullish OB, or Support level
           - Zone must be < current_price * 0.995 (at least 0.5% below)
        
        3. Distance constraints (UNIVERSAL 5% MAX):
           - HARD REJECT: > 5% from current price (TOO_FAR - stale signal)
           - Buffer zone: 3% - 5% from current price (VALID_WAIT - needs pullback)
           - Optimal range: 0.5% - 3% from current price (VALID_NEAR - best entry)
           - Very close: < 0.5% from current price (TOO_LATE - warning only)
           - Universal 5% maximum applies to ALL timeframes (15m - 1w)
        
        4. Entry buffer: ¬±0.2% around zone boundaries
        
        Returns:
            (entry_zone_dict, status)
            
            entry_zone_dict structure:
            {
                'source': str,  # 'FVG', 'OB', 'S/R', or 'FALLBACK'
                'low': float,
                'high': float,
                'center': float,
                'quality': int,  # 0-100
                'distance_pct': float,  # % distance from current price
                'distance_price': float,  # absolute price distance
                'distance_out_of_range': bool,  # ‚úÖ NEW: True if outside 0.5-3% optimal range
                'distance_comment': str | None  # ‚úÖ NEW: Warning message if out of range
            }
            
            status codes:
            - 'TOO_FAR': Entry zone too far (> 5% universal max - HARD REJECT)
            - 'VALID_WAIT': Entry zone in buffer (3% - 5% - wait for pullback)
            - 'VALID_NEAR': Entry zone in optimal range (0.5% - 3% - price approaching)
            - 'TOO_LATE': Price already passed the entry zone (< 0.5% - warning only)
            - 'NO_ZONE': No valid entry zone found (converted to fallback in calling code)
        """
        # ‚úÖ Universal entry distance limits for ALL timeframes (15m - 1w)
        # Entry distance measures signal freshness, not trade duration
        # A signal with 20% entry distance is equally stale on any timeframe
        # Applies to both automatic signals (1h, 2h, 4h, 1d) and manual analysis (all TFs)
        min_distance_pct = 0.005  # 0.5% minimum (unchanged)
        max_distance_pct = 0.050  # 5% UNIVERSAL MAX (all timeframes)
        entry_buffer_pct = 0.002  # 0.2% buffer (unchanged)
        
        valid_zones = []
        
        # Normalize direction
        direction_upper = direction.upper() if isinstance(direction, str) else str(direction).upper()
        is_bearish = 'BEARISH' in direction_upper
        is_bullish = 'BULLISH' in direction_upper
        
        # ==== SEARCH FOR VALID ZONES ====
        
        if is_bearish:
            # BEARISH (SELL): Look for zones ABOVE current price
            
            # Check FVG zones
            for fvg in fvg_zones:
                fvg_type = str(fvg.get('type', '')) if isinstance(fvg, dict) else str(getattr(fvg, 'type', ''))
                if 'BEARISH' not in fvg_type.upper():
                    continue
                
                # Get FVG boundaries
                if isinstance(fvg, dict):
                    fvg_low = fvg.get('bottom', fvg.get('low', 0))
                    fvg_high = fvg.get('top', fvg.get('high', 0))
                else:
                    fvg_low = getattr(fvg, 'bottom', getattr(fvg, 'low', 0))
                    fvg_high = getattr(fvg, 'top', getattr(fvg, 'high', 0))
                
                if not fvg_low or not fvg_high:
                    continue
                
                # Check if FVG is ABOVE current price (min distance)
                if fvg_low > current_price * (1 + min_distance_pct):
                    distance_pct = (fvg_low - current_price) / current_price
                    
                    # ‚úÖ SOFT CONSTRAINT: Always add zone, regardless of distance
                    # Get quality
                    quality = fvg.get('strength', 70) if isinstance(fvg, dict) else getattr(fvg, 'strength', 70)
                    if not isinstance(quality, (int, float)):
                        quality = 70
                    
                    valid_zones.append({
                        'source': 'FVG',
                        'low': fvg_low,
                        'high': fvg_high,
                        'quality': quality,
                        'distance_pct': distance_pct,
                        'distance_price': fvg_low - current_price,
                        'out_of_optimal_range': distance_pct > max_distance_pct  # ‚úÖ NEW: Soft constraint flag
                    })
            
            # Check Order Blocks
            for ob in order_blocks:
                ob_type = str(ob.get('type', '')) if isinstance(ob, dict) else str(getattr(ob, 'type', ''))
                if 'BEARISH' not in ob_type.upper():
                    continue
                
                # Get OB boundaries
                if isinstance(ob, dict):
                    ob_low = ob.get('zone_low', ob.get('bottom', 0))
                    ob_high = ob.get('zone_high', ob.get('top', 0))
                else:
                    ob_low = getattr(ob, 'zone_low', getattr(ob, 'bottom', 0))
                    ob_high = getattr(ob, 'zone_high', getattr(ob, 'top', 0))
                
                if not ob_low or not ob_high:
                    continue
                
                # Check if OB is ABOVE current price
                if ob_low > current_price * (1 + min_distance_pct):
                    distance_pct = (ob_low - current_price) / current_price
                    
                    # ‚úÖ SOFT CONSTRAINT: Always add zone, regardless of distance
                    quality = ob.get('strength', 75) if isinstance(ob, dict) else getattr(ob, 'strength', 75)
                    if not isinstance(quality, (int, float)):
                        quality = 75
                    
                    valid_zones.append({
                        'source': 'OB',
                        'low': ob_low,
                        'high': ob_high,
                        'quality': quality,
                        'distance_pct': distance_pct,
                        'distance_price': ob_low - current_price,
                        'out_of_optimal_range': distance_pct > max_distance_pct  # ‚úÖ NEW: Soft constraint flag
                    })
            
            # Check Resistance levels
            resistance_zones = sr_levels.get('resistance_zones', []) if isinstance(sr_levels, dict) else []
            for res in resistance_zones:
                res_price = res.get('price', res.get('price_level', 0)) if isinstance(res, dict) else getattr(res, 'price', 0)
                
                if not res_price:
                    continue
                
                # Resistance must be ABOVE current price
                if res_price > current_price * (1 + min_distance_pct):
                    distance_pct = (res_price - current_price) / current_price
                    
                    # ‚úÖ SOFT CONSTRAINT: Always add zone, regardless of distance
                    quality = res.get('strength', 60) if isinstance(res, dict) else getattr(res, 'strength', 60)
                    if not isinstance(quality, (int, float)):
                        quality = 60
                    
                    # Create zone with small buffer around resistance
                    zone_width = res_price * 0.002  # 0.2% width
                    valid_zones.append({
                        'source': 'S/R',
                        'low': res_price - zone_width,
                        'high': res_price + zone_width,
                        'quality': quality,
                        'distance_pct': distance_pct,
                        'distance_price': res_price - current_price,
                        'out_of_optimal_range': distance_pct > max_distance_pct  # ‚úÖ NEW: Soft constraint flag
                    })
        
        elif is_bullish:
            # BULLISH (BUY): Look for zones BELOW current price
            
            # Check FVG zones
            for fvg in fvg_zones:
                fvg_type = str(fvg.get('type', '')) if isinstance(fvg, dict) else str(getattr(fvg, 'type', ''))
                if 'BULLISH' not in fvg_type.upper():
                    continue
                
                # Get FVG boundaries
                if isinstance(fvg, dict):
                    fvg_low = fvg.get('bottom', fvg.get('low', 0))
                    fvg_high = fvg.get('top', fvg.get('high', 0))
                else:
                    fvg_low = getattr(fvg, 'bottom', getattr(fvg, 'low', 0))
                    fvg_high = getattr(fvg, 'top', getattr(fvg, 'high', 0))
                
                if not fvg_low or not fvg_high:
                    continue
                
                # Check if FVG is BELOW current price (min distance)
                if fvg_high < current_price * (1 - min_distance_pct):
                    distance_pct = (current_price - fvg_high) / current_price
                    
                    # ‚úÖ SOFT CONSTRAINT: Always add zone, regardless of distance
                    quality = fvg.get('strength', 70) if isinstance(fvg, dict) else getattr(fvg, 'strength', 70)
                    if not isinstance(quality, (int, float)):
                        quality = 70
                    
                    valid_zones.append({
                        'source': 'FVG',
                        'low': fvg_low,
                        'high': fvg_high,
                        'quality': quality,
                        'distance_pct': distance_pct,
                        'distance_price': current_price - fvg_high,
                        'out_of_optimal_range': distance_pct > max_distance_pct  # ‚úÖ NEW: Soft constraint flag
                    })
            
            # Check Order Blocks
            for ob in order_blocks:
                ob_type = str(ob.get('type', '')) if isinstance(ob, dict) else str(getattr(ob, 'type', ''))
                if 'BULLISH' not in ob_type.upper():
                    continue
                
                # Get OB boundaries
                if isinstance(ob, dict):
                    ob_low = ob.get('zone_low', ob.get('bottom', 0))
                    ob_high = ob.get('zone_high', ob.get('top', 0))
                else:
                    ob_low = getattr(ob, 'zone_low', getattr(ob, 'bottom', 0))
                    ob_high = getattr(ob, 'zone_high', getattr(ob, 'top', 0))
                
                if not ob_low or not ob_high:
                    continue
                
                # Check if OB is BELOW current price
                if ob_high < current_price * (1 - min_distance_pct):
                    distance_pct = (current_price - ob_high) / current_price
                    
                    # ‚úÖ SOFT CONSTRAINT: Always add zone, regardless of distance
                    quality = ob.get('strength', 75) if isinstance(ob, dict) else getattr(ob, 'strength', 75)
                    if not isinstance(quality, (int, float)):
                        quality = 75
                    
                    valid_zones.append({
                        'source': 'OB',
                        'low': ob_low,
                        'high': ob_high,
                        'quality': quality,
                        'distance_pct': distance_pct,
                        'distance_price': current_price - ob_high,
                        'out_of_optimal_range': distance_pct > max_distance_pct  # ‚úÖ NEW: Soft constraint flag
                    })
            
            # Check Support levels
            support_zones = sr_levels.get('support_zones', []) if isinstance(sr_levels, dict) else []
            for sup in support_zones:
                sup_price = sup.get('price', sup.get('price_level', 0)) if isinstance(sup, dict) else getattr(sup, 'price', 0)
                
                if not sup_price:
                    continue
                
                # Support must be BELOW current price
                if sup_price < current_price * (1 - min_distance_pct):
                    distance_pct = (current_price - sup_price) / current_price
                    
                    # ‚úÖ SOFT CONSTRAINT: Always add zone, regardless of distance
                    quality = sup.get('strength', 60) if isinstance(sup, dict) else getattr(sup, 'strength', 60)
                    if not isinstance(quality, (int, float)):
                        quality = 60
                    
                    # Create zone with small buffer around support
                    zone_width = sup_price * 0.002  # 0.2% width
                    valid_zones.append({
                        'source': 'S/R',
                        'low': sup_price - zone_width,
                        'high': sup_price + zone_width,
                        'quality': quality,
                        'distance_pct': distance_pct,
                        'distance_price': current_price - sup_price,
                        'out_of_optimal_range': distance_pct > max_distance_pct  # ‚úÖ NEW: Soft constraint flag
                    })
        
        # ==== EVALUATE ZONES ====
        
        if not valid_zones:
            # Check if there are zones in the WRONG direction (price already passed)
            zones_behind = []
            
            if is_bearish:
                # Check for bearish zones BELOW current price (too late)
                for fvg in fvg_zones:
                    fvg_type = str(fvg.get('type', '')) if isinstance(fvg, dict) else str(getattr(fvg, 'type', ''))
                    if 'BEARISH' in fvg_type.upper():
                        fvg_high = fvg.get('top', fvg.get('high', 0)) if isinstance(fvg, dict) else getattr(fvg, 'top', getattr(fvg, 'high', 0))
                        if fvg_high and fvg_high < current_price:
                            zones_behind.append(fvg)
                
                for ob in order_blocks:
                    ob_type = str(ob.get('type', '')) if isinstance(ob, dict) else str(getattr(ob, 'type', ''))
                    if 'BEARISH' in ob_type.upper():
                        ob_high = ob.get('zone_high', ob.get('top', 0)) if isinstance(ob, dict) else getattr(ob, 'zone_high', getattr(ob, 'top', 0))
                        if ob_high and ob_high < current_price:
                            zones_behind.append(ob)
            
            elif is_bullish:
                # Check for bullish zones ABOVE current price (too late)
                for fvg in fvg_zones:
                    fvg_type = str(fvg.get('type', '')) if isinstance(fvg, dict) else str(getattr(fvg, 'type', ''))
                    if 'BULLISH' in fvg_type.upper():
                        fvg_low = fvg.get('bottom', fvg.get('low', 0)) if isinstance(fvg, dict) else getattr(fvg, 'bottom', getattr(fvg, 'low', 0))
                        if fvg_low and fvg_low > current_price:
                            zones_behind.append(fvg)
                
                for ob in order_blocks:
                    ob_type = str(ob.get('type', '')) if isinstance(ob, dict) else str(getattr(ob, 'type', ''))
                    if 'BULLISH' in ob_type.upper():
                        ob_low = ob.get('zone_low', ob.get('bottom', 0)) if isinstance(ob, dict) else getattr(ob, 'zone_low', getattr(ob, 'bottom', 0))
                        if ob_low and ob_low > current_price:
                            zones_behind.append(ob)
            
            if zones_behind:
                logger.warning(f"‚ùå Entry zones exist but price already passed them (TOO_LATE)")
                return None, 'TOO_LATE'
            else:
                logger.warning(f"‚ùå No valid entry zones found in acceptable range (NO_ZONE)")
                return None, 'NO_ZONE'
        
        # ==== SELECT BEST ZONE ====
        
        # Priority: quality * (1 - distance_pct * 10)
        # Prefer closer zones with high quality
        for zone in valid_zones:
            zone['priority'] = zone['quality'] * (1 - zone['distance_pct'] * 10)
        
        best_zone = max(valid_zones, key=lambda z: z['priority'])
        
        # ==== BUILD ENTRY ZONE DICT ====
        
        # Calculate if zone is outside optimal range (using constants)
        distance_out_of_range = best_zone['distance_pct'] * 100 > max_distance_pct * 100 or best_zone['distance_pct'] * 100 < min_distance_pct * 100
        
        entry_zone = {
            'source': best_zone['source'],
            'low': best_zone['low'] * (1 - entry_buffer_pct),
            'high': best_zone['high'] * (1 + entry_buffer_pct),
            'center': (best_zone['low'] + best_zone['high']) / 2,
            'quality': int(best_zone['quality']),
            'distance_pct': best_zone['distance_pct'] * 100,  # Convert to percentage
            'distance_price': best_zone['distance_price'],
            # ‚úÖ NEW FIELDS (soft constraint metadata)
            'distance_out_of_range': distance_out_of_range,
            'distance_comment': f"‚ö† Entry distance outside optimal range ({min_distance_pct*100:.1f}‚Äì{max_distance_pct*100:.1f}%): {best_zone['distance_pct'] * 100:.1f}%" 
                                if distance_out_of_range
                                else None
        }
        
        # ‚úÖ FIX #5: Validate distance DIRECTION (not just magnitude)
        entry_center = entry_zone['center']
        
        if is_bearish:
            # BEARISH: Entry should be ABOVE current price (waiting for rally to sell)
            if entry_center <= current_price:
                logger.warning(f"‚ö†Ô∏è BEARISH entry ${entry_center:.2f} is NOT above current ${current_price:.2f}")
                logger.warning(f"   ‚Üí Entry may have been hit already (check Step 12a)")
            
            # Calculate UPWARD distance
            distance_directional = (entry_center - current_price) / current_price * 100
            distance_direction = "above"
            entry_zone['distance_direction'] = distance_direction
            entry_zone['distance_directional'] = distance_directional
            logger.info(f"   ‚Üí Entry {abs(distance_directional):.1f}% {distance_direction} current price")
            
        elif is_bullish:
            # BULLISH: Entry should be BELOW current price (waiting for dip to buy)
            if entry_center >= current_price:
                logger.warning(f"‚ö†Ô∏è BULLISH entry ${entry_center:.2f} is NOT below current ${current_price:.2f}")
                logger.warning(f"   ‚Üí Entry may have been hit already (check Step 12a)")
            
            # Calculate DOWNWARD distance
            distance_directional = (current_price - entry_center) / current_price * 100
            distance_direction = "below"
            entry_zone['distance_direction'] = distance_direction
            entry_zone['distance_directional'] = distance_directional
            logger.info(f"   ‚Üí Entry {abs(distance_directional):.1f}% {distance_direction} current price")
        
        # ==== DETERMINE STATUS ====
        
        distance_pct = best_zone['distance_pct']
        
        # ‚úÖ FIRST: Check against universal 5% max (reject stale signals)
        if distance_pct > max_distance_pct:  # > 5%
            status = 'TOO_FAR'
            logger.error(
                f"‚ùå Entry zone too far: {distance_pct*100:.1f}% > "
                f"{max_distance_pct*100:.1f}% MAX - "
                f"—Å–∏–≥–Ω–∞–ª—ä—Ç –ù–ï –°–ï –ò–ó–ü–†–ê–©–ê (stale signal, universal limit for all timeframes)"
            )
            return None, 'TOO_FAR'  # REJECT SIGNAL
        
        # ‚úÖ Buffer zone (3% - 5%) - needs pullback
        elif distance_pct > 0.030:  # 3% - 5%
            status = 'VALID_WAIT'
            logger.info(
                f"‚úÖ Entry zone in buffer: {entry_zone['source']} at "
                f"${entry_zone['center']:.2f} ({distance_pct*100:.1f}% away) - "
                f"WAIT for pullback"
            )
        
        # ‚úÖ Optimal zone (0.5% - 3%) - best entry range
        elif distance_pct >= 0.005:  # 0.5% - 3%
            status = 'VALID_NEAR'
            logger.info(
                f"‚úÖ Entry zone in optimal range: {entry_zone['source']} at "
                f"${entry_zone['center']:.2f} ({distance_pct*100:.1f}% away) - "
                f"Price APPROACHING"
            )
        
        # ‚úÖ Very close (< 0.5%) - may be too late but don't reject
        else:  # < 0.5%
            status = 'TOO_LATE'
            logger.warning(
                f"‚ö†Ô∏è Entry zone very close: {distance_pct*100:.1f}% - "
                f"may be too late for optimal entry"
            )
        
        return entry_zone, status

    def _calculate_tp_prices(self, entry_price: float, sl_price: float, bias, ict_components: dict) -> list:
        """Calculate TP levels with 1:2, 1:3, 1:5 RR"""
        risk = abs(entry_price - sl_price)
        if str(bias) == 'MarketBias.BULLISH':
            return [entry_price + risk*3, entry_price + risk*2, entry_price + risk*5]
        else:
            return [entry_price - risk*3, entry_price - risk*2, entry_price - risk*5]

    def _calculate_tp_with_min_rr(
        self,
        entry_price: float,
        sl_price: float,
        liquidity_zones: List,
        min_rr: float = 3.0,
        fibonacci_data: Optional[Dict] = None,
        bias: Optional[str] = None,
        timeframe: str = '1h'
    ) -> List[float]:
        """
        MANDATORY: Calculate TP with GUARANTEED RR >= 1:3
        Now with Fibonacci integration for optimal TP placement
        """
        # ‚úÖ NORMALIZE BIAS: str or enum ‚Üí uppercase string
        bias_str = None
        if bias:
            if isinstance(bias, MarketBias):
                bias_str = bias.value.upper()
            elif isinstance(bias, str):
                bias_str = bias.upper()
            else:
                bias_str = str(bias).upper()
        
        # ‚úÖ GUARD: Raise exception for HOLD/RANGING
        if bias_str in ['NEUTRAL', 'RANGING']:
            raise ValueError(
                f"CRITICAL: _calculate_tp_with_min_rr() called for {bias_str} signal! "
                f"HOLD/RANGING must use early exit. Pipeline violation."
            )
        
        # ‚úÖ VALIDATE params
        if sl_price is None or entry_price is None:
            raise ValueError(
                f"Invalid params: entry={entry_price}, sl={sl_price}. "
                f"Cannot calculate TP without valid prices."
            )
        
        risk = abs(entry_price - sl_price)
        direction = 'LONG' if entry_price > sl_price else 'SHORT'
        
        # TP1: –ú–ò–ù–ò–ú–£–ú RR 1:3
        if direction == 'LONG':
            tp1 = entry_price + (risk * min_rr)
        else:
            tp1 = entry_price - (risk * min_rr)
        
        tp_levels = [tp1]
        logger.info(f"‚úÖ TP1 calculated: {tp1} (RR {min_rr}:1 guaranteed)")
        
        # Try Fibonacci targets first (if available)
        if fibonacci_data and self.fibonacci_analyzer and bias:
            try:
                fib_targets = self.fibonacci_analyzer.get_tp_targets_from_fibonacci(
                    entry_price, bias, fibonacci_data
                )
                
                if fib_targets:
                    logger.info(f"üíé {len(fib_targets)} Fibonacci TP targets found")
                    
                    # Add Fibonacci targets that are beyond TP1
                    for fib_tp in fib_targets:
                        if direction == 'LONG' and fib_tp > tp1:
                            tp_levels.append(fib_tp)
                            logger.info(f"‚úÖ TP{len(tp_levels)} aligned with Fibonacci: {fib_tp}")
                        elif direction == 'SHORT' and fib_tp < tp1:
                            tp_levels.append(fib_tp)
                            logger.info(f"‚úÖ TP{len(tp_levels)} aligned with Fibonacci: {fib_tp}")
                        
                        if len(tp_levels) >= 3:
                            break
            except Exception as e:
                logger.warning(f"Fibonacci TP calculation failed: {e}")
        
        # Fallback to liquidity zones if not enough Fibonacci targets
        if len(tp_levels) < 3 and liquidity_zones:
            for liq_zone in liquidity_zones:
                liq_price = liq_zone.get('price', liq_zone.get('price_level', 0))
                
                if direction == 'LONG' and liq_price > tp1:
                    tp_levels.append(liq_price)
                    logger.info(f"‚úÖ TP{len(tp_levels)} aligned with liquidity: {liq_price}")
                elif direction == 'SHORT' and liq_price < tp1:
                    tp_levels.append(liq_price)
                    logger.info(f"‚úÖ TP{len(tp_levels)} aligned with liquidity: {liq_price}")
                
                if len(tp_levels) >= 3:
                    break
        
        # Final fallback: structural levels with timeframe-based multipliers
        if len(tp_levels) == 1:
            # Get timeframe-optimized multipliers
            tp1_mult, tp2_mult, tp3_mult = get_tp_multipliers_by_timeframe(timeframe)
            
            tp2 = entry_price + (risk * tp2_mult) if direction == 'LONG' else entry_price - (risk * tp2_mult)
            tp_levels.append(tp2)
            logger.info(f"‚úÖ TP2 extended to {tp2_mult}R: {tp2}")
            
            tp3 = entry_price + (risk * tp3_mult) if direction == 'LONG' else entry_price - (risk * tp3_mult)
            tp_levels.append(tp3)
            logger.info(f"‚úÖ TP3 extended to {tp3_mult}R: {tp3}")
        
        return tp_levels[:3]

    def _calculate_sl_price(
        self,
        df: pd.DataFrame,
        entry_setup: Dict,
        entry_price: float,
        bias: MarketBias
    ) -> float:
        """Calculate stop loss using ICT invalidation levels"""
        # ‚úÖ GUARD: Raise exception for HOLD/RANGING
        if bias in [MarketBias.NEUTRAL, MarketBias.RANGING]:
            raise ValueError(
                f"CRITICAL: _calculate_sl_price() called for {bias.value} signal! "
                f"HOLD/RANGING must use early exit. Pipeline violation."
            )
        
        atr = df['atr'].iloc[-1]
        
        if bias == MarketBias.BULLISH:
            # SL below last swing low OR below OB/FVG zone
            lookback = 20
            recent_low = df['low'].iloc[-lookback: ].min()
            
            # Use entry zone bottom if available
            price_zone = entry_setup.get('price_zone', (entry_price, entry_price))
            zone_low = min(price_zone)
            
            # SL = lower of:  zone bottom - buffer OR recent swing low
            buffer = atr * 1.5  # ‚úÖ INCREASED: 1.5 ATR buffer for volatility protection
            sl_from_zone = zone_low - buffer
            sl_from_swing = recent_low - buffer
            
            sl_price = max(sl_from_zone, sl_from_swing)  # ‚úÖ Takes highest (closest to entry for buy orders)
            
            # Ensure minimum distance (3% from entry for volatility protection)
            # ‚úÖ BULLISH: SL MUST be BELOW entry
            min_sl_distance = entry_price * 0.03
            if abs(sl_price - entry_price) < min_sl_distance:
                sl_price = entry_price * 0.97  # At least 3% below for BUY
            
            return sl_price
        
        else:  # BEARISH
            # SL above last swing high OR above OB/FVG zone
            lookback = 20
            recent_high = df['high'].iloc[-lookback:].max()
            
            # Use entry zone top if available
            price_zone = entry_setup.get('price_zone', (entry_price, entry_price))
            zone_high = max(price_zone)
            
            # SL = higher of: zone top + buffer OR recent swing high
            buffer = atr * 1.5  # ‚úÖ INCREASED: 1.5 ATR buffer for volatility protection
            sl_from_zone = zone_high + buffer
            sl_from_swing = recent_high + buffer
            
            sl_price = min(sl_from_zone, sl_from_swing)  # ‚úÖ Takes lowest (closest to entry for sell orders)
            
            # ‚úÖ REMOVED 1% CAP - Now using minimum 3% distance for volatility protection
            # Ensure minimum distance (3% from entry for volatility protection)
            # ‚úÖ BEARISH: SL MUST be ABOVE entry
            min_sl_distance = entry_price * 0.03
            if abs(sl_price - entry_price) < min_sl_distance:
                sl_price = entry_price * 1.03  # At least 3% above for SELL
            
            return sl_price

    def _validate_entry_timing(
        self,
        entry_price: float,
        current_price: float,
        signal_type,
        bias
    ) -> Tuple[bool, str]:
        """
        ‚úÖ FIX 3: Validate that entry is still achievable
        
        ICT Rule: 
        - SELL: Entry MUST be ABOVE current price (waiting for retracement rally)
        - BUY: Entry MUST be BELOW current price (waiting for pullback)
        
        Args:
            entry_price: Proposed entry price
            current_price: Current market price
            signal_type: Signal type (BUY/SELL/STRONG_BUY/STRONG_SELL)
            bias: Market bias
            
        Returns:
            Tuple[bool, str]: (is_valid, reason_message)
        """
        # Get signal type string
        signal_type_str = signal_type.value if hasattr(signal_type, 'value') else str(signal_type)
        
        # Maximum acceptable distance: 20% (likely stale if further)
        max_distance_pct = 0.20
        
        if signal_type_str in ['SELL', 'STRONG_SELL']:
            if entry_price <= current_price:
                return False, f"‚ùå SELL entry ${entry_price:.2f} is NOT above current price ${current_price:.2f} - trade already happened!"
            
            distance_pct = (entry_price - current_price) / current_price
            if distance_pct > max_distance_pct:
                return False, f"‚ùå SELL entry {distance_pct*100:.1f}% above current price - likely stale signal (max 20%)"
        
        elif signal_type_str in ['BUY', 'STRONG_BUY']:
            if entry_price >= current_price:
                return False, f"‚ùå BUY entry ${entry_price:.2f} is NOT below current price ${current_price:.2f} - trade already happened!"
            
            distance_pct = (current_price - entry_price) / current_price
            if distance_pct > max_distance_pct:
                return False, f"‚ùå BUY entry {distance_pct*100:.1f}% below current price - likely stale signal (max 20%)"
        
        return True, "‚úÖ Entry timing valid"

    def _validate_sl_position(self, sl_price: float, order_block, direction, entry_price: float) -> Tuple[float, bool]:
        """
        –ó–ê–î–™–õ–ñ–ò–¢–ï–õ–ù–û: –í–∞–ª–∏–¥–∏—Ä–∞ —á–µ SL –µ –ø–æ–¥/–Ω–∞–¥ –≤–∞–ª–∏–¥–µ–Ω Order Block (STRICT ICT)
        
        BULLISH: SL –¢–†–Ø–ë–í–ê –¥–∞ –µ –ü–û–î Order Block bottom (buffer ‚â• 0.2-0.3%)
        BEARISH: SL –¢–†–Ø–ë–í–ê –¥–∞ –µ –ù–ê–î Order Block top (buffer ‚â• 0.2-0.3%)
        
        Returns:
            Tuple[float, bool]: (validated_sl_price, is_valid)
                - is_valid=False –æ–∑–Ω–∞—á–∞–≤–∞ —á–µ SL –Ω–µ –º–æ–∂–µ –¥–∞ –±—ä–¥–µ ICT-compliant
        """
        if not order_block:
            logger.warning("‚ö†Ô∏è No Order Block for SL validation - INVALID")
            return sl_price, False
        
        # Get OB boundaries - handle both object and dict types
        if isinstance(order_block, dict):
            ob_bottom = order_block.get('zone_low') or order_block.get('bottom')
            ob_top = order_block.get('zone_high') or order_block.get('top')
        else:
            ob_bottom = getattr(order_block, 'zone_low', None) or getattr(order_block, 'bottom', None)
            ob_top = getattr(order_block, 'zone_high', None) or getattr(order_block, 'top', None)
        
        if not ob_bottom or not ob_top:
            logger.warning("‚ö†Ô∏è Invalid Order Block structure - INVALID")
            return sl_price, False
        
        # –ú–∏–Ω–∏–º–∞–ª–µ–Ω buffer (0.2-0.3%)
        min_buffer_pct = 0.002  # 0.2%
        max_buffer_pct = 0.003  # 0.3%
        
        if direction == 'BULLISH' or direction == MarketBias.BULLISH:
            # SL –¢–†–Ø–ë–í–ê –¥–∞ –µ –ü–û–î OB bottom —Å buffer
            required_sl_max = ob_bottom * (1 - min_buffer_pct)
            
            if sl_price >= ob_bottom:
                # SL –µ –í–™–¢–†–ï –∏–ª–∏ –ù–ê–î OB - FORBIDDEN
                logger.error(f"‚ùå BULLISH SL {sl_price:.2f} >= OB bottom {ob_bottom:.2f} - FORBIDDEN")
                return None, False
            
            if sl_price > required_sl_max:
                # SL –µ —Ç–≤—ä—Ä–¥–µ –±–ª–∏–∑–æ –¥–æ OB - –∫–æ—Ä–∏–≥–∏—Ä–∞–π
                sl_price = ob_bottom * (1 - max_buffer_pct)  # 0.3% –ø–æ–¥ OB
                logger.warning(f"‚ö†Ô∏è SL –ö–û–†–ò–ì–ò–†–ê–ù –ü–û–î OB —Å buffer: {sl_price:.2f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ SL –Ω–µ –µ —Ç–≤—ä—Ä–¥–µ –±–ª–∏–∑–æ –¥–æ Entry
            min_sl_distance_pct = 0.005  # –ú–∏–Ω–∏–º—É–º 0.5% –æ—Ç entry
            if abs(entry_price - sl_price) / entry_price < min_sl_distance_pct:
                logger.error(f"‚ùå SL —Ç–≤—ä—Ä–¥–µ –±–ª–∏–∑–æ –¥–æ Entry ({abs(entry_price - sl_price) / entry_price * 100:.2f}%) - FORBIDDEN")
                return None, False
        
        elif direction == 'BEARISH' or direction == MarketBias.BEARISH:
            # SL –¢–†–Ø–ë–í–ê –¥–∞ –µ –ù–ê–î OB top —Å buffer
            required_sl_min = ob_top * (1 + min_buffer_pct)
            
            if sl_price <= ob_top:
                # SL –µ –í–™–¢–†–ï –∏–ª–∏ –ü–û–î OB - FORBIDDEN
                logger.error(f"‚ùå BEARISH SL {sl_price:.2f} <= OB top {ob_top:.2f} - FORBIDDEN")
                return None, False
            
            if sl_price < required_sl_min:
                # SL –µ —Ç–≤—ä—Ä–¥–µ –±–ª–∏–∑–æ –¥–æ OB - –∫–æ—Ä–∏–≥–∏—Ä–∞–π
                sl_price = ob_top * (1 + max_buffer_pct)  # 0.3% –Ω–∞–¥ OB
                logger.warning(f"‚ö†Ô∏è SL –ö–û–†–ò–ì–ò–†–ê–ù –ù–ê–î OB —Å buffer: {sl_price:.2f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ SL –Ω–µ –µ —Ç–≤—ä—Ä–¥–µ –±–ª–∏–∑–æ –¥–æ Entry
            min_sl_distance_pct = 0.005  # –ú–∏–Ω–∏–º—É–º 0.5% –æ—Ç entry
            if abs(sl_price - entry_price) / entry_price < min_sl_distance_pct:
                logger.error(f"‚ùå SL —Ç–≤—ä—Ä–¥–µ –±–ª–∏–∑–æ –¥–æ Entry ({abs(sl_price - entry_price) / entry_price * 100:.2f}%) - FORBIDDEN")
                return None, False
        
        logger.info(f"‚úÖ SL validated: {sl_price:.2f} (ICT-compliant)")
        return sl_price, True

    def _calculate_signal_confidence(
        self,
        ict_components: Dict,
        mtf_analysis: Optional[Dict],
        bias: MarketBias,
        structure_broken: bool,
        displacement_detected: bool,
        risk_reward_ratio: float
    ) -> float:
        """Calculate signal confidence score (0-100)"""
        confidence = 0.0
        
        # Structure break (20%)
        if structure_broken:
            confidence += 20 * self.config['structure_break_weight'] / 0.2
        
        # Whale blocks (25%)
        whale_blocks = ict_components.get('whale_blocks', [])
        if whale_blocks:
            whale_score = min(25, len(whale_blocks) * 10)
            confidence += whale_score * self.config['whale_block_weight'] / 0.25
        
        # Liquidity zones (20%)
        liquidity_zones = ict_components.get('liquidity_zones', [])
        if liquidity_zones:
            liq_score = min(20, len(liquidity_zones) * 5)
            confidence += liq_score * self.config['liquidity_weight'] / 0.2
        
        # Order blocks (15%)
        order_blocks = ict_components.get('order_blocks', [])
        if order_blocks:
            ob_score = min(15, len(order_blocks) * 5)
            confidence += ob_score * self.config['ob_weight'] / 0.15
        
        # FVGs (10%)
        fvgs = ict_components.get('fvgs', [])
        if fvgs:
            fvg_score = min(10, len(fvgs) * 3)
            confidence += fvg_score * self.config['fvg_weight'] / 0.1
        
        # MTF confluence (10%)
        if mtf_analysis:
            confluence_count = mtf_analysis.get('confluence_count', 0)
            mtf_score = min(10, confluence_count * 3)
            confidence += mtf_score * self.config['mtf_weight'] / 0.1
        
        # Breaker blocks (8%) - Implements ESB v1.0 ¬ß4 ‚Äì optional breaker block confluence boost
        breaker_blocks = ict_components.get('breaker_blocks', [])
        if breaker_blocks:
            breaker_score = min(8, len(breaker_blocks) * 3)
            confidence += breaker_score * self.config['breaker_block_weight'] / 0.08
        
        # Mitigation blocks (5%)
        mitigation_blocks = ict_components.get('mitigation_blocks', [])
        if mitigation_blocks:
            mitigation_score = min(5, len(mitigation_blocks) * 2)
            confidence += mitigation_score
        
        # SIBI/SSIB (5%)
        sibi_ssib = ict_components.get('sibi_ssib_zones', [])
        if sibi_ssib:
            sibi_ssib_score = min(5, len(sibi_ssib) * 2)
            confidence += sibi_ssib_score
        
        # Displacement bonus (10%)
        if displacement_detected:
            confidence += 10
        
        # Risk/reward bonus (max 10%)
        rr_bonus = min(10, (risk_reward_ratio / 2) * 5)
        confidence += rr_bonus
        
        # Bias penalty
        if bias == MarketBias.NEUTRAL or bias == MarketBias.RANGING:
            confidence *= 0.8
        
        # LuxAlgo confidence boost
        luxalgo_sr = ict_components.get('luxalgo_sr', {})
        luxalgo_combined = ict_components.get('luxalgo_combined', {})
        
        # Check if price near S/R zone (+15%)
        if luxalgo_sr and (luxalgo_sr.get('support_zones') or luxalgo_sr.get('resistance_zones')):
            confidence += 15
            logger.info("‚úÖ LuxAlgo S/R zones present: +15% confidence")
        
        # Check entry validation (+10%)
        if luxalgo_combined.get('entry_valid', False):
            confidence += 10
            logger.info("‚úÖ LuxAlgo entry validation passed: +10% confidence")
        
        # Check bias alignment (+10%)
        luxalgo_bias = luxalgo_combined.get('bias', 'neutral')
        if luxalgo_bias != 'neutral' and luxalgo_bias.upper() == str(bias).split('.')[-1]:
            confidence += 10
            logger.info(f"‚úÖ LuxAlgo bias aligned with {bias}: +10% confidence")
        
        # Fibonacci OTE zone boost (+10%)
        fibonacci_data = ict_components.get('fibonacci_data', {})
        if fibonacci_data.get('in_ote_zone', False):
            confidence += 10
            logger.info("‚úÖ Price in Fibonacci OTE zone: +10% confidence")
        
        return min(100, max(0, confidence))
    
    def _calculate_signal_strength(
        self,
        confidence: float,
        risk_reward_ratio: float,
        ict_components: Dict
    ) -> SignalStrength:
        """Calculate signal strength (1-5)"""
        # Base on confidence
        if confidence >= 90:
            strength = 5
        elif confidence >= 80:
            strength = 4
        elif confidence >= 70:
            strength = 3
        elif confidence >= 60:
            strength = 2
        else:
            strength = 1
        
        # Boost for high R:R
        if risk_reward_ratio >= 4:
            strength = min(5, strength + 1)
        
        # Boost for multiple ICT confirmations
        total_confirmations = (
            len(ict_components.get('whale_blocks', [])) +
            len(ict_components.get('liquidity_zones', [])) +
            len(ict_components.get('order_blocks', [])) +
            len(ict_components.get('fvgs', []))
        )
        
        if total_confirmations >= 5:
            strength = min(5, strength + 1)
        
        return SignalStrength(strength)
    
    def _create_hold_signal(
        self,
        symbol: str,
        timeframe: str,
        bias: MarketBias,
        confidence: float,
        df: pd.DataFrame,
        ict_components: Dict,
        mtf_data: Optional[Dict[str, pd.DataFrame]],
        current_price: float,
        htf_bias: str,
        mtf_consensus_data: Dict,
        structure_broken: bool,
        displacement_detected: bool,
        mtf_analysis: Optional[Dict]
    ) -> ICTSignal:
        """
        Create HOLD signal for NEUTRAL/RANGING market conditions
        
        HOLD signals are informational only:
        - NO entry price
        - NO stop loss
        - NO take profit
        - NO risk/reward ratio
        - entry_zone is None (not empty dict)
        - entry_status is 'HOLD'
        
        Args:
            symbol: Trading symbol
            timeframe: Timeframe
            bias: Market bias (NEUTRAL or RANGING)
            confidence: Signal confidence
            df: Price dataframe
            ict_components: Detected ICT components
            mtf_data: Multi-timeframe data
            current_price: Current price
            htf_bias: Higher timeframe bias
            mtf_consensus_data: MTF consensus breakdown
            structure_broken: Whether structure was broken
            displacement_detected: Whether displacement was detected
            mtf_analysis: MTF analysis data
            
        Returns:
            ICTSignal with HOLD type (informational only)
        """
        # Reasoning based on bias type
        if bias == MarketBias.RANGING:
            reasoning = "‚ÑπÔ∏è –ü–∞–∑–∞—Ä—ä—Ç –∫–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω. –ù—è–º–∞ —è—Å–Ω–∞ –ø–æ—Å–æ–∫–∞."
        else:  # NEUTRAL
            reasoning = "‚ÑπÔ∏è –ü–∞–∑–∞—Ä–Ω–∞—Ç–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –µ –Ω–µ—É—Ç—Ä–∞–ª–Ω–∞. –û—Ç–∫—Ä–∏—Ç–∏ —Å–∞ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–≤–∏ —Å–∏–≥–Ω–∞–ª–∏."
        
        # Add ICT component counts to reasoning
        whale_count = len(ict_components.get('whale_blocks', []))
        liq_count = len(ict_components.get('liquidity_zones', []))
        ob_count = len(ict_components.get('order_blocks', []))
        fvg_count = len(ict_components.get('fvgs', []))
        
        reasoning += f"\n\nICT –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –æ—Ç–∫—Ä–∏—Ç–∏:"
        if whale_count > 0:
            reasoning += f"\n‚Ä¢ {whale_count} Whale Order Blocks"
        if liq_count > 0:
            reasoning += f"\n‚Ä¢ {liq_count} Liquidity Zones"
        if ob_count > 0:
            reasoning += f"\n‚Ä¢ {ob_count} Order Blocks"
        if fvg_count > 0:
            reasoning += f"\n‚Ä¢ {fvg_count} Fair Value Gaps"
        
        reasoning += "\n\n–¢–µ–∑–∏ –∑–æ–Ω–∏ —Å–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–∏ –∏ –º–æ–≥–∞—Ç –¥–∞ –±—ä–¥–∞—Ç –∏–∑–ø–æ–ª–∑–≤–∞–Ω–∏ –∑–∞ –Ω–∞–±–ª—é–¥–µ–Ω–∏–µ –Ω–∞ –ø–∞–∑–∞—Ä–∞."
        
        # Warnings specific to HOLD signals
        warnings = [
            "–¶–µ–Ω–∞—Ç–∞ —Å–µ –¥–≤–∏–∂–∏ —Å—Ç—Ä–∞–Ω–∏—á–Ω–æ –º–µ–∂–¥—É –ø–æ–¥–¥—Ä—ä–∂–∫–∞ –∏ —Å—ä–ø—Ä–æ—Ç–∏–≤–∞",
            "–ò–∑—á–∞–∫–∞–π—Ç–µ –ø–æ—Ç–≤—ä—Ä–∂–¥–µ–Ω–∏–µ –Ω–∞ –ø—Ä–æ–±–∏–≤ –ø—Ä–µ–¥–∏ –≤—Ö–æ–¥",
            "–ù–∏—Å–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç –∑–∞ –ø–æ—Å–æ—á–Ω–∏ —Å–¥–µ–ª–∫–∏"
        ]
        
        # Add MTF warning if applicable
        if mtf_consensus_data and mtf_consensus_data.get('consensus_pct', 0) < 50:
            warnings.append(f"MTF –∫–æ–Ω—Å–µ–Ω—Å—É—Å –µ –Ω–∏—Å—ä–∫ ({mtf_consensus_data['consensus_pct']:.1f}%)")
        
        # Zone explanations (if available)
        zone_explanations = {}
        if self.zone_explainer:
            try:
                bias_str = bias.value if hasattr(bias, 'value') else str(bias)
                zone_explanations = self.zone_explainer.generate_all_explanations(ict_components, bias_str)
            except Exception as e:
                logger.error(f"Zone explanations error: {e}")
        
        # Create HOLD signal
        signal = ICTSignal(
            timestamp=datetime.now(),
            symbol=symbol,
            timeframe=timeframe,
            signal_type=SignalType.HOLD,
            signal_strength=SignalStrength.WEAK,  # Always WEAK for HOLD
            entry_price=None,  # ‚úÖ NO entry price for HOLD
            sl_price=None,  # ‚úÖ NO stop loss for HOLD
            tp_prices=[],  # ‚úÖ NO take profits for HOLD
            confidence=confidence,
            risk_reward_ratio=None,  # ‚úÖ NO RR for HOLD
            whale_blocks=[wb.to_dict() if hasattr(wb, 'to_dict') else wb for wb in ict_components.get('whale_blocks', [])],
            liquidity_zones=[lz.__dict__ if hasattr(lz, '__dict__') else lz for lz in ict_components.get('liquidity_zones', [])],
            liquidity_sweeps=[ls.__dict__ if hasattr(ls, '__dict__') else ls for ls in ict_components.get('liquidity_sweeps', [])],
            order_blocks=[ob.to_dict() if hasattr(ob, 'to_dict') else ob for ob in ict_components.get('order_blocks', [])],
            fair_value_gaps=[fvg.to_dict() if hasattr(fvg, 'to_dict') else fvg for fvg in ict_components.get('fvgs', [])],
            internal_liquidity=[ilp for ilp in ict_components.get('internal_liquidity', [])],
            breaker_blocks=[bb.to_dict() for bb in ict_components.get('breaker_blocks', [])],
            mitigation_blocks=[mb.to_dict() for mb in ict_components.get('mitigation_blocks', [])],
            sibi_ssib_zones=[sz.to_dict() for sz in ict_components.get('sibi_ssib_zones', [])],
            fibonacci_data=ict_components.get('fibonacci_data', {}),
            luxalgo_sr=ict_components.get('luxalgo_sr', {}),
            luxalgo_ict=ict_components.get('luxalgo_ict', {}),
            luxalgo_combined=ict_components.get('luxalgo_combined', {}),
            bias=bias,
            structure_broken=structure_broken,
            displacement_detected=displacement_detected,
            mtf_confluence=mtf_analysis.get('confluence_count', 0) if mtf_analysis else 0,
            htf_bias=htf_bias,
            mtf_structure=mtf_analysis.get('mtf_structure', 'NEUTRAL') if mtf_analysis else 'NEUTRAL',
            mtf_consensus_data=mtf_consensus_data,
            entry_zone=None,  # ‚úÖ None for HOLD (not empty dict)
            entry_status='HOLD',  # ‚úÖ HOLD status
            distance_penalty=False,
            reasoning=reasoning,
            warnings=warnings,
            zone_explanations=zone_explanations
        )
        
        logger.info(f"‚úÖ Generated HOLD signal (early exit) - {bias.value}")
        logger.info(f"   Confidence: {confidence:.1f}%")
        logger.info(f"   MTF Consensus: {mtf_consensus_data.get('consensus_pct', 0):.1f}%")
        
        return signal
    
    def _determine_signal_type(
        self,
        bias: MarketBias,
        signal_strength: SignalStrength,
        confidence: float
    ) -> SignalType:
        """Determine signal type"""
        if bias == MarketBias.NEUTRAL or bias == MarketBias.RANGING:
            return SignalType.HOLD
        
        if bias == MarketBias.BULLISH:
            if signal_strength.value >= 4 and confidence >= 85:
                return SignalType.STRONG_BUY
            else:
                return SignalType.BUY
        
        elif bias == MarketBias.BEARISH:
            if signal_strength.value >= 4 and confidence >= 85:
                return SignalType.STRONG_SELL
            else:
                return SignalType.SELL
        
        return SignalType.HOLD
    
    def _generate_reasoning(
        self,
        ict_components: Dict,
        bias: MarketBias,
        entry_setup: Optional[Dict],
        mtf_analysis: Optional[Dict]
    ) -> str:
        """Generate human-readable reasoning"""
        lines = []
        
        # Market bias
        lines.append(f"Market Bias: {bias.value}")
        
        # HTF bias
        if mtf_analysis:
            htf_bias = mtf_analysis.get('htf_bias', 'NEUTRAL')
            lines.append(f"Higher Timeframe: {htf_bias}")
        
        # Entry setup
        if entry_setup:
            setup_type = entry_setup.get('type', 'unknown')
            lines.append(f"Entry Setup: {setup_type.replace('_', ' ').title()}")
        
        # ICT components
        whale_count = len(ict_components.get('whale_blocks', []))
        liq_count = len(ict_components.get('liquidity_zones', []))
        ob_count = len(ict_components.get('order_blocks', []))
        fvg_count = len(ict_components.get('fvgs', []))
        
        lines.append(f"\nICT Confirmations:")
        if whale_count > 0:
            lines.append(f"- {whale_count} Whale Order Blocks detected")
        if liq_count > 0:
            lines.append(f"- {liq_count} Liquidity Zones identified")
        if ob_count > 0:
            lines.append(f"- {ob_count} Order Blocks found")
        if fvg_count > 0:
            lines.append(f"- {fvg_count} Fair Value Gaps present")
        
        # MTF confluence
        if mtf_analysis:
            confluence = mtf_analysis.get('confluence_count', 0)
            if confluence >= 2:
                lines.append(f"- Multi-timeframe alignment ({int(confluence)}/5 TFs)")
        
        return '\n'.join(lines)
    
    def _generate_warnings(
        self,
        ict_components: Dict,
        risk_reward_ratio: float,
        df: pd.DataFrame
    ) -> List[str]:
        """Generate warnings and caveats"""
        warnings = []
        
        # Low R:R warning
        if risk_reward_ratio < 2.5:
            warnings.append("Risk/reward ratio below 2.5")
        
        # Limited ICT confirmations
        total_confirmations = (
            len(ict_components.get('whale_blocks', [])) +
            len(ict_components.get('liquidity_zones', [])) +
            len(ict_components.get('order_blocks', [])) +
            len(ict_components.get('fvgs', []))
        )
        
        if total_confirmations < 3:
            warnings.append("Limited ICT confirmations")
        
        # High volatility
        atr = df['atr'].iloc[-1]
        current_price = df['close'].iloc[-1]
        atr_pct = (atr / current_price) * 100
        
        if atr_pct > 3:
            warnings.append("High volatility detected")
        
        # Low volume
        if 'volume_ratio' in df.columns:
            volume_ratio = df['volume_ratio'].iloc[-1]
            if volume_ratio < 0.7:
                warnings.append("Below average volume")
        
        return warnings
    
    def _create_no_trade_message(
        self,
        symbol: str,
        timeframe: str,
        reason: str,
        details: str,
        mtf_breakdown: Dict,
        current_price: float = None,
        price_change_24h: float = None,
        rsi: float = None,
        signal_direction: str = None,
        confidence: float = None
    ) -> Dict:
        """
        –°—ä–∑–¥–∞–≤–∞ —Å—ä–æ–±—â–µ–Ω–∏–µ "–ù—è–º–∞ –ø–æ–¥—Ö–æ–¥—è—â —Ç—Ä–µ–π–¥" —Å –æ–±—è—Å–Ω–µ–Ω–∏–µ
        
        Args:
            symbol: Trading pair symbol
            timeframe: Analysis timeframe
            reason: Main reason for blocking the trade
            details: Detailed explanation with values
            mtf_breakdown: Multi-timeframe analysis breakdown
            current_price: Current price of the asset
            price_change_24h: 24h price change percentage
            rsi: RSI indicator value
            signal_direction: Signal direction (BUY/SELL)
            confidence: Signal confidence percentage
        
        Returns:
            Dict —Å—ä—Å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–∞–Ω–æ —Å—ä–æ–±—â–µ–Ω–∏–µ (–Ω–µ ICTSignal –æ–±–µ–∫—Ç)
        """
        # Calculate MTF consensus percentage
        mtf_consensus_pct = 0.0
        if mtf_breakdown:
            aligned_count = sum(1 for data in mtf_breakdown.values() if data.get('aligned', False))
            total_count = len(mtf_breakdown)
            mtf_consensus_pct = (aligned_count / total_count * 100) if total_count > 0 else 0.0
        
        return {
            'type': 'NO_TRADE',
            'symbol': symbol,
            'timeframe': timeframe,
            'timestamp': datetime.now().isoformat(),
            'reason': reason,
            'details': details,
            'mtf_breakdown': mtf_breakdown,
            'mtf_consensus_pct': mtf_consensus_pct,
            'current_price': current_price,
            'price_change_24h': price_change_24h,
            'rsi': rsi,
            'signal_direction': signal_direction,
            'confidence': confidence,
            # Keep legacy message field for backward compatibility (will be ignored by new format)
            'message': f"""
‚ùå <b>–ù–Ø–ú–ê –ü–û–î–•–û–î–Ø–© –¢–†–ï–ô–î</b>

üí∞ <b>–°–∏–º–≤–æ–ª:</b> {symbol}
‚è∞ <b>–¢–∞–π–º—Ñ—Ä–µ–π–º:</b> {timeframe}

üö´ <b>–ü—Ä–∏—á–∏–Ω–∞:</b> {reason}
üìã <b>–î–µ—Ç–∞–π–ª–∏:</b> {details}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
üìä <b>MTF Breakdown:</b>
{self._format_mtf_breakdown(mtf_breakdown)}

üí° <b>–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:</b> –ò–∑—á–∞–∫–∞–π—Ç–µ –ø–æ-–¥–æ–±—Ä–∏ —É—Å–ª–æ–≤–∏—è –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä–µ—Ç–µ –¥—Ä—É–≥ —Ç–∞–π–º—Ñ—Ä–µ–π–º
"""
        }
    
    def _format_mtf_breakdown(self, breakdown: Dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–∞ MTF breakdown –∑–∞ –ø–æ–∫–∞–∑–≤–∞–Ω–µ"""
        lines = []
        for tf, data in sorted(breakdown.items(), key=lambda x: self._timeframe_order(x[0])):
            bias = data['bias']
            confidence = data['confidence']
            aligned = data['aligned']
            
            emoji = "‚úÖ" if aligned else "‚ùå"
            if bias == 'NO_DATA':
                line = f"{emoji} {tf}: –ù—è–º–∞ –¥–∞–Ω–Ω–∏"
            else:
                line = f"{emoji} {tf}: {bias} ({confidence:.0f}% —É–≤–µ—Ä–µ–Ω)"
            
            lines.append(line)
        
        return "\n".join(lines)
    
    def _timeframe_order(self, tf: str) -> int:
        """–í—Ä—ä—â–∞ —á–∏—Å–ª–æ–≤ —Ä–µ–¥ –Ω–∞ timeframe –∑–∞ —Å–æ—Ä—Ç–∏—Ä–∞–Ω–µ"""
        order = {
            '1m': 1, '3m': 2, '5m': 3, '15m': 4, '30m': 5,
            '1h': 6, '2h': 7, '4h': 8, '6h': 9, '12h': 10,
            '1d': 11, '3d': 12, '1w': 13
        }
        return order.get(tf, 999)
    
    def _extract_context_data(
        self, 
        df: pd.DataFrame, 
        bias: 'MarketBias',
        symbol: Optional[str] = None  # NEW: Optional parameter (backward compatible)
    ) -> Dict:
        """
        Extract context data for no-trade messages
        
        Returns:
            Dict with current_price, price_change_24h, rsi, signal_direction
        """
        try:
            current_price = df['close'].iloc[-1]
            
            # Calculate 24h price change (if enough data)
            price_change_24h = None
            if len(df) >= 24:
                price_24h_ago = df['close'].iloc[-24]
                price_change_24h = ((current_price - price_24h_ago) / price_24h_ago) * 100
            
            # Calculate RSI
            rsi = None
            if 'rsi' in df.columns:
                rsi = df['rsi'].iloc[-1]
            else:
                # Calculate RSI if not present
                if len(df) >= 15:
                    delta = df['close'].diff()
                    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                    rs = gain / loss.replace(0, 1)
                    rs_value = rs.iloc[-1]
                    # Validate RSI calculation
                    if pd.notna(rs_value) and rs_value != float('inf'):
                        rsi = 100 - (100 / (1 + rs_value))
                    else:
                        rsi = None
            
            # Determine signal direction from bias
            signal_direction = None
            if hasattr(bias, 'value'):
                bias_val = bias.value
            else:
                bias_val = str(bias)
            
            if 'BULLISH' in bias_val.upper() or 'BUY' in bias_val.upper():
                signal_direction = 'BUY'
            elif 'BEARISH' in bias_val.upper() or 'SELL' in bias_val.upper():
                signal_direction = 'SELL'
            else:
                signal_direction = 'NEUTRAL'
            
            # === NEW: ENHANCED CONTEXT (Add below existing code) ===
            
            # Volume Context
            volume_ratio = 1.0
            volume_spike = False
            try:
                if 'volume_ratio' in df.columns:
                    # Use pre-calculated volume_ratio from dataframe (uses median)
                    volume_ratio = df['volume_ratio'].iloc[-1]
                    volume_spike = volume_ratio > 2.0
                elif 'volume' in df.columns and len(df) >= 20:
                    # Fallback: calculate using median
                    volume_median = df['volume'].rolling(20).median().iloc[-1]
                    current_volume = df['volume'].iloc[-1]
                    if volume_median > 0:
                        volume_ratio = current_volume / volume_median
                        volume_spike = volume_ratio > 2.0
            except Exception as e:
                logger.debug(f"Volume context calculation error: {e}")
            
            # Volatility Context
            volatility_pct = 0.0
            high_volatility = False
            try:
                if 'atr' in df.columns:
                    atr = df['atr'].iloc[-1]
                    volatility_pct = (atr / current_price) * 100 if current_price > 0 else 0
                    high_volatility = volatility_pct > 3.0
            except Exception as e:
                logger.debug(f"Volatility context calculation error: {e}")
            
            # Trading Session Context
            session = 'UNKNOWN'
            try:
                hour_utc = datetime.utcnow().hour
                if 0 <= hour_utc < 8:
                    session = 'ASIAN'
                elif 8 <= hour_utc < 16:
                    session = 'LONDON'
                else:
                    session = 'NEW_YORK'
            except Exception as e:
                logger.debug(f"Session detection error: {e}")
            
            # BTC Correlation Context
            btc_correlation = None
            btc_aligned = None
            if symbol and symbol not in ['BTCUSDT', 'BTC', 'BTCUSD']:
                # Calculate real BTC correlation
                btc_correlation, btc_aligned = self._calculate_btc_correlation(symbol, df)
            
            return {
                # ‚úÖ EXISTING FIELDS (unchanged)
                'current_price': current_price,
                'price_change_24h': price_change_24h,
                'rsi': rsi,
                'signal_direction': signal_direction,
                
                # ‚úÖ NEW FIELDS (added for enhanced context)
                'volume_ratio': round(volume_ratio, 2),
                'volume_spike': volume_spike,
                'volatility_pct': round(volatility_pct, 2),
                'high_volatility': high_volatility,
                'btc_correlation': btc_correlation,
                'btc_aligned': btc_aligned,
                'trading_session': session
            }
        except Exception as e:
            logger.warning(f"Error extracting context data for bias {bias}: {e}", exc_info=True)
            return {
                'current_price': None,
                'price_change_24h': None,
                'rsi': None,
                'signal_direction': None
            }
    
    def _apply_context_filters(
        self,
        base_confidence: float,
        context: Dict,
        ict_components: Dict
    ) -> Tuple[float, List[str]]:
        """
        ‚úÖ NEW: Apply context-based confidence adjustments and generate warnings
        
        This method enhances signal quality by considering market context:
        - Volume conditions
        - Volatility levels
        - Trading session
        - BTC correlation (for altcoins)
        
        Args:
            base_confidence: Base confidence score from ICT analysis
            context: Context data from _extract_context_data()
            ict_components: ICT components dictionary
            
        Returns:
            Tuple of (adjusted_confidence, warnings_list)
            
        ‚ö†Ô∏è IMPORTANT: This method only ADJUSTS confidence, never blocks signals!
        Signal blocking is still controlled by existing min_confidence threshold.
        """
        warnings = []
        context_info = []  # ‚úÖ PR #3 FIX #4: Separate context from warnings
        adjustment = 0.0
        
        try:
            # ‚úÖ PR #3 FIX #4: Determine current session first
            session = context.get('trading_session', 'UNKNOWN')
            is_peak_session = session in ['LONDON', 'NEW_YORK']
            
            # === FILTER 1: VOLUME ANALYSIS ===
            volume_ratio = context.get('volume_ratio', 1.0)
            volume_spike = context.get('volume_spike', False)
            
            if volume_ratio < 0.5:
                # ‚úÖ PR #3 FIX #4: Only warn about low volume during off-peak sessions
                if not is_peak_session:
                    warnings.append("‚ö†Ô∏è LOW VOLUME - Reduced liquidity may affect execution")
                    adjustment -= 10
                    logger.info("Context filter: Low volume detected (-10%)")
                else:
                    # During peak sessions, low volume relative to 24h avg is less critical
                    logger.info("Context filter: Low volume detected but ignored (peak session)")
            elif volume_spike:
                # High volume spike - increase confidence
                warnings.append("‚úÖ HIGH VOLUME - Strong market participation")
                adjustment += 5
                logger.info("Context filter: Volume spike detected (+5%)")
            
            # === FILTER 2: VOLATILITY ANALYSIS ===
            volatility_pct = context.get('volatility_pct', 0.0)
            high_volatility = context.get('high_volatility', False)
            
            if high_volatility:
                # High volatility - slight confidence reduction (riskier)
                warnings.append("‚ö†Ô∏è HIGH VOLATILITY - Consider wider stop loss")
                adjustment -= 5
                logger.info(f"Context filter: High volatility ({volatility_pct:.1f}%) detected (-5%)")
            
            # === FILTER 3: TRADING SESSION ===
            # ‚úÖ PR #3 FIX #4: Move session info to context (not warnings)
            
            if session == 'ASIAN':
                # Asian session - typically lower liquidity for crypto
                context_info.append("‚ÑπÔ∏è ASIAN SESSION - Lower liquidity period")
                adjustment -= 5
                logger.info("Context filter: Asian session (-5%)")
            elif session == 'LONDON':
                # London session - high liquidity
                context_info.append("üåç LONDON SESSION - Peak liquidity period")
                adjustment += 5
                logger.info("Context filter: London session (+5%)")
            elif session == 'NEW_YORK':
                # NY session - high liquidity (especially overlap with London)
                context_info.append("üóΩ NEW YORK SESSION - High liquidity period")
                adjustment += 3
                logger.info("Context filter: New York session (+3%)")
            
            # === FILTER 4: BTC CORRELATION (for altcoins only) ===
            btc_correlation = context.get('btc_correlation')
            btc_aligned = context.get('btc_aligned')
            
            if btc_correlation is not None:
                if btc_aligned == False:
                    # Low correlation - independent move (can be risky)
                    warnings.append("‚ö†Ô∏è LOW BTC CORRELATION - Independent price action")
                    adjustment -= 10
                    logger.info(f"Context filter: Low BTC correlation ({btc_correlation:.2f}) (-10%)")
                elif btc_aligned == True:
                    # High correlation - trend confirmation
                    warnings.append("‚úÖ BTC ALIGNED - Trend confirmation")
                    adjustment += 10
                    logger.info(f"Context filter: High BTC correlation ({btc_correlation:.2f}) (+10%)")
            
            # === CALCULATE ADJUSTED CONFIDENCE ===
            adjusted_confidence = base_confidence + adjustment
            
            # Ensure confidence stays within 0-100 bounds
            adjusted_confidence = max(0.0, min(100.0, adjusted_confidence))
            
            # Log summary
            if adjustment != 0:
                logger.info(f"‚úÖ Context filters applied: {adjustment:+.1f}% adjustment")
                logger.info(f"   Base confidence: {base_confidence:.1f}% ‚Üí Adjusted: {adjusted_confidence:.1f}%")
            else:
                logger.info("‚úÖ Context filters: No adjustments needed")
            
            # ‚úÖ PR #3 FIX #4: Return both warnings and context info
            # Combine context_info into warnings for now (backward compatible)
            all_messages = warnings + context_info
            
            return adjusted_confidence, all_messages
            
        except Exception as e:
            logger.error(f"‚ùå Context filter error: {e}")
            # On error, return original confidence with no warnings
            return base_confidence, []
    
    def _extract_ml_features(
        self,
        df: pd.DataFrame,
        components: Dict,
        mtf_analysis: Optional[Dict],
        bias: 'MarketBias',
        displacement: bool,
        structure_break: bool
    ) -> Dict:
        """
        Extract ML features from ICT analysis
        
        CRITICAL: NO EMA/MACD/MA - ONLY ICT + NEUTRAL INDICATORS
        
        Returns:
            Dictionary of ML features
        """
        try:
            current_price = df['close'].iloc[-1]
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # NEUTRAL TECHNICAL INDICATORS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            # RSI
            if 'rsi' in df.columns:
                rsi = df['rsi'].iloc[-1]
            else:
                # Calculate RSI if not present
                # Note: .mean() here is legitimate - it's part of the standard RSI formula
                # (exponential smoothing of gains/losses), not a moving average for signals
                delta = df['close'].diff()
                gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
                loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
                rs = gain / loss.replace(0, 1)
                rsi = 100 - (100 / (1 + rs.iloc[-1]))
            
            # Volume metrics (use from dataframe - already calculated with median)
            if 'volume_ratio' in df.columns:
                volume_ratio = df['volume_ratio'].iloc[-1]
            else:
                # Fallback if not in dataframe
                volume_median = df['volume'].iloc[-20:].median()
                current_volume = df['volume'].iloc[-1]
                volume_ratio = current_volume / volume_median if volume_median > 0 else 1.0
            
            # Volatility (ATR-based)
            returns = df['close'].pct_change()
            volatility = returns.std() * 100
            
            # Price change
            price_change_pct = ((current_price - df['close'].iloc[-20]) / df['close'].iloc[-20]) * 100
            
            # Price position in 20-period range (Pure ICT - no MA/Bollinger)
            range_high = df['high'].iloc[-20:].max()
            range_low = df['low'].iloc[-20:].min()
            bb_position = (current_price - range_low) / (range_high - range_low) if (range_high - range_low) > 0 else 0.5
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # PURE ICT METRICS
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            num_order_blocks = len(components.get('order_blocks', []))
            num_fvgs = len(components.get('fvgs', []))
            num_whale_blocks = len(components.get('whale_blocks', []))
            num_liquidity_zones = len(components.get('liquidity_zones', []))
            num_ilp = len(components.get('internal_liquidity', []))
            
            # Calculate liquidity strength
            liquidity_strength = 0.0
            for liq_zone in components.get('liquidity_zones', []):
                if hasattr(liq_zone, 'strength'):
                    liquidity_strength += liq_zone.strength
            liquidity_strength = liquidity_strength / max(num_liquidity_zones, 1)
            
            # MTF confluence
            mtf_confluence = 0.0
            if mtf_analysis:
                aligned_tfs = 0
                total_tfs = 0
                for tf, tf_data in mtf_analysis.items():
                    if isinstance(tf_data, dict) and 'bias' in tf_data:
                        total_tfs += 1
                        if tf_data['bias'] == bias:
                            aligned_tfs += 1
                mtf_confluence = aligned_tfs / max(total_tfs, 1)
            
            # Bias strength
            bias_strength = 1.0 if bias == MarketBias.BULLISH else -1.0 if bias == MarketBias.BEARISH else 0.0
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # CONSTRUCT FEATURE DICT
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            features = {
                # Technical indicators (for ml_engine compatibility)
                'rsi': rsi,
                'price_change_pct': price_change_pct,
                'volume_ratio': volume_ratio,
                'volatility': volatility,
                'bb_position': bb_position,
                'ict_confidence': 0.5,  # Will be updated after confidence calculation
                
                # ICT-specific features
                'num_order_blocks': num_order_blocks,
                'num_fvgs': num_fvgs,
                'num_whale_blocks': num_whale_blocks,
                'num_liquidity_zones': num_liquidity_zones,
                'num_ilp': num_ilp,
                'liquidity_strength': liquidity_strength,
                'mtf_confluence': mtf_confluence,
                'bias_strength': bias_strength,
                'displacement_detected': 1 if displacement else 0,
                'structure_break_detected': 1 if structure_break else 0,
                
                # Market context (TODO: Implement if needed for ML models)
                'btc_correlation': 0.0,  # Placeholder - correlation with BTC price movement
                'sentiment_score': 0.0,  # Placeholder - news/social sentiment score
            }
            
            return features
            
        except Exception as e:
            logger.error(f"‚ùå ML feature extraction error: {e}")
            return {}
    
    def _apply_ml_optimization(
        self,
        entry_price: float,
        stop_loss: float,
        take_profit: List[float],
        ml_features: Dict,
        bias: 'MarketBias',
        components: Dict
    ) -> Tuple[float, float, List[float]]:
        """
        Apply ML-based optimization to Entry/SL/TP
        
        CRITICAL RULES:
        - Entry can be adjusted ¬±0.5% max
        - SL can ONLY move AWAY from entry (more conservative)
        - BULLISH: SL stays –ü–û–î Order Block
        - BEARISH: SL stays –ù–ê–î Order Block
        - TP can be extended based on liquidity zones
        - NEVER violates ICT Order Block placement
        
        Returns:
            (optimized_entry, optimized_sl, optimized_tp_list)
        """
        try:
            optimized_entry = entry_price
            optimized_sl = stop_loss
            optimized_tp = take_profit.copy()
            
            # Get ML confidence metrics
            ml_confidence = ml_features.get('ict_confidence', 0.5) * 100
            liquidity_strength = ml_features.get('liquidity_strength', 0.0)
            mtf_confluence = ml_features.get('mtf_confluence', 0.0)
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 1. ENTRY OPTIMIZATION (¬±0.5% max)
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            if ml_confidence > 80 and mtf_confluence > 0.6:
                # Find closest OB to current entry
                order_blocks = components.get('order_blocks', [])
                
                best_entry_zone = None
                min_distance = float('inf')
                
                for ob in order_blocks:
                    if hasattr(ob, 'zone_high') and hasattr(ob, 'zone_low'):
                        ob_mid = (ob.zone_high + ob.zone_low) / 2
                        distance = abs(ob_mid - entry_price) / entry_price
                        
                        # Only consider OBs within 0.5% of entry
                        if distance < 0.005 and distance < min_distance:
                            # Check if OB aligns with bias
                            if bias == MarketBias.BULLISH and hasattr(ob, 'type') and 'BULLISH' in str(ob.type.value):
                                best_entry_zone = ob_mid
                                min_distance = distance
                            elif bias == MarketBias.BEARISH and hasattr(ob, 'type') and 'BEARISH' in str(ob.type.value):
                                best_entry_zone = ob_mid
                                min_distance = distance
                
                if best_entry_zone is not None:
                    logger.info(f"üéØ ML optimizing entry: {entry_price:.2f} ‚Üí {best_entry_zone:.2f}")
                    optimized_entry = best_entry_zone
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 2. STOP LOSS OPTIMIZATION
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            # If ML confidence is LOW, widen SL
            if ml_confidence < 60:
                sl_distance = abs(stop_loss - entry_price)
                new_sl_distance = sl_distance * 1.1
                
                if bias == MarketBias.BULLISH:
                    optimized_sl = optimized_entry - new_sl_distance  # –ü–û–î entry
                else:
                    optimized_sl = optimized_entry + new_sl_distance  # –ù–ê–î entry
                
                logger.info(f"üõ°Ô∏è ML widening SL due to low confidence: {stop_loss:.2f} ‚Üí {optimized_sl:.2f}")
            
            # If ML confidence is HIGH, tighten SL (but never closer than nearest OB)
            elif ml_confidence > 85 and liquidity_strength > 0.7:
                order_blocks = components.get('order_blocks', [])
                
                # Find nearest OB in SL direction
                nearest_ob_distance = float('inf')
                
                for ob in order_blocks:
                    if hasattr(ob, 'zone_high') and hasattr(ob, 'zone_low'):
                        
                        if bias == MarketBias.BULLISH:
                            # BULLISH: Check OB below entry (SL should be –ü–û–î OB)
                            ob_edge = ob.zone_low  # Bottom of OB
                            
                            if ob_edge < entry_price:  # OB is below entry
                                distance = abs(entry_price - ob_edge)
                                nearest_ob_distance = min(nearest_ob_distance, distance)
                        
                        elif bias == MarketBias.BEARISH:
                            # BEARISH: Check OB above entry (SL should be –ù–ê–î OB)
                            ob_edge = ob.zone_high  # Top of OB
                            
                            if ob_edge > entry_price:  # OB is above entry
                                distance = abs(ob_edge - entry_price)
                                nearest_ob_distance = min(nearest_ob_distance, distance)
                
                # Tighten SL, but NOT closer than OB + 5% buffer
                sl_distance = abs(stop_loss - entry_price)
                new_sl_distance = max(
                    sl_distance * 0.95,              # Tighten by 5%
                    nearest_ob_distance * 1.05       # BUT keep 5% beyond OB
                )
                
                if bias == MarketBias.BULLISH:
                    optimized_sl = optimized_entry - new_sl_distance  # –ü–û–î entry
                else:
                    optimized_sl = optimized_entry + new_sl_distance  # –ù–ê–î entry
                
                logger.info(f"üéØ ML tightening SL: {stop_loss:.2f} ‚Üí {optimized_sl:.2f}")
                logger.info(f"   (Keeping SL {'–ü–û–î' if bias == MarketBias.BULLISH else '–ù–ê–î'} nearest OB)")
            
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            # 3. TAKE PROFIT OPTIMIZATION
            # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
            
            if liquidity_strength > 0.6:
                liquidity_zones = components.get('liquidity_zones', [])
                
                for i, tp in enumerate(take_profit):
                    extended_tp = tp
                    
                    for liq_zone in liquidity_zones:
                        if hasattr(liq_zone, 'price_level'):
                            liq_price = liq_zone.price_level
                            
                            # Check if liquidity is in profit direction
                            if bias == MarketBias.BULLISH and liq_price > tp and liq_price < tp * 1.15:
                                extended_tp = max(extended_tp, liq_price)
                            elif bias == MarketBias.BEARISH and liq_price < tp and liq_price > tp * 0.85:
                                extended_tp = min(extended_tp, liq_price)
                    
                    if extended_tp != tp:
                        logger.info(f"üíé ML extending TP{i+1}: {tp:.2f} ‚Üí {extended_tp:.2f} (liquidity target)")
                        optimized_tp[i] = extended_tp
            
            return optimized_entry, optimized_sl, optimized_tp
            
        except Exception as e:
            logger.error(f"‚ùå ML optimization error: {e}")
            return entry_price, stop_loss, take_profit
    
    def _get_htf_bias_with_fallback(self, symbol: str, mtf_data: Optional[Dict]) -> str:
        """
        –ó–ê–î–™–õ–ñ–ò–¢–ï–õ–ù–û: –ü–æ–ª—É—á–∞–≤–∞ HTF bias –æ—Ç 1D ‚Üí 4H fallback
        """
        if mtf_data is None or not isinstance(mtf_data, dict):
            logger.warning("No MTF data available, using NEUTRAL bias")
            return 'NEUTRAL'
        
        try:
            # –û–ø–∏—Ç 1: 1D timeframe (HTF)
            if '1d' in mtf_data or '1D' in mtf_data:
                df_1d = mtf_data.get('1d') if mtf_data.get('1d') is not None else mtf_data.get('1D')
                if df_1d is not None and not df_1d.empty and len(df_1d) >= 20:
                    # Determine bias from 1D
                    bias_components = self._detect_ict_components(df_1d, '1d')
                    htf_bias = self._determine_market_bias(df_1d, bias_components, None)
                    htf_bias_str = htf_bias.value if hasattr(htf_bias, 'value') else str(htf_bias)
                    logger.info(f"‚úÖ HTF Bias from 1D: {htf_bias_str}")
                    return htf_bias_str
            
            # –û–ø–∏—Ç 2: 4H timeframe (fallback)
            logger.warning("‚ö†Ô∏è 1D bias failed, trying 4H fallback...")
            if '4h' in mtf_data or '4H' in mtf_data:
                df_4h = mtf_data.get('4h') if mtf_data.get('4h') is not None else mtf_data.get('4H')
                if df_4h is not None and not df_4h.empty and len(df_4h) >= 20:
                    bias_components = self._detect_ict_components(df_4h, '4h')
                    htf_bias = self._determine_market_bias(df_4h, bias_components, None)
                    htf_bias_str = htf_bias.value if hasattr(htf_bias, 'value') else str(htf_bias)
                    logger.info(f"‚úÖ HTF Bias from 4H (fallback): {htf_bias_str}")
                    return htf_bias_str
            
            logger.warning("‚ùå No HTF data available, using NEUTRAL bias")
            return 'NEUTRAL'
            
        except Exception as e:
            logger.error(f"HTF bias error: {e}, defaulting to NEUTRAL")
            return 'NEUTRAL'
    
    def format_13_point_output(self, signal: ICTSignal, df: pd.DataFrame) -> Dict:
        """
        Format signal as comprehensive 13-point output structure
        
        Args:
            signal: ICTSignal object
            df: OHLCV DataFrame
            
        Returns:
            Dictionary with 13 comprehensive analysis points
        """
        try:
            current_price = df['close'].iloc[-1]
            
            # Get primary order block for SL validation
            primary_ob = signal.order_blocks[0] if signal.order_blocks else None
            
            # Validate SL positioning
            sl_compliant, sl_reason = self._validate_sl_under_over_ob(signal, primary_ob)
            
            output = {
                '1_mtf_bias': {
                    'htf_bias': signal.htf_bias,
                    'mtf_structure': signal.mtf_structure,
                    'confluence_score': signal.mtf_confluence,
                    'bias_description': f"{signal.htf_bias} bias with {signal.mtf_confluence}/5 confluence"
                },
                
                '2_liquidity_map': {
                    'total_zones': len(signal.liquidity_zones),
                    'zones': signal.liquidity_zones[:5],  # Top 5
                    'sweeps_detected': len(signal.liquidity_sweeps),
                    'next_target': signal.liquidity_zones[0] if signal.liquidity_zones else None
                },
                
                '3_ict_zones': {
                    'whale_blocks': len(signal.whale_blocks),
                    'order_blocks': len(signal.order_blocks),
                    'fair_value_gaps': len(signal.fair_value_gaps),
                    'internal_liquidity': len(signal.internal_liquidity),
                    'breaker_blocks': len(signal.breaker_blocks),
                    'mitigation_blocks': len(signal.mitigation_blocks),
                    'sibi_ssib': len(signal.sibi_ssib_zones)
                },
                
                '4_order_blocks_detail': [
                    self._format_order_block(ob) for ob in signal.order_blocks[:3]
                ],
                
                '5_fvg_analysis': {
                    'total_fvgs': len(signal.fair_value_gaps),
                    'bullish_fvgs': sum(1 for fvg in signal.fair_value_gaps if 'BULLISH' in str(fvg.get('type', ''))),
                    'bearish_fvgs': sum(1 for fvg in signal.fair_value_gaps if 'BEARISH' in str(fvg.get('type', ''))),
                    'nearest_fvg': signal.fair_value_gaps[0] if signal.fair_value_gaps else None
                },
                
                '6_luxalgo_sr': {
                    'support_zones': len(signal.luxalgo_sr.get('support_zones', [])),
                    'resistance_zones': len(signal.luxalgo_sr.get('resistance_zones', [])),
                    'price_near_sr': self._check_price_near_sr(current_price, signal.luxalgo_sr),
                    'entry_valid': signal.luxalgo_combined.get('entry_valid', False),
                    'luxalgo_bias': signal.luxalgo_combined.get('bias', 'neutral')
                },
                
                '7_fibonacci': {
                    'in_ote_zone': signal.fibonacci_data.get('in_ote_zone', False),
                    'swing_high': signal.fibonacci_data.get('swing_high'),
                    'swing_low': signal.fibonacci_data.get('swing_low'),
                    'ote_zone': signal.fibonacci_data.get('ote_zone'),
                    'nearest_level': signal.fibonacci_data.get('nearest_level'),
                    'retracements_count': len(signal.fibonacci_data.get('retracements', [])),
                    'extensions_count': len(signal.fibonacci_data.get('extensions', []))
                },
                
                '8_entry': {
                    'price': signal.entry_price,
                    'signal_type': signal.signal_type.value,
                    'confidence': signal.confidence,
                    'strength': signal.signal_strength.value,
                    'reasoning': signal.reasoning
                },
                
                '9_stop_loss': {
                    'price': signal.sl_price,
                    'reason': sl_reason,
                    'order_block_reference': self._get_sl_order_block(signal, primary_ob),
                    'ict_compliant': sl_compliant,
                    'distance_pct': abs((signal.sl_price - signal.entry_price) / signal.entry_price) * 100
                },
                
                '10_take_profit': {
                    'tp1': {
                        'price': signal.tp_prices[0] if signal.tp_prices else None,
                        'risk_reward': self._calculate_rr(signal, 0),
                        'distance_pct': abs((signal.tp_prices[0] - signal.entry_price) / signal.entry_price) * 100 if signal.tp_prices else 0
                    },
                    'tp2': {
                        'price': signal.tp_prices[1] if len(signal.tp_prices) > 1 else None,
                        'risk_reward': self._calculate_rr(signal, 1) if len(signal.tp_prices) > 1 else None,
                        'distance_pct': abs((signal.tp_prices[1] - signal.entry_price) / signal.entry_price) * 100 if len(signal.tp_prices) > 1 else None
                    } if len(signal.tp_prices) > 1 else None,
                    'tp3': {
                        'price': signal.tp_prices[2] if len(signal.tp_prices) > 2 else None,
                        'risk_reward': self._calculate_rr(signal, 2) if len(signal.tp_prices) > 2 else None,
                        'distance_pct': abs((signal.tp_prices[2] - signal.entry_price) / signal.entry_price) * 100 if len(signal.tp_prices) > 2 else None
                    } if len(signal.tp_prices) > 2 else None,
                    'risk_reward_ratio': signal.risk_reward_ratio,
                    'min_rr_guaranteed': 3.0,
                    'rr_compliance': 'COMPLIANT' if signal.risk_reward_ratio >= 3.0 else f'NON_COMPLIANT (RR: {signal.risk_reward_ratio:.2f})'
                },
                
                '11_mtf_structure': {
                    'htf_trend': signal.htf_bias,
                    'mtf_structure': signal.mtf_structure,
                    'structure_broken': signal.structure_broken,
                    'displacement_detected': signal.displacement_detected,
                    'alignment_score': signal.mtf_confluence
                },
                
                '12_next_liquidity_forecast': {
                    'nearest_liquidity': signal.liquidity_zones[0] if signal.liquidity_zones else None,
                    'target_type': 'BUY_SIDE' if (hasattr(signal.bias, 'value') and signal.bias.value == 'BULLISH') else 'SELL_SIDE',
                    'estimated_distance': self._calculate_liquidity_distance(current_price, signal.liquidity_zones)
                },
                
                '13_ml_optimization': {
                    'ml_available': self.ml_engine is not None or self.ml_predictor is not None,
                    'ml_used': signal.confidence > 50,  # Simplified check
                    'optimized_entry': signal.entry_price,
                    'optimized_sl': signal.sl_price,
                    'optimized_tps': signal.tp_prices
                },
                
                'chart_data': None,  # Will be populated by chart generator
                
                'analysis_sequence': {
                    'timestamp': signal.timestamp.isoformat() if isinstance(signal.timestamp, datetime) else str(signal.timestamp),
                    'timeframe': signal.timeframe,
                    'sequence_completed': True,
                    'steps_executed': 12
                }
            }
            
            logger.info("‚úÖ 13-point output formatted successfully")
            return output
            
        except Exception as e:
            logger.error(f"Error formatting 13-point output: {e}")
            return {}
    
    def _validate_sl_under_over_ob(self, signal: ICTSignal, order_block) -> Tuple[bool, str]:
        """
        Validate that SL is correctly positioned relative to Order Block
        
        Returns:
            Tuple of (is_compliant, reason_description)
        """
        if not order_block:
            return False, "No Order Block available for validation"
        
        try:
            # Get OB boundaries
            if isinstance(order_block, dict):
                ob_bottom = order_block.get('zone_low') or order_block.get('bottom')
                ob_top = order_block.get('zone_high') or order_block.get('top')
            else:
                ob_bottom = getattr(order_block, 'zone_low', None) or getattr(order_block, 'bottom', None)
                ob_top = getattr(order_block, 'zone_high', None) or getattr(order_block, 'top', None)
            
            if not ob_bottom or not ob_top:
                return False, "Invalid Order Block structure"
            
            # Check compliance based on bias
            bias_str = signal.bias.value if hasattr(signal.bias, 'value') else str(signal.bias)
            
            if 'BULLISH' in bias_str.upper():
                # For bullish: SL must be BELOW Order Block
                if signal.sl_price < ob_bottom:
                    return True, f"SL correctly positioned below Order Block ({signal.sl_price:.2f} < {ob_bottom:.2f})"
                else:
                    return False, f"SL VIOLATION: SL {signal.sl_price:.2f} should be below OB bottom {ob_bottom:.2f}"
            
            elif 'BEARISH' in bias_str.upper():
                # For bearish: SL must be ABOVE Order Block
                if signal.sl_price > ob_top:
                    return True, f"SL correctly positioned above Order Block ({signal.sl_price:.2f} > {ob_top:.2f})"
                else:
                    return False, f"SL VIOLATION: SL {signal.sl_price:.2f} should be above OB top {ob_top:.2f}"
            
            return False, "Unknown bias for SL validation"
            
        except Exception as e:
            logger.error(f"SL validation error: {e}")
            return False, f"Validation error: {str(e)}"
    
    def _get_sl_order_block(self, signal: ICTSignal, order_block) -> Optional[Dict]:
        """Get Order Block reference used for SL calculation"""
        if not order_block:
            return None
        
        try:
            if isinstance(order_block, dict):
                return {
                    'zone_low': order_block.get('zone_low'),
                    'zone_high': order_block.get('zone_high'),
                    'type': order_block.get('type')
                }
            else:
                return {
                    'zone_low': getattr(order_block, 'zone_low', None),
                    'zone_high': getattr(order_block, 'zone_high', None),
                    'type': str(getattr(order_block, 'type', None))
                }
        except Exception as e:
            logger.error(f"Error getting SL Order Block: {e}")
            return None
    
    def _calculate_rr(self, signal: ICTSignal, tp_index: int) -> Optional[float]:
        """Calculate Risk/Reward ratio for specific TP level"""
        if tp_index >= len(signal.tp_prices):
            return None
        
        try:
            tp = signal.tp_prices[tp_index]
            risk = abs(signal.entry_price - signal.sl_price)
            reward = abs(tp - signal.entry_price)
            
            if risk == 0:
                return None
            
            return reward / risk
            
        except Exception as e:
            logger.error(f"Error calculating RR: {e}")
            return None
    
    def _format_order_block(self, ob) -> Dict:
        """Format Order Block for output"""
        try:
            if isinstance(ob, dict):
                return {
                    'zone_low': ob.get('zone_low'),
                    'zone_high': ob.get('zone_high'),
                    'type': ob.get('type'),
                    'strength': ob.get('strength', 'MEDIUM')
                }
            else:
                return {
                    'zone_low': getattr(ob, 'zone_low', None),
                    'zone_high': getattr(ob, 'zone_high', None),
                    'type': str(getattr(ob, 'type', None)),
                    'strength': getattr(ob, 'strength', 'MEDIUM')
                }
        except Exception as e:
            logger.error(f"Error formatting Order Block: {e}")
            return {}
    
    def _check_price_near_sr(self, price: float, luxalgo_sr: Dict) -> bool:
        """Check if price is near any S/R zone"""
        try:
            threshold = 0.02  # 2% threshold
            
            support_zones = luxalgo_sr.get('support_zones', [])
            resistance_zones = luxalgo_sr.get('resistance_zones', [])
            
            for zone in support_zones + resistance_zones:
                zone_price = zone.get('price', 0)
                if zone_price and abs(price - zone_price) / price < threshold:
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Error checking price near S/R: {e}")
            return False
    
    def _calculate_liquidity_distance(self, current_price: float, liquidity_zones: List) -> Optional[float]:
        """Calculate distance to nearest liquidity zone"""
        if not liquidity_zones:
            return None
        
        try:
            nearest_zone = liquidity_zones[0]
            zone_price = nearest_zone.get('price', nearest_zone.get('price_level', current_price))
            distance_pct = abs((zone_price - current_price) / current_price) * 100
            return distance_pct
            
        except Exception as e:
            logger.error(f"Error calculating liquidity distance: {e}")
            return None

    def _get_liquidity_zones_with_fallback(self, df: pd.DataFrame, symbol: str, timeframe: str) -> List:
        """
        –ó–ê–î–™–õ–ñ–ò–¢–ï–õ–ù–û: –û–ø–∏—Ç–≤–∞ fresh liquidity map, –°–ê–ú–û –ê–ö–û –ù–ï –µ –≥–æ—Ç–æ–≤–∞ ‚Üí cache
        """
        try:
            # –û–ø–∏—Ç 1: Fresh liquidity map
            if hasattr(self, 'liquidity_mapper') and self.liquidity_mapper:
                try:
                    liquidity_zones = self.liquidity_mapper.detect_liquidity_zones(df, timeframe)
                    if liquidity_zones:
                        logger.info(f"‚úÖ Fresh liquidity map: {len(liquidity_zones)} zones")
                        return liquidity_zones
                except Exception as e:
                    logger.warning(f"Fresh liquidity map failed: {e}")
            
            # –û–ø–∏—Ç 2: Cache fallback
            if self.cache_manager:
                cached_zones = self.cache_manager.get(f"liquidity_zones_{symbol}_{timeframe}")
                if cached_zones:
                    logger.warning(f"‚ö†Ô∏è Using CACHED liquidity zones for {symbol} {timeframe}")
                    return cached_zones
            
            logger.warning(f"‚ùå No liquidity zones available for {symbol} {timeframe}")
            return []
            
        except Exception as e:
            logger.error(f"Liquidity zones error: {e}")
            return []
    
    def _fetch_btc_data(
        self,
        start_time: datetime,
        end_time: datetime,
        timeframe: str = '1h'
    ) -> Optional[pd.DataFrame]:
        """
        Fetch BTC price data for correlation calculation
        
        Args:
            start_time: Start datetime
            end_time: End datetime
            timeframe: Candle timeframe (default: 1h)
            
        Returns:
            DataFrame with BTC OHLCV data or None if fetch fails
        """
        try:
            # Import requests here to handle missing dependency gracefully
            # This allows the engine to work without requests if BTC correlation is not needed
            import requests
            
            # Convert datetime to milliseconds
            start_ms = int(start_time.timestamp() * 1000)
            end_ms = int(end_time.timestamp() * 1000)
            
            # Binance timeframe mapping
            tf_map = {
                '1m': '1m',
                '3m': '3m',
                '5m': '5m',
                '15m': '15m',
                '30m': '30m',
                '1h': '1h',
                '2h': '2h',
                '4h': '4h',
                '6h': '6h',
                '12h': '12h',
                '1d': '1d',
                '3d': '3d',
                '1w': '1w',
            }
            
            interval = tf_map.get(timeframe.lower(), '1h')
            
            # Binance API endpoint
            url = "https://api.binance.com/api/v3/klines"
            params = {
                'symbol': 'BTCUSDT',
                'interval': interval,
                'startTime': start_ms,
                'endTime': end_ms,
                'limit': 500
            }
            
            # Fetch BTC klines
            response = requests.get(url, params=params, timeout=10)
            
            if response.status_code != 200:
                logger.warning(f"Binance API returned {response.status_code}")
                return None
            
            klines = response.json()
            
            if not klines:
                logger.warning("No BTC data returned from Binance")
                return None
            
            # Convert to DataFrame
            df = pd.DataFrame(klines, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_volume', 'trades', 'taker_buy_base',
                'taker_buy_quote', 'ignore'
            ])
            
            # Convert types
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['close'] = df['close'].astype(float)
            
            # Set index
            df = df.set_index('timestamp')
            
            logger.debug(f"‚úÖ Fetched {len(df)} BTC candles for correlation")
            return df[['close']]  # Return only close prices
            
        except ImportError as e:
            logger.warning(f"Required library not available - BTC correlation disabled: {e}")
            return None
        except Exception as e:
            logger.warning(f"BTC data fetch failed: {e}")
            return None
    
    def _calculate_btc_correlation(
        self,
        symbol: str,
        df: pd.DataFrame
    ) -> Tuple[Optional[float], Optional[bool]]:
        """
        Calculate correlation with BTC price movement
        
        Args:
            symbol: Trading pair symbol
            df: Price DataFrame with datetime index
            
        Returns:
            Tuple of (correlation, is_aligned)
            - correlation: Pearson correlation coefficient (-1 to 1) or None
            - is_aligned: True if |correlation| > 0.7, False if < 0.3, None otherwise
        """
        try:
            # Skip BTC itself
            if symbol.upper() in ['BTCUSDT', 'BTC', 'BTCUSD', 'BTCBUSD']:
                return None, None
            
            # Need at least 30 candles for meaningful correlation
            if len(df) < 30:
                logger.debug("Insufficient data for BTC correlation (need 30+ candles)")
                return None, None
            
            # Get time range from df
            start_time = df.index[0]
            end_time = df.index[-1]
            
            # Determine timeframe from df index frequency
            if len(df) >= 2:
                time_diff = (df.index[1] - df.index[0]).total_seconds() / 60
                if time_diff <= 1:
                    tf = '1m'
                elif time_diff <= 3:
                    tf = '3m'
                elif time_diff <= 5:
                    tf = '5m'
                elif time_diff <= 15:
                    tf = '15m'
                elif time_diff <= 30:
                    tf = '30m'
                elif time_diff <= 60:
                    tf = '1h'
                elif time_diff <= 240:
                    tf = '4h'
                else:
                    tf = '1d'
            else:
                tf = '1h'  # Default fallback
            
            # Fetch BTC data
            btc_df = self._fetch_btc_data(start_time, end_time, tf)
            
            if btc_df is None or len(btc_df) < 30:
                logger.debug("BTC data fetch failed or insufficient")
                return None, None
            
            # Align timestamps (merge on index)
            merged = df[['close']].merge(
                btc_df[['close']],
                left_index=True,
                right_index=True,
                how='inner',
                suffixes=('_asset', '_btc')
            )
            
            if len(merged) < 30:
                logger.debug(f"After merge, only {len(merged)} matching candles - insufficient")
                return None, None
            
            # Calculate percentage returns
            returns_df = merged.pct_change().dropna()
            
            # Ensure we still have enough data after dropna
            if len(returns_df) < 29:  # Need at least 29 returns for 30 candles
                logger.debug(f"After pct_change, only {len(returns_df)} returns - insufficient")
                return None, None
            
            asset_returns = returns_df['close_asset']
            btc_returns = returns_df['close_btc']
            
            # Calculate Pearson correlation
            correlation = asset_returns.corr(btc_returns)
            
            # Check if correlation is valid
            if pd.isna(correlation) or np.isinf(correlation):
                logger.debug("Correlation calculation returned NaN or Inf")
                return None, None
            
            # Determine alignment
            abs_corr = abs(correlation)
            if abs_corr > 0.7:
                is_aligned = True  # Strong correlation (following BTC)
            elif abs_corr < 0.3:
                is_aligned = False  # Weak correlation (independent move)
            else:
                is_aligned = None  # Moderate correlation (neutral)
            
            logger.info(f"‚úÖ BTC correlation for {symbol}: {correlation:.3f} (aligned: {is_aligned})")
            return correlation, is_aligned
            
        except Exception as e:
            logger.warning(f"BTC correlation calculation error: {e}")
            return None, None
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # PR #8 LAYER 2: STRUCTURE-AWARE TP PLACEMENT
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _find_obstacles_in_path(
        self,
        entry_price: float,
        target_price: float,
        direction: str,  # 'LONG' or 'SHORT'
        ict_components: Dict
    ) -> List[Dict]:
        """
        Scan for OPPOSING zones between Entry and Target (PR #8)
        
        For LONG: Find BEARISH zones (resistance)
        - Bearish Order Blocks
        - Bearish FVGs
        - Resistance levels (LuxAlgo S/R)
        - Bearish Whale Blocks
        
        For SHORT: Find BULLISH zones (support)
        - Bullish Order Blocks
        - Bullish FVGs
        - Support levels
        - Bullish Whale Blocks
        
        Args:
            entry_price: Entry price
            target_price: Target price (TP level)
            direction: 'LONG' or 'SHORT'
            ict_components: Dict with all ICT components
            
        Returns:
            List of obstacles sorted by proximity to entry:
            [
                {
                    'type': 'BEARISH_OB' | 'BEARISH_FVG' | 'RESISTANCE' | 'BEARISH_WHALE',
                    'price': float,
                    'strength': 0-100,
                    'description': 'Human-readable Bulgarian text'
                },
                ...
            ]
        """
        try:
            obstacles = []
            
            # Determine price range
            min_price = min(entry_price, target_price)
            max_price = max(entry_price, target_price)
            
            logger.info(f"üîç Scanning obstacles between ${min_price:.2f} and ${max_price:.2f}")
            
            # 1. Check Order Blocks
            order_blocks = ict_components.get('order_blocks', [])
            for ob in order_blocks:
                try:
                    # Get OB price and type
                    if hasattr(ob, 'price'):
                        ob_price = ob.price
                    elif isinstance(ob, dict):
                        ob_price = ob.get('price', 0)
                    else:
                        continue
                    
                    # Check if in range
                    if min_price <= ob_price <= max_price:
                        # Get OB type
                        if hasattr(ob, 'type'):
                            ob_type_str = str(ob.type.value) if hasattr(ob.type, 'value') else str(ob.type)
                        elif isinstance(ob, dict):
                            ob_type_str = ob.get('type', '')
                        else:
                            continue
                        
                        # Check if opposing
                        is_obstacle = False
                        obstacle_type = ''
                        
                        if direction == 'LONG' and 'BEARISH' in ob_type_str.upper():
                            is_obstacle = True
                            obstacle_type = 'BEARISH_OB'
                        elif direction == 'SHORT' and 'BULLISH' in ob_type_str.upper():
                            is_obstacle = True
                            obstacle_type = 'BULLISH_OB'
                        
                        if is_obstacle:
                            # Get strength from OB
                            strength = 70  # Default
                            if hasattr(ob, 'strength'):
                                strength = ob.strength
                            elif isinstance(ob, dict):
                                strength = ob.get('strength', 70)
                            
                            obstacles.append({
                                'type': obstacle_type,
                                'price': ob_price,
                                'strength': strength,
                                'description': '–ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª–Ω–∞ –∑–æ–Ω–∞' if obstacle_type == 'BEARISH_OB' else '–ò–Ω—Å—Ç–∏—Ç—É—Ü–∏–æ–Ω–∞–ª–Ω–∞ –ø–æ–¥–∫—Ä–µ–ø–∞',
                                'source': 'ORDER_BLOCK'
                            })
                            logger.debug(f"   Found obstacle: {obstacle_type} @ ${ob_price:.2f} (strength: {strength})")
                except Exception as e:
                    logger.debug(f"Error processing order block: {e}")
                    continue
            
            # 2. Check FVGs
            fvgs = ict_components.get('fvgs', [])
            for fvg in fvgs:
                try:
                    # Get FVG price (center)
                    if hasattr(fvg, 'high') and hasattr(fvg, 'low'):
                        fvg_price = (fvg.high + fvg.low) / 2
                    elif isinstance(fvg, dict):
                        fvg_high = fvg.get('high', 0)
                        fvg_low = fvg.get('low', 0)
                        fvg_price = (fvg_high + fvg_low) / 2 if fvg_high and fvg_low else 0
                    else:
                        continue
                    
                    if not fvg_price:
                        continue
                    
                    # Check if in range
                    if min_price <= fvg_price <= max_price:
                        # Check if opposing
                        is_bullish = False
                        if hasattr(fvg, 'is_bullish'):
                            is_bullish = fvg.is_bullish
                        elif isinstance(fvg, dict):
                            is_bullish = fvg.get('is_bullish', False)
                        
                        is_obstacle = False
                        obstacle_type = ''
                        
                        if direction == 'LONG' and not is_bullish:
                            is_obstacle = True
                            obstacle_type = 'BEARISH_FVG'
                        elif direction == 'SHORT' and is_bullish:
                            is_obstacle = True
                            obstacle_type = 'BULLISH_FVG'
                        
                        if is_obstacle:
                            # FVG strength based on gap size
                            strength = 60  # Default
                            if hasattr(fvg, 'strength'):
                                strength = fvg.strength
                            elif isinstance(fvg, dict):
                                strength = fvg.get('strength', 60)
                            
                            obstacles.append({
                                'type': obstacle_type,
                                'price': fvg_price,
                                'strength': strength,
                                'description': 'Fair Value Gap –∑–æ–Ω–∞',
                                'source': 'FVG'
                            })
                            logger.debug(f"   Found obstacle: {obstacle_type} @ ${fvg_price:.2f} (strength: {strength})")
                except Exception as e:
                    logger.debug(f"Error processing FVG: {e}")
                    continue
            
            # 3. Check Support/Resistance (LuxAlgo)
            luxalgo_sr = ict_components.get('luxalgo_sr', {})
            if luxalgo_sr:
                try:
                    # For LONG, check resistance zones
                    if direction == 'LONG':
                        resistance_zones = luxalgo_sr.get('resistance_zones', [])
                        for zone in resistance_zones:
                            zone_price = zone.get('price', 0)
                            if zone_price and min_price <= zone_price <= max_price:
                                strength = zone.get('strength', 65)
                                obstacles.append({
                                    'type': 'RESISTANCE',
                                    'price': zone_price,
                                    'strength': strength,
                                    'description': '–°—ä–ø—Ä–æ—Ç–∏–≤–∞ (LuxAlgo)',
                                    'source': 'LUXALGO_SR'
                                })
                                logger.debug(f"   Found obstacle: RESISTANCE @ ${zone_price:.2f} (strength: {strength})")
                    
                    # For SHORT, check support zones
                    elif direction == 'SHORT':
                        support_zones = luxalgo_sr.get('support_zones', [])
                        for zone in support_zones:
                            zone_price = zone.get('price', 0)
                            if zone_price and min_price <= zone_price <= max_price:
                                strength = zone.get('strength', 65)
                                obstacles.append({
                                    'type': 'SUPPORT',
                                    'price': zone_price,
                                    'strength': strength,
                                    'description': '–ü–æ–¥–∫—Ä–µ–ø–∞ (LuxAlgo)',
                                    'source': 'LUXALGO_SR'
                                })
                                logger.debug(f"   Found obstacle: SUPPORT @ ${zone_price:.2f} (strength: {strength})")
                except Exception as e:
                    logger.debug(f"Error processing LuxAlgo S/R: {e}")
            
            # 4. Check Whale Blocks
            whale_blocks = ict_components.get('whale_blocks', [])
            for wb in whale_blocks:
                try:
                    # Get whale block price
                    if hasattr(wb, 'price'):
                        wb_price = wb.price
                    elif isinstance(wb, dict):
                        wb_price = wb.get('price', 0)
                    else:
                        continue
                    
                    if not wb_price:
                        continue
                    
                    # Check if in range
                    if min_price <= wb_price <= max_price:
                        # Get whale block type
                        if hasattr(wb, 'block_type'):
                            wb_type_str = str(wb.block_type.value) if hasattr(wb.block_type, 'value') else str(wb.block_type)
                        elif isinstance(wb, dict):
                            wb_type_str = wb.get('block_type', '')
                        else:
                            continue
                        
                        # Check if opposing
                        is_obstacle = False
                        obstacle_type = ''
                        
                        if direction == 'LONG' and 'BEARISH' in wb_type_str.upper():
                            is_obstacle = True
                            obstacle_type = 'BEARISH_WHALE'
                        elif direction == 'SHORT' and 'BULLISH' in wb_type_str.upper():
                            is_obstacle = True
                            obstacle_type = 'BULLISH_WHALE'
                        
                        if is_obstacle:
                            # Whale blocks are typically stronger
                            strength = 80  # Default high strength
                            if hasattr(wb, 'strength'):
                                strength = wb.strength
                            elif isinstance(wb, dict):
                                strength = wb.get('strength', 80)
                            
                            obstacles.append({
                                'type': obstacle_type,
                                'price': wb_price,
                                'strength': strength,
                                'description': 'Whale Institution Block',
                                'source': 'WHALE_BLOCK'
                            })
                            logger.debug(f"   Found obstacle: {obstacle_type} @ ${wb_price:.2f} (strength: {strength})")
                except Exception as e:
                    logger.debug(f"Error processing whale block: {e}")
                    continue
            
            # Sort obstacles by proximity to entry price
            obstacles.sort(key=lambda x: abs(x['price'] - entry_price))
            
            logger.info(f"   Found {len(obstacles)} obstacles in path")
            
            return obstacles
            
        except Exception as e:
            logger.error(f"Error finding obstacles in path from ${entry_price:.2f} to ${target_price:.2f}: {type(e).__name__}: {str(e)}")
            import traceback
            logger.debug(f"Obstacle detection traceback: {traceback.format_exc()}")
            return []
    
    def _evaluate_obstacle_strength(
        self,
        obstacle: Dict,
        context: Dict  # Contains HTF bias, displacement, etc.
    ) -> Dict:
        """
        Evaluate obstacle and predict market reaction (PR #8)
        
        Scoring System (0-100):
        - Base strength: From detector (volume, candle size, age)
        - HTF bias alignment: +20 if aligned, -20 if against
        - Displacement: -15 if strong momentum in our direction
        - Retest history: +10 if tested 2+ times
        - Volume profile: +/-10 based on volume strength
        - Zone age: -5 if > 100 candles old
        - MTF confirmation: +15 if confirmed on multiple TFs
        
        Decision Thresholds:
        - Strength >= 75: "–ú–ù–û–ì–û –í–ï–†–û–Ø–¢–ù–û –û–¢–ë–õ–™–°–ö–í–ê–ù–ï" (85% confidence)
        - Strength 60-74: "–í–ï–†–û–Ø–¢–ù–û –û–¢–ë–õ–™–°–ö–í–ê–ù–ï" (70% confidence)
        - Strength 45-59: "–ù–ï–°–ò–ì–£–†–ù–û" (50% confidence)
        - Strength < 45: "–í–ï–†–û–Ø–¢–ù–û –ü–†–û–ë–ò–í–ê–ù–ï" (70% confidence)
        
        Args:
            obstacle: Obstacle dict with type, price, strength, description
            context: Context dict with HTF bias, displacement, direction
            
        Returns:
            {
                'strength': 0-100,
                'will_likely_reject': True/False,
                'confidence': 0-100,
                'decision': 'Bulgarian text',
                'reasoning': 'Detailed explanation in Bulgarian'
            }
        """
        try:
            # Start with base strength from detector
            base_strength = obstacle.get('strength', 50)
            adjusted_strength = float(base_strength)
            
            reasoning_parts = []
            
            # 1. HTF bias alignment
            htf_bias = context.get('htf_bias', 'NEUTRAL')
            direction = context.get('direction', 'LONG')
            obstacle_type = obstacle.get('type', '')
            
            if htf_bias != 'NEUTRAL':
                if (direction == 'LONG' and 'BEARISH' in obstacle_type and htf_bias == 'BEARISH') or \
                   (direction == 'SHORT' and 'BULLISH' in obstacle_type and htf_bias == 'BULLISH'):
                    # HTF supports obstacle (stronger)
                    adjusted_strength += 20
                    reasoning_parts.append("HTF bias –ø–æ–¥–∫—Ä–µ–ø—è –∑–æ–Ω–∞—Ç–∞ ‚ö†Ô∏è")
                else:
                    # HTF against obstacle (weaker)
                    adjusted_strength -= 20
                    reasoning_parts.append("HTF bias –µ —Å—Ä–µ—â—É –∑–æ–Ω–∞—Ç–∞ ‚úÖ")
            
            # 2. Displacement check
            displacement_detected = context.get('displacement_detected', False)
            if displacement_detected:
                adjusted_strength -= 15
                reasoning_parts.append("–°–∏–ª–µ–Ω momentum –≤ –Ω–∞—à–∞—Ç–∞ –ø–æ—Å–æ–∫–∞ ‚úÖ")
            
            # 3. Volume (if available from obstacle)
            if obstacle.get('volume_strength', 0) > 1.5:
                adjusted_strength += 10
                reasoning_parts.append("–í–∏—Å–æ–∫ volume –≤ –∑–æ–Ω–∞—Ç–∞ ‚ö†Ô∏è")
            elif obstacle.get('volume_strength', 0) < 0.7:
                adjusted_strength -= 10
                reasoning_parts.append("–ù–∏—Å—ä–∫ volume –≤ –∑–æ–Ω–∞—Ç–∞ ‚úÖ")
            
            # 4. MTF confirmation (simplified - check if obstacle source is multi-TF)
            if 'mtf_confluence' in context and context['mtf_confluence'] > 2:
                adjusted_strength += 15
                reasoning_parts.append("MTF –ø–æ—Ç–≤—ä—Ä–∂–¥–µ–Ω–∏–µ (4H+1D) ‚ö†Ô∏è")
            
            # Clamp to 0-100
            adjusted_strength = max(0, min(100, adjusted_strength))
            
            # Determine decision and confidence
            from config.trading_config import get_trading_config
            config = get_trading_config()
            
            very_strong_threshold = config.get('very_strong_obstacle', 75)
            strong_threshold = config.get('strong_obstacle', 60)
            moderate_threshold = config.get('moderate_obstacle', 45)
            
            will_reject = False
            confidence = 50
            decision = ""
            
            if adjusted_strength >= very_strong_threshold:
                will_reject = True
                confidence = 85
                decision = "–ú–ù–û–ì–û –í–ï–†–û–Ø–¢–ù–û –û–¢–ë–õ–™–°–ö–í–ê–ù–ï"
                reasoning_parts.append("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –°–∏–ª–Ω–∞ —Å—ä–ø—Ä–æ—Ç–∏–≤–∞, —â–µ –æ—Ç–±–ª—ä—Å–Ω–µ")
            elif adjusted_strength >= strong_threshold:
                will_reject = True
                confidence = 70
                decision = "–í–ï–†–û–Ø–¢–ù–û –û–¢–ë–õ–™–°–ö–í–ê–ù–ï"
                reasoning_parts.append("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –í–µ—Ä–æ—è—Ç–Ω–∞ —Å—ä–ø—Ä–æ—Ç–∏–≤–∞")
            elif adjusted_strength >= moderate_threshold:
                will_reject = False
                confidence = 50
                decision = "–ù–ï–°–ò–ì–£–†–ù–û"
                reasoning_parts.append("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –ù–µ—Å–∏–≥—É—Ä–Ω–∞ –∑–æ–Ω–∞")
            else:
                will_reject = False
                confidence = 70
                decision = "–í–ï–†–û–Ø–¢–ù–û –ü–†–û–ë–ò–í–ê–ù–ï"
                reasoning_parts.append("–ó–∞–∫–ª—é—á–µ–Ω–∏–µ: –°–ª–∞–±–∞ –∑–æ–Ω–∞, –≤–µ—Ä–æ—è—Ç–Ω–æ —â–µ –ø—Ä–æ–±–∏–µ")
            
            reasoning = '\n'.join(reasoning_parts)
            
            return {
                'strength': adjusted_strength,
                'will_likely_reject': will_reject,
                'confidence': confidence,
                'decision': decision,
                'reasoning': reasoning
            }
            
        except Exception as e:
            logger.error(f"Error evaluating obstacle: {e}")
            # Return neutral evaluation on error
            return {
                'strength': 50,
                'will_likely_reject': False,
                'confidence': 50,
                'decision': '–ù–ï–°–ò–ì–£–†–ù–û',
                'reasoning': '–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–∞'
            }
    
    def _calculate_smart_tp_with_structure_validation(
        self,
        entry_price: float,
        sl_price: float,  # NEVER modified
        direction: str,  # 'LONG' or 'SHORT'
        ict_components: Dict,
        timeframe: str
    ) -> List[float]:
        """
        Calculate structure-aware TPs (PR #8 Layer 2)
        
        CRITICAL RULES:
        - SL is NEVER modified ‚úÖ
        - Entry is NEVER modified ‚úÖ
        - Only TP is adjusted based on obstacles
        - Min RR must still be met (2.5:1 minimum)
        
        Process:
        1. Calculate mathematical TPs (Risk √ó 3, √ó 5, √ó 8)
        2. Scan obstacles between Entry and TP3
        3. Evaluate each obstacle strength
        4. For each TP level:
           a. Check if obstacle in path
           b. If obstacle weak (< 45): Place TP AFTER obstacle
           c. If obstacle strong (>= 75): Place TP BEFORE obstacle (0.3% buffer)
           d. Validate RR still meets minimum
           e. If RR fails: Keep mathematical TP + add warning
        5. Return adjusted TPs
        
        Args:
            entry_price: Entry price (fixed)
            sl_price: Stop loss price (fixed)
            direction: 'LONG' or 'SHORT'
            ict_components: ICT components dict
            timeframe: Timeframe
            
        Returns:
            [tp1, tp2, tp3] with smart positioning
        """
        try:
            # Load config
            from config.trading_config import get_trading_config
            config = get_trading_config()
            
            # Check if structure TP is enabled
            if not config.get('use_structure_tp', True):
                logger.info("üìä Structure TP disabled - using mathematical TPs")
                # Fallback to mathematical TPs
                risk = abs(entry_price - sl_price)
                tp1_mult, tp2_mult, tp3_mult = get_tp_multipliers_by_timeframe(timeframe)
                
                if direction == 'LONG':
                    return [
                        entry_price + (risk * tp1_mult),
                        entry_price + (risk * tp2_mult),
                        entry_price + (risk * tp3_mult)
                    ]
                else:
                    return [
                        entry_price - (risk * tp1_mult),
                        entry_price - (risk * tp2_mult),
                        entry_price - (risk * tp3_mult)
                    ]
            
            # Step 1: Calculate mathematical TPs
            risk = abs(entry_price - sl_price)
            tp1_mult, tp2_mult, tp3_mult = get_tp_multipliers_by_timeframe(timeframe)
            
            if direction == 'LONG':
                math_tp1 = entry_price + (risk * tp1_mult)
                math_tp2 = entry_price + (risk * tp2_mult)
                math_tp3 = entry_price + (risk * tp3_mult)
            else:
                math_tp1 = entry_price - (risk * tp1_mult)
                math_tp2 = entry_price - (risk * tp2_mult)
                math_tp3 = entry_price - (risk * tp3_mult)
            
            logger.info(f"üìä Mathematical TPs: TP1=${math_tp1:.2f}, TP2=${math_tp2:.2f}, TP3=${math_tp3:.2f}")
            
            # Step 2: Scan obstacles between Entry and TP3
            max_tp = max(math_tp1, math_tp2, math_tp3) if direction == 'LONG' else min(math_tp1, math_tp2, math_tp3)
            obstacles = self._find_obstacles_in_path(
                entry_price=entry_price,
                target_price=max_tp,
                direction=direction,
                ict_components=ict_components
            )
            
            if not obstacles:
                logger.info("‚úÖ No obstacles found - using mathematical TPs")
                return [math_tp1, math_tp2, math_tp3]
            
            # Step 3 & 4: Evaluate obstacles and adjust TPs
            logger.info(f"üîç Evaluating {len(obstacles)} obstacles for TP adjustment")
            
            # Build context for obstacle evaluation
            context = {
                'direction': direction,
                'htf_bias': ict_components.get('htf_bias', 'NEUTRAL'),
                'displacement_detected': ict_components.get('displacement_detected', False),
                'mtf_confluence': ict_components.get('mtf_confluence', 0)
            }
            
            # Adjust each TP level
            min_rr_tp1 = config.get('min_rr_tp1', 2.5)
            min_rr_tp2 = config.get('min_rr_tp2', 3.5)
            min_rr_tp3 = config.get('min_rr_tp3', 5.0)
            
            adjusted_tp1 = self._adjust_tp_before_obstacle(
                math_tp=math_tp1,
                obstacles=obstacles,
                entry_price=entry_price,
                direction=direction,
                risk=risk,
                min_rr=min_rr_tp1
            )
            
            adjusted_tp2 = self._adjust_tp_before_obstacle(
                math_tp=math_tp2,
                obstacles=obstacles,
                entry_price=entry_price,
                direction=direction,
                risk=risk,
                min_rr=min_rr_tp2
            )
            
            adjusted_tp3 = self._adjust_tp_before_obstacle(
                math_tp=math_tp3,
                obstacles=obstacles,
                entry_price=entry_price,
                direction=direction,
                risk=risk,
                min_rr=min_rr_tp3
            )
            
            logger.info(f"‚úÖ Structure-aware TPs: TP1=${adjusted_tp1:.2f}, TP2=${adjusted_tp2:.2f}, TP3=${adjusted_tp3:.2f}")
            
            return [adjusted_tp1, adjusted_tp2, adjusted_tp3]
            
        except Exception as e:
            logger.error(f"Error calculating smart TPs: {e}")
            # Fallback to mathematical TPs with timeframe-based multipliers
            risk = abs(entry_price - sl_price)
            tp1_mult, tp2_mult, tp3_mult = get_tp_multipliers_by_timeframe(timeframe)
            if direction == 'LONG':
                return [
                    entry_price + (risk * tp1_mult),
                    entry_price + (risk * tp2_mult),
                    entry_price + (risk * tp3_mult)
                ]
            else:
                return [
                    entry_price - (risk * tp1_mult),
                    entry_price - (risk * tp2_mult),
                    entry_price - (risk * tp3_mult)
                ]
    
    def _adjust_tp_before_obstacle(
        self,
        math_tp: float,
        obstacles: List[Dict],
        entry_price: float,
        direction: str,
        risk: float,  # Fixed from SL distance
        min_rr: float = 2.5
    ) -> float:
        """
        Adjust single TP level considering obstacles (PR #8 Helper)
        
        Logic:
        1. Find obstacles between Entry and math_tp
        2. Filter by strength (>= 60 = significant)
        3. If no significant obstacles: Return math_tp unchanged
        4. If obstacle found:
           a. Calculate safe TP (0.3% before obstacle)
           b. Check if safe TP meets min RR
           c. If YES: Use safe TP
           d. If NO: Keep math_tp + log warning for user
        
        Args:
            math_tp: Mathematical TP (Risk √ó multiplier)
            obstacles: List of obstacles
            entry_price: Entry price
            direction: 'LONG' or 'SHORT'
            risk: Risk amount (|entry - sl|)
            min_rr: Minimum RR ratio required
            
        Returns:
            Adjusted TP (or original if RR fails)
        """
        try:
            from config.trading_config import get_trading_config
            config = get_trading_config()
            
            min_obstacle_strength = config.get('min_obstacle_strength', 60)
            obstacle_buffer = config.get('obstacle_buffer_pct', 0.003)
            
            # Find obstacles in path
            min_price = min(entry_price, math_tp)
            max_price = max(entry_price, math_tp)
            
            obstacles_in_path = []
            for obs in obstacles:
                obs_price = obs.get('price', 0)
                obs_strength = obs.get('strength', 0)
                
                # Check if in path and significant
                if min_price < obs_price < max_price and obs_strength >= min_obstacle_strength:
                    # Evaluate obstacle
                    context = {
                        'direction': direction,
                        'htf_bias': 'NEUTRAL',  # Simplified for helper
                        'displacement_detected': False,
                        'mtf_confluence': 0
                    }
                    evaluation = self._evaluate_obstacle_strength(obs, context)
                    
                    if evaluation['will_likely_reject']:
                        obstacles_in_path.append({
                            'obstacle': obs,
                            'evaluation': evaluation,
                            'price': obs_price
                        })
            
            # No significant obstacles - use mathematical TP
            if not obstacles_in_path:
                return math_tp
            
            # Find nearest strong obstacle
            if direction == 'LONG':
                # For LONG, find lowest obstacle price
                obstacles_in_path.sort(key=lambda x: x['price'])
                nearest_obstacle = obstacles_in_path[0]
            else:
                # For SHORT, find highest obstacle price
                obstacles_in_path.sort(key=lambda x: x['price'], reverse=True)
                nearest_obstacle = obstacles_in_path[0]
            
            # Calculate safe TP (before obstacle with buffer)
            obstacle_price = nearest_obstacle['price']
            if direction == 'LONG':
                safe_tp = obstacle_price * (1 - obstacle_buffer)  # 0.3% before
            else:
                safe_tp = obstacle_price * (1 + obstacle_buffer)  # 0.3% before
            
            # Validate RR
            reward = abs(safe_tp - entry_price)
            actual_rr = reward / risk if risk > 0 else 0
            
            if actual_rr >= min_rr:
                # Safe TP meets minimum RR - use it
                logger.info(f"   ‚úÖ TP adjusted to ${safe_tp:.2f} (before obstacle @ ${obstacle_price:.2f}, RR: {actual_rr:.2f})")
                return safe_tp
            else:
                # Safe TP doesn't meet minimum RR - keep mathematical TP and warn
                logger.warning(f"   ‚ö†Ô∏è Obstacle @ ${obstacle_price:.2f} but safe TP has RR {actual_rr:.2f} < {min_rr:.2f}")
                logger.warning(f"   ‚Üí Keeping mathematical TP ${math_tp:.2f} (RR: {abs(math_tp - entry_price) / risk:.2f})")
                return math_tp
            
        except Exception as e:
            logger.error(f"Error adjusting TP: {e}")
            return math_tp  # Return original on error
    
    def _check_news_sentiment_before_signal(
        self,
        symbol: str,
        signal_type: str,  # 'BUY' or 'SELL'
        timeframe: str
    ) -> Dict:
        """
        Check recent news sentiment BEFORE generating signal (PR #8 Layer 1)
        
        Logic:
        - Get news from last 24h (configurable)
        - Calculate weighted sentiment (-100 to +100)
        - CRITICAL news: √ó 3 weight
        - IMPORTANT news: √ó 2 weight
        - NORMAL news: √ó 1 weight
        
        Decision matrix:
        - BUY signal + sentiment < -30: BLOCK signal
        - BUY signal + sentiment -10 to -30: WARN
        - SELL signal + sentiment > +30: BLOCK signal
        - SELL signal + sentiment +10 to +30: WARN
        
        Args:
            symbol: Trading pair (e.g., 'BTCUSDT')
            signal_type: 'BUY' or 'SELL'
            timeframe: Timeframe being analyzed
            
        Returns:
            {
                'allow_signal': True/False,
                'sentiment_score': -100 to +100,
                'critical_news': List[news],
                'reasoning': 'Explanation in Bulgarian'
            }
        """
        try:
            # Check if news filter is enabled
            from config.trading_config import get_trading_config
            config = get_trading_config()
            
            if not config.get('use_news_filter', True):
                logger.info("üì∞ News filter disabled - allowing signal")
                return {
                    'allow_signal': True,
                    'sentiment_score': 0,
                    'critical_news': [],
                    'reasoning': 'News filter disabled'
                }
            
            # Try to get fundamental helper
            try:
                from utils.fundamental_helper import FundamentalHelper
                fundamental_helper = FundamentalHelper()
                
                # Check if fundamental analysis is enabled
                if not fundamental_helper.is_enabled():
                    logger.info("üì∞ Fundamental analysis disabled - allowing signal")
                    return {
                        'allow_signal': True,
                        'sentiment_score': 0,
                        'critical_news': [],
                        'reasoning': 'Fundamental analysis disabled'
                    }
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Could not initialize FundamentalHelper: {e}")
                # Allow signal if news system unavailable
                return {
                    'allow_signal': True,
                    'sentiment_score': 0,
                    'critical_news': [],
                    'reasoning': 'News system unavailable'
                }
            
            # Get news from cache
            from utils.news_cache import NewsCache
            news_cache = NewsCache(cache_dir='cache', ttl_minutes=60)
            news_articles = news_cache.get_cached_news(symbol)
            
            if not news_articles:
                logger.info(f"üì∞ No news available for {symbol} - allowing signal")
                return {
                    'allow_signal': True,
                    'sentiment_score': 0,
                    'critical_news': [],
                    'reasoning': 'No recent news'
                }
            
            # Filter news from last N hours
            from datetime import datetime, timedelta
            lookback_hours = config.get('news_lookback_hours', 24)
            cutoff = datetime.now() - timedelta(hours=lookback_hours)
            
            recent_news = []
            for article in news_articles:
                try:
                    time_str = article.get('time', '')
                    if time_str:
                        article_time = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                        if article_time >= cutoff:
                            recent_news.append(article)
                    else:
                        # Include if no timestamp (better safe than sorry)
                        recent_news.append(article)
                except:
                    recent_news.append(article)
            
            if not recent_news:
                logger.info(f"üì∞ No recent news (last {lookback_hours}h) - allowing signal")
                return {
                    'allow_signal': True,
                    'sentiment_score': 0,
                    'critical_news': [],
                    'reasoning': f'No news in last {lookback_hours}h'
                }
            
            # Analyze sentiment with weighted importance
            from fundamental.sentiment_analyzer import SentimentAnalyzer
            sentiment_analyzer = SentimentAnalyzer()
            
            # Calculate weighted sentiment (-100 to +100)
            news_weight_critical = config.get('news_weight_critical', 3.0)
            news_weight_important = config.get('news_weight_important', 2.0)
            news_weight_normal = config.get('news_weight_normal', 1.0)
            
            # Sentiment normalization constants
            SENTIMENT_NEUTRAL_BASELINE = 50.0  # Base sentiment value (neutral)
            SENTIMENT_SCALE_FACTOR = 2.0       # Multiplier to convert 0-100 to -100 to +100
            
            total_sentiment = 0.0
            total_weight = 0.0
            critical_news = []
            
            for article in recent_news:
                # Analyze individual article using public analyze_news method
                single_result = sentiment_analyzer.analyze_news([article])
                single_sentiment = single_result.get('score', SENTIMENT_NEUTRAL_BASELINE)
                
                # Determine importance weight
                importance = article.get('importance', 'NORMAL').upper()
                if importance == 'CRITICAL':
                    weight = news_weight_critical
                    critical_news.append({
                        'title': title,
                        'importance': 'CRITICAL',
                        'sentiment': single_sentiment,
                        'time_ago': article.get('time_ago', 'N/A')
                    })
                elif importance == 'IMPORTANT':
                    weight = news_weight_important
                    critical_news.append({
                        'title': title,
                        'importance': 'IMPORTANT',
                        'sentiment': single_sentiment,
                        'time_ago': article.get('time_ago', 'N/A')
                    })
                else:
                    weight = news_weight_normal
                
                # Convert 0-100 to -100 to +100
                normalized_sentiment = (single_sentiment - SENTIMENT_NEUTRAL_BASELINE) * SENTIMENT_SCALE_FACTOR
                
                total_sentiment += normalized_sentiment * weight
                total_weight += weight
            
            # Calculate weighted average sentiment
            sentiment_score = total_sentiment / total_weight if total_weight > 0 else 0
            
            logger.info(f"üì∞ News sentiment for {symbol}: {sentiment_score:.1f} (from {len(recent_news)} articles)")
            
            # Get thresholds from config
            block_negative = config.get('news_block_threshold_negative', -30)
            block_positive = config.get('news_block_threshold_positive', 30)
            warn_threshold = config.get('news_warn_threshold', 10)
            
            # Decision logic
            allow_signal = True
            reasoning = ""
            
            if signal_type in ['BUY', 'STRONG_BUY']:
                if sentiment_score < block_negative:
                    allow_signal = False
                    reasoning = f"‚õî –°–ò–ì–ù–ê–õ –ë–õ–û–ö–ò–†–ê–ù: –°–∏–ª–Ω–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏ –Ω–æ–≤–∏–Ω–∏ (Sentiment: {sentiment_score:.0f}). LONG –ø–æ–∑–∏—Ü–∏—è –µ —Ä–∏—Å–∫–æ–≤–∞."
                    logger.warning(f"‚ùå Blocking BUY signal - negative sentiment: {sentiment_score:.1f}")
                elif sentiment_score < -warn_threshold:
                    reasoning = f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –õ–µ–∫–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–∏ –Ω–æ–≤–∏–Ω–∏ (Sentiment: {sentiment_score:.0f}). –ë—ä–¥–∏ –ø—Ä–µ–¥–ø–∞–∑–ª–∏–≤ —Å LONG."
                    logger.warning(f"‚ö†Ô∏è Warning for BUY signal - mild negative sentiment: {sentiment_score:.1f}")
                else:
                    reasoning = f"‚úÖ –ù–æ–≤–∏–Ω–∏—Ç–µ –ø–æ–¥–¥—ä—Ä–∂–∞—Ç LONG –ø–æ–∑–∏—Ü–∏—è (Sentiment: {sentiment_score:.0f})"
                    logger.info(f"‚úÖ News supports BUY signal: {sentiment_score:.1f}")
            
            elif signal_type in ['SELL', 'STRONG_SELL']:
                if sentiment_score > block_positive:
                    allow_signal = False
                    reasoning = f"‚õî –°–ò–ì–ù–ê–õ –ë–õ–û–ö–ò–†–ê–ù: –°–∏–ª–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–∏ –Ω–æ–≤–∏–Ω–∏ (Sentiment: {sentiment_score:.0f}). SHORT –ø–æ–∑–∏—Ü–∏—è –µ —Ä–∏—Å–∫–æ–≤–∞."
                    logger.warning(f"‚ùå Blocking SELL signal - positive sentiment: {sentiment_score:.1f}")
                elif sentiment_score > warn_threshold:
                    reasoning = f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –õ–µ–∫–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–∏ –Ω–æ–≤–∏–Ω–∏ (Sentiment: {sentiment_score:.0f}). –ë—ä–¥–∏ –ø—Ä–µ–¥–ø–∞–∑–ª–∏–≤ —Å SHORT."
                    logger.warning(f"‚ö†Ô∏è Warning for SELL signal - mild positive sentiment: {sentiment_score:.1f}")
                else:
                    reasoning = f"‚úÖ –ù–æ–≤–∏–Ω–∏—Ç–µ –ø–æ–¥–¥—ä—Ä–∂–∞—Ç SHORT –ø–æ–∑–∏—Ü–∏—è (Sentiment: {sentiment_score:.0f})"
                    logger.info(f"‚úÖ News supports SELL signal: {sentiment_score:.1f}")
            
            return {
                'allow_signal': allow_signal,
                'sentiment_score': sentiment_score,
                'critical_news': critical_news[:3],  # Top 3 critical news
                'reasoning': reasoning
            }
            
        except Exception as e:
            logger.error(f"‚ùå News sentiment check error: {e}")
            # On error, allow signal (don't block trading on news system failure)
            return {
                'allow_signal': True,
                'sentiment_score': 0,
                'critical_news': [],
                'reasoning': f'News check error: {str(e)}'
            }
    
    # ============================================================================
    # ENTRY GATING & CONFIDENCE THRESHOLD HELPER METHODS (ESB v1.0 ¬ß2.1-2.2)
    # ============================================================================
    
    def _get_system_state(self) -> str:
        """
        Get current system state (OPERATIONAL, DEGRADED, MAINTENANCE, EMERGENCY)
        
        Returns:
            str: System state
        """
        # TODO: Implement system state check (can be enhanced in follow-up PR)
        # For now, always return OPERATIONAL
        return 'OPERATIONAL'
    
    def _check_breaker_block_active(self, ict_components: Dict, signal_type) -> bool:
        """
        Check if an active breaker block exists in signal direction
        
        Args:
            ict_components: Dictionary of ICT components
            signal_type: Signal type (BUY, SELL, STRONG_BUY, STRONG_SELL)
            
        Returns:
            bool: True if breaker block is active in signal direction
        """
        try:
            breaker_blocks = ict_components.get('breaker_blocks', [])
            
            # Get signal direction
            signal_direction = signal_type.value if hasattr(signal_type, 'value') else str(signal_type)
            
            for bb in breaker_blocks:
                # Check if breaker block aligns with signal direction
                bb_type = bb.get('type', '') if isinstance(bb, dict) else getattr(bb, 'type', '')
                bb_type_str = bb_type.value if hasattr(bb_type, 'value') else str(bb_type)
                
                if 'BUY' in signal_direction and 'BULLISH' in bb_type_str:
                    return True
                if 'SELL' in signal_direction and 'BEARISH' in bb_type_str:
                    return True
            
            return False
        except Exception as e:
            logger.warning(f"Error checking breaker block: {e}")
            return False
    
    def _check_active_signal(self, symbol: str, timeframe: str) -> bool:
        """
        Check if an active signal already exists for this symbol+timeframe
        
        Args:
            symbol: Trading symbol
            timeframe: Timeframe
            
        Returns:
            bool: True if active signal exists
        """
        # TODO: Implement signal collision check (can be enhanced in follow-up PR)
        # For now, return False (no collision)
        return False
    
    def _check_cooldown(self, symbol: str, timeframe: str) -> bool:
        """
        Check if cooldown is active for this symbol+timeframe
        
        Args:
            symbol: Trading symbol
            timeframe: Timeframe
            
        Returns:
            bool: True if cooldown is active
        """
        # TODO: Implement cooldown check (can be enhanced in follow-up PR)
        # For now, return False (no cooldown)
        return False
    
    def _get_market_state(self, symbol: str) -> str:
        """
        Get market state for symbol (OPEN, CLOSED, HALTED, INVALID)
        
        Args:
            symbol: Trading symbol
            
        Returns:
            str: Market state
        """
        # TODO: Implement market state check (can be enhanced in follow-up PR)
        # For now, assume market is open (crypto markets are 24/7)
        return 'OPEN'
    
    def _check_signature(self, symbol: str, timeframe: str, signal_type, timestamp) -> bool:
        """
        Check if signal signature has been seen before (deduplication)
        
        Args:
            symbol: Trading symbol
            timeframe: Timeframe
            signal_type: Signal type
            timestamp: Signal timestamp
            
        Returns:
            bool: True if signature has been seen before
        """
        # TODO: Implement signature deduplication (can be enhanced in follow-up PR)
        # For now, return False (not seen)
        return False
    
    # ============================================================================
    # END ENTRY GATING HELPER METHODS
    # ============================================================================
    
    # ============================================================================
    # EXECUTION ELIGIBILITY HELPER METHODS (ESB v1.0 ¬ß2.3)
    # ============================================================================
    
    def _get_execution_state(self) -> str:
        """
        Get current execution system state
        
        Returns:
            str: "READY" / "PAUSED" / "DISABLED"
        
        Default: "READY" (allows execution)
        
        Future implementation: Check system state from config or monitoring system
        """
        # TODO: Implement dynamic execution state check
        # For now, return safe default
        return 'READY'
    
    def _check_execution_layer_available(self) -> bool:
        """
        Check if execution layer is available
        
        Returns:
            bool: True if available, False otherwise
        
        Default: True (allows execution)
        
        Future implementation: Health check on execution layer
        """
        # TODO: Implement execution layer health check
        # For now, return safe default
        return True
    
    def _check_symbol_execution_lock(self, symbol: str) -> bool:
        """
        Check if symbol has execution lock
        
        Args:
            symbol: Trading symbol (e.g., "BTCUSDT")
        
        Returns:
            bool: True if locked, False otherwise
        
        Default: False (allows execution)
        
        Future implementation: Check symbol-specific locks from config/database
        """
        # TODO: Implement symbol lock check
        # For now, return safe default (not locked)
        return False
    
    def _check_position_capacity(self, symbol: str, direction: str) -> bool:
        """
        Check if position capacity is available for symbol/direction
        
        Args:
            symbol: Trading symbol
            direction: Signal direction (e.g., "BUY", "SELL")
        
        Returns:
            bool: True if capacity available, False otherwise
        
        Default: True (allows execution)
        
        Future implementation: Check max positions limit, per-symbol limits
        """
        # TODO: Implement position capacity check
        # For now, return safe default
        return True
    
    def _check_emergency_halt(self) -> bool:
        """
        Check if emergency execution halt is active
        
        Returns:
            bool: True if halt active, False otherwise
        
        Default: False (allows execution)
        
        Future implementation: Check emergency halt flag from monitoring system
        """
        # TODO: Implement emergency halt check
        # For now, return safe default (not active)
        return False
    
    # ============================================================================
    # END EXECUTION ELIGIBILITY HELPER METHODS
    # ============================================================================
    
    # ============================================================================
    # RISK ADMISSION HELPER METHODS (ESB v1.0 ¬ß2.4)
    # ============================================================================
    
    def _get_signal_risk(self) -> float:
        """
        Calculate risk per signal as % of account
        
        Returns:
            float: Risk per signal (%)
        
        Default: 1.0% (safe, non-blocking)
        
        Future implementation: Calculate based on entry price, SL, and position size
        Formula: risk = ((entry - sl) / entry) * 100
        """
        # TODO: Implement actual signal risk calculation
        # For now, return safe default
        return 1.0
    
    def _get_total_open_risk(self) -> float:
        """
        Calculate total open risk across all positions
        
        Returns:
            float: Total open risk (%)
        
        Default: 0.0% (safe, non-blocking)
        
        Future implementation: Sum risk from all open positions
        """
        # TODO: Implement total open risk aggregation
        # For now, return safe default
        return 0.0
    
    def _get_symbol_exposure(self, symbol: str) -> float:
        """
        Calculate exposure to specific symbol
        
        Args:
            symbol: Trading symbol (e.g., "BTCUSDT")
        
        Returns:
            float: Symbol exposure (%)
        
        Default: 0.0% (safe, non-blocking)
        
        Future implementation: Calculate from open positions for this symbol
        """
        # TODO: Implement symbol exposure calculation
        # For now, return safe default
        return 0.0
    
    def _get_direction_exposure(self, direction: str) -> float:
        """
        Calculate exposure to specific direction (LONG/SHORT)
        
        Args:
            direction: Signal direction (e.g., "BUY", "SELL")
        
        Returns:
            float: Direction exposure (%)
        
        Default: 0.0% (safe, non-blocking)
        
        Future implementation: Aggregate exposure from all positions in this direction
        """
        # TODO: Implement direction exposure calculation
        # For now, return safe default
        return 0.0
    
    def _get_daily_loss(self) -> float:
        """
        Calculate daily loss as % of account
        
        Returns:
            float: Daily loss (%)
        
        Default: 0.0% (safe, non-blocking)
        
        Future implementation: Calculate from closed trades today
        """
        # TODO: Implement daily loss calculation
        # For now, return safe default
        return 0.0
    
    # ============================================================================
    # END RISK ADMISSION HELPER METHODS
    # ============================================================================
    
    def record_signal_outcome(
        self,
        signal_id: str,
        outcome: str,  # 'WIN', 'LOSS', 'BE' (break-even)
        actual_rr: float,
        signal_data: Optional[Dict] = None
    ) -> None:
        """
        Record signal outcome for ML training
        
        Args:
            signal_id: Unique signal identifier
            outcome: Trade outcome
            actual_rr: Actual risk/reward achieved
            signal_data: Original signal data with ML features
        """
        try:
            if not self.use_ml or not signal_data:
                return
            
            # Record in ML Engine
            if self.ml_engine:
                ml_features = signal_data.get('ml_features', {})
                success = outcome == 'WIN'
                
                # Extract required fields
                symbol = signal_data.get('symbol', 'UNKNOWN')
                timeframe = signal_data.get('timeframe', '1h')
                signal_type = signal_data.get('signal_type', 'HOLD')
                confidence = signal_data.get('confidence', 50.0)
                
                self.ml_engine.record_outcome(
                    symbol=symbol,
                    timeframe=timeframe,
                    signal=signal_type,
                    confidence=confidence,
                    features=ml_features,
                    success=success
                )
                
                logger.info(f"‚úÖ ML outcome recorded: {signal_id} - {outcome} (RR: {actual_rr:.2f})")
            
        except Exception as e:
            logger.error(f"‚ùå ML outcome recording error: {e}")


# Example usage
if __name__ == "__main__":
    print("üéØ ICT Signal Engine - Test Mode")
    
    # Create sample data
    dates = pd.date_range(start='2025-01-01', periods=200, freq='1H')
    np.random.seed(42)
    
    # Simulate realistic price data
    base_price = 50000
    prices = []
    current = base_price
    
    for i in range(200):
        # Add trending moves with some order blocks
        if i == 80:  # Bullish setup
            change = -150  # OB candle
        elif i in [81, 82, 83]:  # Displacement
            change = 600
        elif i == 150:  # Bearish setup
            change = 200  # OB candle
        elif i in [151, 152, 153]:  # Displacement
            change = -550
        else:
            change = np.random.randn() * 100
        
        current += change
        prices.append(current)
    
    # Create dataframe
    df = pd.DataFrame({
        'timestamp': dates,
        'open': prices,
        'high': [p + abs(np.random.randn() * 50) for p in prices],
        'low': [p - abs(np.random.randn() * 50) for p in prices],
        'close': [p + np.random.randn() * 30 for p in prices],
        'volume': [1000000 + np.random.randn() * 200000 for _ in prices]
    })
    
    # Initialize engine
    engine = ICTSignalEngine()
    
    # Generate signal
    signal = engine.generate_signal(df, symbol="BTCUSDT", timeframe="1H")
    
    if signal:
        print(f"\n‚úÖ Generated {signal.signal_type.value} signal!")
        print(f"\nüìä Signal Details:")
        print(f"   Symbol: {signal.symbol}")
        print(f"   Timeframe: {signal.timeframe}")
        print(f"   Strength: {'üî•' * signal.signal_strength.value}")
        print(f"   Confidence: {signal.confidence:.1f}%")
        print(f"\nüí∞ Trade Setup:")
        print(f"   Entry: ${signal.entry_price:.2f}")
        print(f"   Stop Loss: ${signal.sl_price:.2f}")
        print(f"   Take Profits:")
        for i, tp in enumerate(signal.tp_prices, 1):
            print(f"     TP{i}: ${tp:.2f}")
        print(f"   Risk/Reward: {signal.risk_reward_ratio:.2f}")
        print(f"\nüìà ICT Analysis:")
        print(f"   Market Bias: {signal.bias.value}")
        print(f"   Whale Blocks: {len(signal.whale_blocks)}")
        print(f"   Liquidity Zones: {len(signal.liquidity_zones)}")
        print(f"   Order Blocks: {len(signal.order_blocks)}")
        print(f"   FVGs: {len(signal.fair_value_gaps)}")
        print(f"   MTF Confluence: {signal.mtf_confluence}")
        print(f"\nüìù Reasoning:")
        print(signal.reasoning)
        if signal.warnings:
            print(f"\n‚ö†Ô∏è  Warnings:")
            for warning in signal.warnings:
                print(f"   - {warning}")
    else:
        print("\n‚ùå No signal generated (conditions not met)")
    
    print("\n‚úÖ ICT Signal Engine test completed!")
    print(f"Total lines: {sum(1 for line in open(__file__))}+")
