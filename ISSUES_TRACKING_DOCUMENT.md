# üìã ISSUES TRACKING DOCUMENT
## Crypto Signal Bot - System Problems Registry

**–î–æ–∫—É–º–µ–Ω—Ç –≤–µ—Ä—Å–∏—è:** 1.0  
**–î–∞—Ç–∞ –Ω–∞ —Å—ä–∑–¥–∞–≤–∞–Ω–µ:** 24 –î–µ–∫–µ–º–≤—Ä–∏ 2025  
**–¶–µ–ª:** –ü—Ä–æ—Å–ª–µ–¥—è–≤–∞–Ω–µ –Ω–∞ –æ—Ç–∫—Ä–∏—Ç–∏ –ø—Ä–æ–±–ª–µ–º–∏ –∏ —Å—Ç–∞—Ç—É—Å –Ω–∞ —Ä–µ—à–µ–Ω–∏—è—Ç–∞  
**–†–µ–∂–∏–º:** READ-ONLY ANALYSIS - –ë–µ–∑ –ø—Ä–æ–º–µ–Ω–∏ –ø–æ –∫–æ–¥–∞

---

## üìä SUMMARY STATISTICS

| –ú–µ—Ç—Ä–∏–∫–∞ | –°—Ç–æ–π–Ω–æ—Å—Ç |
|---------|----------|
| **–û–±—â –±—Ä–æ–π –ø—Ä–æ–±–ª–µ–º–∏** | 15 |
| **–ö—Ä–∏—Ç–∏—á–Ω–∏ (HIGH)** | 3 |
| **–°—Ä–µ–¥–Ω–∏ (MEDIUM)** | 8 |
| **–ù–∏—Å–∫–∏ (LOW)** | 4 |
| **Open** | 15 |
| **In Progress** | 0 |
| **Resolved** | 0 |

---

## üö® CRITICAL ISSUES (HIGH Priority)

### P1: Auto-Signal Function Missing

**ID:** P1  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** HIGH  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `bot.py`
- Line: ~13556 (scheduler job setup)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
–§—É–Ω–∫—Ü–∏—è—Ç–∞ `send_alert_signal()` –µ scheduled –≤ APScheduler –Ω–æ –Ω–µ —Å—ä—â–µ—Å—Ç–≤—É–≤–∞ –≤ –∫–æ–¥–∞.

```python
# Line 13556-13562
app.job_queue.run_repeating(
    send_alert_signal,  # ‚Üê FUNCTION NOT FOUND!
    interval=settings['alert_interval'],
    first=10,
    data={'chat_id': OWNER_CHAT_ID},
    name=f"alerts_{OWNER_CHAT_ID}"
)
```

**–¢—ä—Ä—Å–µ–Ω–µ –≤ –∫–æ–¥–∞:**
```bash
grep -rn "def send_alert_signal" bot.py
# Result: NO MATCHES
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- –§—É–Ω–∫—Ü–∏—è—Ç–∞ –Ω–µ –µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–∞–Ω–∞
- Scheduler job reference –ª–∏–ø—Å–≤–∞—â–∞—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è
- Auto-alerts —Å–∞ "enabled" –≤—ä–≤ feature flags –Ω–æ –Ω–µ —Ä–∞–±–æ—Ç—è—Ç

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª–Ω–æ—Å—Ç:**
   - Auto-alerts –ù–ï —Å–µ –∏–∑–ø—Ä–∞—â–∞—Ç –≤—ä–ø—Ä–µ–∫–∏ —á–µ —Å–∞ enabled
   - Users –æ—á–∞–∫–≤–∞—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏ —Å–∏–≥–Ω–∞–ª–∏ –Ω–æ –≥–∏ –Ω—è–º–∞
   - Scheduler job —â–µ —Ñ–µ–π–ª–≤–∞ –ø—Ä–∏ –∏–∑–ø—ä–ª–Ω–µ–Ω–∏–µ

2. **User Experience:**
   - –ó–∞–±–ª—É–¥–∞ —á–µ auto-alerts —Ä–∞–±–æ—Ç—è—Ç
   - –õ–∏–ø—Å–∞ –Ω–∞ –æ—á–∞–∫–≤–∞–Ω–∏ —Å–∏–≥–Ω–∞–ª–∏

3. **System Stability:**
   - Scheduler –º–æ–∂–µ –¥–∞ –ª–æ–≥–≤–∞ errors
   - Job –º–æ–∂–µ –¥–∞ —Å–µ retry –±–µ–∑–∫—Ä–∞–π–Ω–æ

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

```python
async def send_alert_signal(context):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä–∞ –∏ –∏–∑–ø—Ä–∞—â–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏ —Å–∏–≥–Ω–∞–ª–∏ –∫—ä–º enabled users.
    –ò–∑–ø—ä–ª–Ω—è–≤–∞ —Å–µ period–∏—á–Ω–æ –æ—Ç scheduler.
    """
    try:
        chat_id = context.job.data['chat_id']
        
        # 1. Get user settings
        settings = get_user_settings(context.application.bot_data, chat_id)
        
        if not settings.get('alerts_enabled', False):
            return
        
        # 2. Analyze all symbols
        symbols = ['BTCUSDT', 'ETHUSDT', 'SOLUSDT', 'XRPUSDT', 'BNBUSDT', 'ADAUSDT']
        timeframe = settings.get('timeframe', '1h')
        
        signals = []
        
        for symbol in symbols:
            # 3. Run same ICT analysis as manual /signal
            klines = await fetch_klines(symbol, timeframe, 200)
            df = prepare_dataframe(klines)
            mtf_data = fetch_mtf_data(symbol, timeframe, df)
            
            # 4. Generate ICT signal
            ict_signal = ict_engine_global.generate_signal(
                df=df,
                symbol=symbol,
                timeframe=timeframe,
                mtf_data=mtf_data
            )
            
            # 5. Filter by confidence and entry zone
            if ict_signal and ict_signal.confidence >= 70:
                entry_zone, entry_status = get_entry_zone(ict_signal)
                
                # Only include VALID signals
                if entry_status in ['VALID_WAIT', 'VALID_NEAR']:
                    signals.append(ict_signal)
        
        # 6. Get top N signals
        top_n = settings.get('alert_top_n', 3)
        signals = sorted(signals, key=lambda s: s.confidence, reverse=True)[:top_n]
        
        # 7. Send signals
        for signal in signals:
            # Check cooldown
            if not is_signal_already_sent(signal.symbol, signal.signal_type.value, 
                                          timeframe, signal.confidence, signal.entry_price, 60):
                # Format & send
                msg = format_ict_signal_13_point(signal)
                await context.bot.send_message(
                    chat_id=chat_id,
                    text=msg,
                    parse_mode='HTML'
                )
                
                # Track signal
                mark_signal_sent(signal.symbol, signal.signal_type.value, 
                                timeframe, signal.confidence, signal.entry_price)
                
                # Add to monitor
                add_signal_to_monitor(signal, signal.symbol, timeframe, chat_id)
        
    except Exception as e:
        logger.error(f"Auto-signal error: {e}")
```

**Steps to Implement:**
1. Create `send_alert_signal()` function in bot.py
2. Use same ICT analysis as manual `/signal`
3. Filter by confidence ‚â• 70%
4. Apply entry zone validation (TOO_LATE, NO_ZONE check)
5. Implement cooldown to avoid duplicates
6. Send top N signals to enabled users
7. Track in active_trades for monitoring

**Testing:**
1. Enable auto-alerts: `/alerts on`
2. Wait for scheduled execution (15 min interval)
3. Verify signals are sent
4. Check cooldown works (no duplicates)
5. Verify signals added to real-time monitor

**–ë–µ–ª–µ–∂–∫–∏:**
- –§—É–Ω–∫—Ü–∏—è—Ç–∞ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–ª–µ–¥–≤–∞ –°–™–©–ê–¢–ê –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–Ω–æ—Å—Ç –∫–∞—Ç–æ manual signals
- –í—Å–∏—á–∫–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ —Ñ–∏–ª—Ç—Ä–∏ —Ç—Ä—è–±–≤–∞ –¥–∞ —Å–µ –ø—Ä–∏–ª–∞–≥–∞—Ç
- Cooldown –µ –∫—Ä–∏—Ç–∏—á–µ–Ω –∑–∞ –∏–∑–±—è–≥–≤–∞–Ω–µ –Ω–∞ spam

---

### P6: Daily Loss Limit Not Enforced

**ID:** P6  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** HIGH  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `risk_config.json`
- File: `bot.py` (signal generation logic)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
Risk config –∏–º–∞ `max_daily_loss_pct: 6.0` –∏ `stop_trading_on_daily_limit: true` –Ω–æ
–ø—Ä–æ–≤–µ—Ä–∫–∞—Ç–∞ –õ–ò–ü–°–í–ê –≤ signal generation –ø—Ä–æ—Ü–µ—Å–∞.

**–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:**
```json
{
  "max_daily_loss_pct": 6.0,
  "stop_trading_on_daily_limit": true
}
```

**–¢—ä—Ä—Å–µ–Ω–µ –≤ –∫–æ–¥–∞:**
```bash
grep -rn "max_daily_loss" bot.py
grep -rn "stop_trading_on_daily_limit" bot.py
# Result: Config –µ –∑–∞—Ä–µ–¥–µ–Ω –Ω–æ –ù–ï —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞!
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- Risk manager –µ available
- Config –µ –∑–∞—Ä–µ–¥–µ–Ω
- –ù–æ –Ω—è–º–∞ check –ø—Ä–∏ signal_cmd() –∏–ª–∏ ict_cmd()

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Risk Management:**
   - Daily loss limit –º–æ–∂–µ –¥–∞ –±—ä–¥–µ –Ω–∞–¥—Ö–≤—ä—Ä–ª–µ–Ω
   - –ù—è–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ —Å–ø–∏—Ä–∞–Ω–µ –Ω–∞ trading
   - Risk config –µ –Ω–µ–µ—Ñ–µ–∫—Ç–∏–≤–µ–Ω

2. **Financial Impact:**
   - –í—ä–∑–º–æ–∂–Ω–æ—Å—Ç –∑–∞ excessive losses –≤ –ª–æ—à –¥–µ–Ω
   - –õ–∏–ø—Å–∞ –Ω–∞ –∑–∞—â–∏—Ç–∞

3. **Compliance:**
   - –†–∏—Å–∫ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏—Ç–µ –Ω–µ —Å–µ —Å–ø–∞–∑–≤–∞—Ç

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

```python
def check_daily_loss_limit(chat_id: int) -> tuple[bool, str]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–≤–∞ –¥–∞–ª–∏ daily loss limit –µ –¥–æ—Å—Ç–∏–≥–Ω–∞—Ç.
    
    Returns:
        (can_trade: bool, message: str)
    """
    try:
        # Load risk config
        with open('risk_config.json', 'r') as f:
            risk_config = json.load(f)
        
        max_daily_loss_pct = risk_config['max_daily_loss_pct']
        stop_trading = risk_config['stop_trading_on_daily_limit']
        
        if not stop_trading:
            return True, ""  # Feature disabled
        
        # Load today's trades from journal
        today = datetime.now(timezone.utc).date()
        
        # Get all trades for today
        journal_file = f"{BASE_PATH}/trading_journal.json"
        if not os.path.exists(journal_file):
            return True, ""  # No trades yet
        
        with open(journal_file, 'r') as f:
            journal = json.load(f)
        
        today_trades = [
            t for t in journal 
            if datetime.fromisoformat(t['timestamp']).date() == today
            and t.get('outcome') in ['WIN', 'LOSS']
        ]
        
        if not today_trades:
            return True, ""  # No completed trades
        
        # Calculate daily PnL
        total_pnl_pct = sum(t.get('pnl_pct', 0) for t in today_trades)
        
        # Check limit
        if total_pnl_pct <= -max_daily_loss_pct:
            msg = (
                f"üö´ <b>DAILY LOSS LIMIT REACHED!</b>\n\n"
                f"üìâ Today's Loss: <b>{abs(total_pnl_pct):.2f}%</b>\n"
                f"‚ö†Ô∏è Limit: <b>{max_daily_loss_pct}%</b>\n\n"
                f"Trading is automatically stopped for today.\n"
                f"System will resume tomorrow."
            )
            return False, msg
        
        return True, ""
        
    except Exception as e:
        logger.error(f"Daily loss check error: {e}")
        return True, ""  # Allow trading on error (fail-open)
```

**Integration in signal_cmd():**

```python
async def signal_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # ... existing code ...
    
    # ‚úÖ CHECK DAILY LOSS LIMIT BEFORE ANALYSIS
    can_trade, limit_msg = check_daily_loss_limit(update.effective_chat.id)
    
    if not can_trade:
        await update.message.reply_text(limit_msg, parse_mode='HTML')
        return
    
    # Continue with signal generation...
```

**Steps to Implement:**
1. Create `check_daily_loss_limit()` function
2. Add check in `signal_cmd()` BEFORE analysis
3. Add check in `ict_cmd()` BEFORE analysis
4. Add check in `send_alert_signal()` (when implemented)
5. Load daily trades from trading journal
6. Calculate daily PnL %
7. Block signal generation if limit reached
8. Send notification to user

**Testing:**
1. Set `max_daily_loss_pct: 2.0` (low for testing)
2. Generate losing trades until limit
3. Try `/signal` ‚Üí should be blocked
4. Verify notification is sent
5. Check next day ‚Üí should allow trading

**–ë–µ–ª–µ–∂–∫–∏:**
- Check —Ç—Ä—è–±–≤–∞ –¥–∞ –µ –ü–†–ï–î–ò signal analysis (—Å–ø–µ—Å—Ç—è–≤–∞–Ω–µ –Ω–∞ compute)
- –ò–∑–ø–æ–ª–∑–≤–∞–π trading journal –∑–∞ PnL tracking
- Fail-open –Ω–∞ error (allow trading –∞–∫–æ check —Ñ–µ–π–ª–Ω–µ)

---

### P15: Not All Commands Secured

**ID:** P15  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** HIGH  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `bot.py` (all command handlers)
- File: `security/rate_limiter.py`, `security/auth.py`

**–û–ø–∏—Å–∞–Ω–∏–µ:**
Security modules (v2.0.0) —Å–∞ available –Ω–æ –Ω–µ –≤—Å–∏—á–∫–∏ commands –∏–∑–ø–æ–ª–∑–≤–∞—Ç
security decorators (`@rate_limited`, `@require_auth`).

**–ù–∞–ª–∏—á–Ω–∏ decorators:**
```python
from security.rate_limiter import check_rate_limit, rate_limiter
from security.auth import require_auth, require_admin
```

**–ü—Ä–æ–±–ª–µ–º:**
```bash
# Search for @rate_limited usage
grep -n "@rate_limited" bot.py

# Result: –°–∞–º–æ –Ω—è–∫–æ–∏ commands –∏–º–∞—Ç decorator!
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- Security system –µ –¥–æ–±–∞–≤–µ–Ω –≤ v2.0.0
- –ù–µ –≤—Å–∏—á–∫–∏ commands —Å–∞ –æ–±–Ω–æ–≤–µ–Ω–∏
- Inconsistent protection

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Security:**
   - –í—ä–∑–º–æ–∂–Ω–æ—Å—Ç –∑–∞ spam/DoS –Ω–∞ unprotected commands
   - Bypass –Ω–∞ rate limiting
   - Uncontrolled resource usage

2. **Performance:**
   - Possible overload from spam
   - API quota exhaustion (Binance)

3. **User Experience:**
   - Unfair resource distribution

**Audit –Ω–∞ commands:**

| Command | @rate_limited? | @require_auth? | Risk |
|---------|---------------|----------------|------|
| `/start` | ‚ùå NO | ‚ùå NO | LOW |
| `/help` | ‚ùå NO | ‚ùå NO | LOW |
| `/signal` | ‚ö†Ô∏è PARTIAL | ‚ùå NO | HIGH |
| `/ict` | ‚úÖ YES | ‚ùå NO | MEDIUM |
| `/market` | ‚ùå NO | ‚ùå NO | MEDIUM |
| `/news` | ‚ùå NO | ‚ùå NO | MEDIUM |
| `/breaking` | ‚ùå NO | ‚ùå NO | HIGH |
| `/settings` | ‚ùå NO | ‚ùå NO | LOW |
| `/alerts` | ‚ùå NO | ‚ùå NO | LOW |
| `/backtest` | ‚ùå NO | ‚ùå NO | HIGH |
| `/journal` | ‚ùå NO | ‚ùå NO | LOW |
| `/stats` | ‚ùå NO | ‚ùå NO | LOW |
| `/risk` | ‚ùå NO | ‚ùå NO | LOW |
| `/dailyreport` | ‚ùå NO | ‚úÖ YES (admin) | MEDIUM |
| `/restart` | ‚ùå NO | ‚úÖ YES (admin) | MEDIUM |

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

```python
# HIGH-COST COMMANDS (API calls, heavy computation)
@rate_limited(calls=3, period=60)  # 3 calls per minute
@require_auth
async def signal_cmd(update, context):
    pass

@rate_limited(calls=3, period=60)
@require_auth
async def ict_cmd(update, context):
    pass

@rate_limited(calls=5, period=60)
@require_auth
async def backtest_cmd(update, context):
    pass

@rate_limited(calls=10, period=60)
@require_auth
async def breaking_cmd(update, context):
    pass

# MEDIUM-COST COMMANDS
@rate_limited(calls=10, period=60)
@require_auth
async def market_cmd(update, context):
    pass

@rate_limited(calls=10, period=60)
@require_auth
async def news_cmd(update, context):
    pass

# LOW-COST COMMANDS (data retrieval only)
@rate_limited(calls=20, period=60)
async def stats_cmd(update, context):
    pass

@rate_limited(calls=20, period=60)
async def journal_cmd(update, context):
    pass

# NO RATE LIMIT (critical commands)
async def start_cmd(update, context):
    pass

async def help_cmd(update, context):
    pass
```

**Steps to Implement:**
1. Audit ALL command handlers
2. Classify by resource cost (HIGH/MEDIUM/LOW)
3. Apply appropriate rate limits
4. Add @require_auth to user-facing commands
5. Keep admin commands with @require_admin
6. Test rate limiting works
7. Monitor security events

**Testing:**
1. Spam `/signal` command ‚Üí should be rate limited
2. Verify error message to user
3. Check security_monitor logs
4. Test from unauthorized user ‚Üí should be blocked

**–ë–µ–ª–µ–∂–∫–∏:**
- Different limits –∑–∞ different command types
- Start/Help –≤–∏–Ω–∞–≥–∏ –¥–æ—Å—Ç—ä–ø–Ω–∏ (no rate limit)
- Admin commands –≤–∏–Ω–∞–≥–∏ —Å @require_admin

---

## ‚ö†Ô∏è MEDIUM PRIORITY ISSUES

### P2: Monolithic bot.py Structure

**ID:** P2  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** MEDIUM  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `bot.py` (entire file)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
bot.py –µ 13,721 —Ä–µ–¥–∞ –≤ –µ–¥–∏–Ω —Ñ–∞–π–ª.

**–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**
```bash
wc -l bot.py
# 13721 bot.py
```

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
- Lines 1-300: Imports & environment
- Lines 300-500: Configuration & constants
- Lines 500-6000: Helper functions
- Lines 6000-13000: Command handlers
- Lines 13000-13721: Scheduler & main

**–ü—Ä–∏—á–∏–Ω–∞:**
- Incremental development
- All functionality added to single file
- No modularization strategy

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Maintainability:**
   - –¢—Ä—É–¥–Ω–æ –Ω–∞–≤–∏–≥–∏—Ä–∞–Ω–µ
   - –°–ª–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ä–∞–Ω–µ –Ω–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
   - –í–∏—Å–æ–∫ —Ä–∏—Å–∫ –æ—Ç –≥—Ä–µ—à–∫–∏

2. **Testing:**
   - Difficult to unit test
   - High coupling
   - Can't mock dependencies easily

3. **Performance:**
   - Slow import time (5-10 seconds)
   - Large memory footprint

4. **Collaboration:**
   - Merge conflicts
   - Difficult code review

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

**–ú–æ–¥—É–ª–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```
bot/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ main.py                    # Entry point
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ settings.py            # User settings
‚îÇ   ‚îú‚îÄ‚îÄ constants.py           # Constants
‚îÇ   ‚îî‚îÄ‚îÄ environment.py         # Env variables
‚îú‚îÄ‚îÄ commands/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ signal.py              # /signal, /ict
‚îÇ   ‚îú‚îÄ‚îÄ market.py              # /market
‚îÇ   ‚îú‚îÄ‚îÄ news.py                # /news, /breaking
‚îÇ   ‚îú‚îÄ‚îÄ settings.py            # /settings, /alerts
‚îÇ   ‚îú‚îÄ‚îÄ analysis.py            # /backtest, /journal
‚îÇ   ‚îî‚îÄ‚îÄ admin.py               # /restart, /dailyreport
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ signal_generator.py    # Signal generation logic
‚îÇ   ‚îú‚îÄ‚îÄ chart_service.py       # Chart generation
‚îÇ   ‚îú‚îÄ‚îÄ market_data.py         # Binance API
‚îÇ   ‚îî‚îÄ‚îÄ news_service.py        # News fetching
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ signal.py              # Signal data class
‚îÇ   ‚îú‚îÄ‚îÄ user.py                # User settings
‚îÇ   ‚îî‚îÄ‚îÄ trade.py               # Trade tracking
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ cache.py               # Cache management
‚îÇ   ‚îú‚îÄ‚îÄ validators.py          # Input validation
‚îÇ   ‚îî‚îÄ‚îÄ formatters.py          # Message formatting
‚îî‚îÄ‚îÄ scheduler/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ jobs.py                # Scheduled jobs
```

**Migration Steps:**
1. Create bot/ package structure
2. Move constants ‚Üí config/constants.py
3. Move command handlers ‚Üí commands/
4. Move business logic ‚Üí services/
5. Move data models ‚Üí models/
6. Move utilities ‚Üí utils/
7. Create main.py as entry point
8. Update imports
9. Test incrementally

**–ë–µ–ª–µ–∂–∫–∏:**
- Incremental refactoring (–Ω–µ –Ω–∞–≤–µ–¥–Ω—ä–∂)
- Maintain backward compatibility
- Extensive testing required

---

### P3: Admin Module Hardcoded Paths

**ID:** P3  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** MEDIUM  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `admin/admin_module.py`
- Line: 14

**–û–ø–∏—Å–∞–Ω–∏–µ:**
Admin paths —Å–∞ hardcoded –∫—ä–º `/workspaces/Crypto-signal-bot/`.

**–ö–æ–¥:**
```python
# Line 14
ADMIN_DIR = "/workspaces/Crypto-signal-bot/admin"
ADMIN_PASSWORD_FILE = f"{ADMIN_DIR}/admin_password.json"
REPORTS_DIR = f"{ADMIN_DIR}/reports"
```

**–ü—Ä–æ–±–ª–µ–º:**
- –†–∞–±–æ—Ç–∏ —Å–∞–º–æ –≤ GitHub Codespaces
- –ù–ï —Ä–∞–±–æ—Ç–∏ –Ω–∞ production server (/root/Crypto-signal-bot)
- –ù–ï —Ä–∞–±–æ—Ç–∏ –Ω–∞ local development

**–ü—Ä–∏—á–∏–Ω–∞:**
- Hardcoded path during development
- No dynamic path detection

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Functionality:**
   - Admin module –ù–ï —Ä–∞–±–æ—Ç–∏ –Ω–∞ production
   - Reports –ù–ï —Å–µ –≥–µ–Ω–µ—Ä–∏—Ä–∞—Ç
   - Password management —Ñ–µ–π–ª–≤–∞

2. **Deployment:**
   - –¢—Ä—è–±–≤–∞ manual edit –Ω–∞ paths
   - Deployment –Ω–µ –µ portable

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

```python
import os
from pathlib import Path

# Detect BASE_PATH dynamically (same as bot.py)
if os.getenv('BOT_BASE_PATH'):
    BASE_PATH = os.getenv('BOT_BASE_PATH')
elif os.path.exists('/root/Crypto-signal-bot'):
    BASE_PATH = '/root/Crypto-signal-bot'
elif os.path.exists('/workspaces/Crypto-signal-bot'):
    BASE_PATH = '/workspaces/Crypto-signal-bot'
else:
    # Fallback to module directory
    BASE_PATH = str(Path(__file__).parent.parent)

ADMIN_DIR = f"{BASE_PATH}/admin"
ADMIN_PASSWORD_FILE = f"{ADMIN_DIR}/admin_password.json"
REPORTS_DIR = f"{ADMIN_DIR}/reports"
DAILY_REPORTS_DIR = f"{REPORTS_DIR}/daily"
WEEKLY_REPORTS_DIR = f"{REPORTS_DIR}/weekly"
MONTHLY_REPORTS_DIR = f"{REPORTS_DIR}/monthly"

# Create directories with validation
for dir_path in [ADMIN_DIR, REPORTS_DIR, DAILY_REPORTS_DIR, 
                  WEEKLY_REPORTS_DIR, MONTHLY_REPORTS_DIR]:
    try:
        os.makedirs(dir_path, exist_ok=True)
        logger.info(f"‚úÖ Directory ready: {dir_path}")
    except Exception as e:
        logger.error(f"‚ùå Failed to create {dir_path}: {e}")
        raise RuntimeError(f"Admin module initialization failed: {e}")
```

**Steps to Implement:**
1. Add BASE_PATH detection (–∫–æ–ø–∏—Ä–∞–π –æ—Ç bot.py)
2. Replace hardcoded paths
3. Add directory creation validation
4. Test on different environments:
   - Codespace
   - Production server
   - Local development
5. Verify reports are generated

**Testing:**
1. Deploy to production server
2. Run `/dailyreport`
3. Check reports directory
4. Verify files are created

**–ë–µ–ª–µ–∂–∫–∏:**
- Use same logic –∫–∞—Ç–æ bot.py BASE_PATH
- Fail fast –∞–∫–æ directories –Ω–µ –º–æ–≥–∞—Ç –¥–∞ —Å–µ —Å—ä–∑–¥–∞–¥–∞—Ç

---

### P5: ML Model Not Auto-Training

**ID:** P5  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** MEDIUM  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `ml_engine.py`
- File: `ml_predictor.py`
- File: `journal_backtest.py` (trading journal)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
ML models exist –∏ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞—Ç –∑–∞ confidence adjustment –Ω–æ –ù–ï —Å–µ —Ç—Ä–µ–Ω–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ
–æ—Ç real trading results.

**–¢–µ–∫—É—â–æ —Å—ä—Å—Ç–æ—è–Ω–∏–µ:**
- ML Engine: Hybrid predictions (ICT + Classical)
- ML Predictor: Win probability
- Trading Journal: Tracks all trades with outcomes
- Backtest Engine: Comprehensive testing

**–õ–∏–ø—Å–≤–∞—â–∞ –≤—Ä—ä–∑–∫–∞:**
```
Trading Journal Results ‚Üí ML Training Pipeline ‚Üí Updated Models
                ‚ùå NOT CONNECTED ‚ùå
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- ML modules —Å–∞ —Å—ä–∑–¥–∞–¥–µ–Ω–∏
- Journal tracking –µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–∞–Ω
- –ù–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏—è—Ç training pipeline –ª–∏–ø—Å–≤–∞

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **ML Accuracy:**
   - Models –Ω–µ —Å–µ –ø–æ–¥–æ–±—Ä—è–≤–∞—Ç —Å –≤—Ä–µ–º–µ—Ç–æ
   - Predictions –±–∞–∑–∏—Ä–∞–Ω–∏ –Ω–∞ —Å—Ç–∞—Ä–∏ –¥–∞–Ω–Ω–∏
   - Confidence adjustment –º–æ–∂–µ –¥–∞ –µ –Ω–µ—Ç–æ—á–µ–Ω

2. **Adaptability:**
   - –°–∏—Å—Ç–µ–º–∞—Ç–∞ –Ω–µ —Å–µ –∞–¥–∞–ø—Ç–∏—Ä–∞ –∫—ä–º –Ω–æ–≤–∏ market conditions
   - ML –æ—Å—Ç–∞–≤–∞ —Å—Ç–∞—Ç–∏—á–µ–Ω

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

```python
async def ml_auto_training_job(context):
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ training –Ω–∞ ML models –æ—Ç journal results.
    –ò–∑–ø—ä–ª–Ω—è–≤–∞ —Å–µ weekly (Sunday 03:00 UTC).
    """
    try:
        logger.info("ü§ñ Starting ML auto-training...")
        
        # 1. Load trading journal
        journal_file = f"{BASE_PATH}/trading_journal.json"
        
        if not os.path.exists(journal_file):
            logger.warning("No journal data for ML training")
            return
        
        with open(journal_file, 'r') as f:
            journal = json.load(f)
        
        # 2. Filter completed trades (WIN/LOSS)
        completed_trades = [
            t for t in journal
            if t.get('outcome') in ['WIN', 'LOSS']
        ]
        
        if len(completed_trades) < 50:
            logger.warning(f"Insufficient trades for ML training: {len(completed_trades)}")
            return
        
        # 3. Prepare training data
        X_features = []
        y_outcomes = []
        
        for trade in completed_trades:
            # Extract features
            features = {
                'ict_confidence': trade.get('confidence', 0) / 100.0,
                'risk_reward': trade.get('risk_reward', 0),
                'mtf_alignment': trade.get('mtf_alignment', 0) / 100.0,
                'order_block_strength': trade.get('ob_strength', 0) / 100.0,
                'liquidity_confluence': trade.get('liquidity_score', 0) / 100.0,
                'timeframe_weight': TIMEFRAME_WEIGHTS.get(trade.get('timeframe'), 0.5),
                # ... more features
            }
            
            X_features.append(list(features.values()))
            
            # Binary outcome: 1 = WIN, 0 = LOSS
            y_outcomes.append(1 if trade['outcome'] == 'WIN' else 0)
        
        X = np.array(X_features)
        y = np.array(y_outcomes)
        
        # 4. Train ML Engine
        if ML_AVAILABLE and ml_engine.model is not None:
            logger.info("Training ML Engine...")
            ml_engine.train(X, y)
            ml_engine.save_model()  # Persist
            logger.info("‚úÖ ML Engine retrained")
        
        # 5. Train ML Predictor
        if ML_PREDICTOR_AVAILABLE and ml_predictor.is_trained:
            logger.info("Training ML Predictor...")
            
            # Prepare trade data for predictor
            for trade in completed_trades:
                ml_predictor.record_trade_outcome(
                    trade_data={
                        'entry_price': trade['entry_price'],
                        'analysis_data': trade.get('analysis_features', {})
                    },
                    won=trade['outcome'] == 'WIN'
                )
            
            ml_predictor.save_model()
            logger.info("‚úÖ ML Predictor retrained")
        
        # 6. Send training summary to owner
        win_rate = sum(y) / len(y) * 100
        
        msg = (
            f"ü§ñ <b>ML AUTO-TRAINING COMPLETE</b>\n\n"
            f"üìä <b>Training Data:</b>\n"
            f"  ‚Ä¢ Trades: {len(completed_trades)}\n"
            f"  ‚Ä¢ Win Rate: {win_rate:.1f}%\n\n"
            f"‚úÖ Models Updated:\n"
            f"  ‚Ä¢ ML Engine: Retrained\n"
            f"  ‚Ä¢ ML Predictor: Retrained\n\n"
            f"üí° Models will improve signal accuracy."
        )
        
        await context.bot.send_message(
            chat_id=OWNER_CHAT_ID,
            text=msg,
            parse_mode='HTML'
        )
        
        logger.info(f"‚úÖ ML auto-training completed: {len(completed_trades)} trades")
        
    except Exception as e:
        logger.error(f"ML auto-training error: {e}")
```

**Integration –≤ scheduler:**

```python
# Line ~13300 (in main())
scheduler.add_job(
    ml_auto_training_job,
    'cron',
    day_of_week='sun',  # Sunday
    hour=3,             # 03:00 UTC
    minute=0
)
logger.info("‚úÖ ML auto-training scheduled (Sundays 03:00 UTC)")
```

**Steps to Implement:**
1. Create `ml_auto_training_job()` function
2. Load completed trades from journal
3. Extract features from trade data
4. Train ML Engine with new data
5. Train ML Predictor with outcomes
6. Save updated models
7. Schedule weekly execution
8. Send summary notification

**Testing:**
1. Generate 50+ trades (WIN/LOSS)
2. Manually trigger training job
3. Verify models are updated
4. Check prediction accuracy improves
5. Test on new signals

**–ë–µ–ª–µ–∂–∫–∏:**
- Minimum 50 trades –∑–∞ meaningful training
- Weekly schedule (–Ω–µ —Ç–≤—ä—Ä–¥–µ —á–µ—Å—Ç–æ)
- Persist models —Å–ª–µ–¥ training

---

### P8: Cooldown System Incomplete

**ID:** P8  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** MEDIUM  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `bot.py`
- Functions: `signal_cmd()` (line 6191), `ict_cmd()` (line 6391)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
Cooldown check –µ –∏–º–ø–ª–µ–º–µ–Ω—Ç–∏—Ä–∞–Ω –≤ `/ict` –Ω–æ –õ–ò–ü–°–í–ê –≤ `/signal`.

**–ö–æ–¥ –∞–Ω–∞–ª–∏–∑:**

**In `/ict` (line 6514-6532):**
```python
# ‚úÖ HAS COOLDOWN CHECK
signal_key = f"{symbol}_{timeframe}_{signal.signal_type.value}"

if is_signal_already_sent(
    symbol=symbol,
    signal_type=signal.signal_type.value,
    timeframe=timeframe,
    confidence=signal.confidence,
    entry_price=signal.entry_price,
    cooldown_minutes=60
):
    await processing_msg.edit_text(
        f"‚è≥ Signal for {symbol} already sent recently...",
        parse_mode='HTML'
    )
    return
```

**In `/signal` (line 6191-6388):**
```python
# ‚ùå NO COOLDOWN CHECK
# Goes straight to signal generation
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- Cooldown –µ –¥–æ–±–∞–≤–µ–Ω –≤ `/ict`
- `/signal` –Ω–µ –µ –æ–±–Ω–æ–≤–µ–Ω
- Inconsistent behavior

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Signal Duplication:**
   - `/signal` –º–æ–∂–µ –¥–∞ –≥–µ–Ω–µ—Ä–∏—Ä–∞ –¥—É–±–ª–∏—Ä–∞–Ω–∏ —Å–∏–≥–Ω–∞–ª–∏
   - –°–∞–º–æ `/ict` –µ –∑–∞—â–∏—Ç–µ–Ω

2. **User Confusion:**
   - –ó–∞—â–æ `/signal` –ø–æ–∑–≤–æ–ª—è–≤–∞ duplicates?
   - Inconsistent UX

3. **Resource Waste:**
   - Unnecessary API calls
   - Duplicate analysis

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

**Unified Cooldown System:**

```python
def check_signal_cooldown(symbol: str, signal_type: str, timeframe: str, 
                         confidence: float, entry_price: float,
                         cooldown_minutes: int = 60) -> tuple[bool, str]:
    """
    Unified cooldown check –∑–∞ –≤—Å–∏—á–∫–∏ signal commands.
    
    Returns:
        (is_duplicate: bool, message: str)
    """
    if is_signal_already_sent(
        symbol=symbol,
        signal_type=signal_type,
        timeframe=timeframe,
        confidence=confidence,
        entry_price=entry_price,
        cooldown_minutes=cooldown_minutes
    ):
        msg = (
            f"‚è≥ <b>Signal Already Sent Recently</b>\n\n"
            f"üìä {symbol} {timeframe} {signal_type}\n"
            f"üïê Cooldown: {cooldown_minutes} minutes\n\n"
            f"Please wait before requesting again."
        )
        return True, msg
    
    return False, ""
```

**Apply to both commands:**

```python
async def signal_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # ... existing code –¥–æ signal generation ...
    
    # ‚úÖ CHECK COOLDOWN
    is_duplicate, cooldown_msg = check_signal_cooldown(
        symbol=symbol,
        signal_type=ict_signal.signal_type.value,
        timeframe=timeframe,
        confidence=ict_signal.confidence,
        entry_price=ict_signal.entry_price,
        cooldown_minutes=60
    )
    
    if is_duplicate:
        await processing_msg.edit_text(cooldown_msg, parse_mode='HTML')
        return
    
    # Continue with formatting & sending...
```

**Steps to Implement:**
1. Create unified `check_signal_cooldown()` function
2. Add check to `/signal` command
3. Keep existing check in `/ict`
4. Use same cooldown period (60 min)
5. Test both commands
6. Verify cooldown works

**Testing:**
1. Generate signal with `/signal BTC 1h`
2. Immediately request `/signal BTC 1h` again ‚Üí should be blocked
3. Request `/ict BTC 1h` ‚Üí should also be blocked (same signal)
4. Wait 60+ min ‚Üí should allow new signal

**–ë–µ–ª–µ–∂–∫–∏:**
- Cooldown —Ç—Ä—è–±–≤–∞ –¥–∞ –µ SHARED between `/signal` and `/ict`
- Same signal –æ—Ç different commands = same cooldown
- Clear messaging –∑–∞ users

---

### P10: Scheduler Jobs Without Error Handling

**ID:** P10  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** MEDIUM  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `bot.py`
- Lines: 13000-13522 (scheduler setup)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
Scheduler jobs –Ω—è–º–∞—Ç global exception handling. Job failure –º–æ–∂–µ –¥–∞ crash scheduler.

**–ü—Ä–æ–±–ª–µ–º–Ω–∏ jobs:**

```python
# Lines 13082-13094 - Daily Report
scheduler.add_job(
    send_daily_report,  # ‚Üê No error handling
    'cron', hour=0, minute=30
)

# Lines 13137-13148 - Weekly Report
scheduler.add_job(
    send_weekly_report,  # ‚Üê No error handling
    'cron', day_of_week='mon', hour=9
)

# Lines 13202-13219 - Diagnostics
scheduler.add_job(
    run_diagnostics,  # ‚Üê No error handling
    'cron', hour=0, minute=0
)

# Lines 13513-13520 - Weekly Backtest
scheduler.add_job(
    weekly_backtest_wrapper,  # ‚Üê No error handling
    'cron', day_of_week='mon', hour=9
)
```

**–ü—Ä–∏—á–∏–Ω–∞:**
- Jobs —Å–∞ async functions
- Exception –≤ job –º–æ–∂–µ –¥–∞ crash scheduler
- No retry logic

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Stability:**
   - Job crash –º–æ–∂–µ –¥–∞ —Å–ø—Ä–µ scheduler
   - Other jobs –º–æ–∂–µ –¥–∞ –Ω–µ —Å–µ –∏–∑–ø—ä–ª–Ω—è—Ç

2. **Monitoring:**
   - Failures —Å–∞ silent
   - No notification –∑–∞ errors

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

**Job Wrapper with Error Handling:**

```python
def safe_job(job_name: str):
    """
    Decorator –∑–∞ scheduler jobs - –¥–æ–±–∞–≤—è error handling –∏ retry logic.
    """
    def decorator(func):
        @wraps(func)
        async def wrapper(context):
            max_retries = 3
            retry_delay = 60  # seconds
            
            for attempt in range(max_retries):
                try:
                    logger.info(f"üîÑ Starting job: {job_name} (attempt {attempt + 1}/{max_retries})")
                    
                    result = await func(context)
                    
                    logger.info(f"‚úÖ Job completed: {job_name}")
                    return result
                    
                except Exception as e:
                    logger.error(f"‚ùå Job failed: {job_name} (attempt {attempt + 1})")
                    logger.error(f"Error: {str(e)}")
                    logger.exception(e)
                    
                    if attempt < max_retries - 1:
                        logger.info(f"‚è≥ Retrying in {retry_delay}s...")
                        await asyncio.sleep(retry_delay)
                    else:
                        # Final failure - notify owner
                        try:
                            await context.bot.send_message(
                                chat_id=OWNER_CHAT_ID,
                                text=(
                                    f"‚ùå <b>SCHEDULER JOB FAILED</b>\n\n"
                                    f"Job: {job_name}\n"
                                    f"Attempts: {max_retries}\n"
                                    f"Error: {str(e)[:200]}\n\n"
                                    f"Check logs for details."
                                ),
                                parse_mode='HTML'
                            )
                        except:
                            pass  # Even notification failed
                        
                        logger.error(f"üí• Job permanently failed: {job_name}")
        
        return wrapper
    return decorator
```

**Apply to all jobs:**

```python
@safe_job("daily_report")
async def send_daily_report(context):
    # Existing code...
    pass

@safe_job("weekly_report")
async def send_weekly_report(context):
    # Existing code...
    pass

@safe_job("diagnostics")
async def run_diagnostics(context):
    # Existing code...
    pass

@safe_job("weekly_backtest")
async def weekly_backtest_wrapper(context):
    # Existing code...
    pass

@safe_job("auto_signal")
async def send_alert_signal(context):
    # Existing code...
    pass
```

**Steps to Implement:**
1. Create `safe_job()` decorator
2. Apply to ALL scheduler jobs
3. Configure retry logic (max 3 attempts)
4. Add failure notification to owner
5. Test job failure scenarios

**Testing:**
1. Force job failure (throw exception)
2. Verify retry attempts
3. Check notification is sent
4. Verify scheduler continues running
5. Test next scheduled execution

**–ë–µ–ª–µ–∂–∫–∏:**
- Max 3 retries —Å 60s delay
- Notify owner –Ω–∞ permanent failure
- Scheduler —Ç—Ä—è–±–≤–∞ –¥–∞ –ø—Ä–æ–¥—ä–ª–∂–∏ running

---

### P13: Global Cache Without Cleanup

**ID:** P13  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** MEDIUM  
**–î–∞—Ç–∞ –Ω–∞ –æ—Ç–∫—Ä–∏–≤–∞–Ω–µ:** 24 Dec 2025

**–õ–æ–∫–∞—Ü–∏—è:**
- File: `bot.py`
- Lines: 350-401 (CACHE implementation)

**–û–ø–∏—Å–∞–Ω–∏–µ:**
Global CACHE dict –º–æ–∂–µ –¥–∞ —Ä–∞—Å—Ç–µ –±–µ–∑–∫—Ä–∞–π–Ω–æ. –ù—è–º–∞ size limit –∏–ª–∏ LRU eviction.

**–¢–µ–∫—É—â –∫–æ–¥:**
```python
# Lines 350-361
CACHE = {
    'backtest': {},      # –ú–æ–∂–µ –¥–∞ —Å—Ç–∞–Ω–µ –≥–æ–ª—è–º
    'market': {},        # –ú–æ–∂–µ –¥–∞ —Å—Ç–∞–Ω–µ –≥–æ–ª—è–º
    'ml_performance': {} # –ú–æ–∂–µ –¥–∞ —Å—Ç–∞–Ω–µ –≥–æ–ª—è–º
}

CACHE_TTL = {
    'backtest': 300,      # 5 minutes
    'market': 180,        # 3 minutes
    'ml_performance': 300 # 5 minutes
}
```

**–ü—Ä–æ–±–ª–µ–º:**
- Items —Å–µ –¥–æ–±–∞–≤—è—Ç –Ω–æ NEVER —Å–µ –∏–∑—Ç—Ä–∏–≤–∞—Ç (–æ—Å–≤–µ–Ω –ø—Ä–∏ TTL check)
- Expired items –æ—Å—Ç–∞–≤–∞—Ç –¥–æ —Å–ª–µ–¥–≤–∞—â–∏—è `get_cached()` call
- –ù—è–º–∞ global size limit

**–ü—Ä–∏—á–∏–Ω–∞:**
- –û–ø—Ä–æ—Å—Ç–µ–Ω–∞ implementation
- TTL-based expiration —Å–∞–º–æ –ø—Ä–∏ access
- No cleanup job

**–í–ª–∏—è–Ω–∏–µ –≤—ä—Ä—Ö—É —Å–∏—Å—Ç–µ–º–∞—Ç–∞:**
1. **Memory:**
   - Unbounded growth
   - –ú–æ–∂–µ –¥–∞ –¥–æ—Å—Ç–∏–≥–Ω–µ GB —Ä–∞–∑–º–µ—Ä–∏ –ø—Ä–∏ heavy usage

2. **Performance:**
   - Large dict lookups
   - Memory pressure

**–ü—Ä–µ–ø–æ—Ä—ä—á–∞–Ω–æ —Ä–µ—à–µ–Ω–∏–µ:**

**LRU Cache with Size Limit:**

```python
from collections import OrderedDict
from threading import Lock

class LRUCache:
    """
    Thread-safe LRU cache —Å TTL –∏ size limit.
    """
    
    def __init__(self, max_size: int = 100, ttl_seconds: int = 300):
        self.max_size = max_size
        self.ttl_seconds = ttl_seconds
        self.cache = OrderedDict()
        self.lock = Lock()
    
    def get(self, key: str):
        """Get value from cache (thread-safe)."""
        with self.lock:
            if key not in self.cache:
                return None
            
            # Check TTL
            item = self.cache[key]
            age = (datetime.now(timezone.utc) - item['timestamp']).total_seconds()
            
            if age > self.ttl_seconds:
                # Expired
                del self.cache[key]
                return None
            
            # Move to end (most recently used)
            self.cache.move_to_end(key)
            
            return item['data']
    
    def set(self, key: str, value):
        """Set value in cache (thread-safe)."""
        with self.lock:
            # Remove if exists (to update position)
            if key in self.cache:
                del self.cache[key]
            
            # Add new item
            self.cache[key] = {
                'data': value,
                'timestamp': datetime.now(timezone.utc)
            }
            
            # Enforce size limit (evict oldest)
            while len(self.cache) > self.max_size:
                oldest_key = next(iter(self.cache))
                del self.cache[oldest_key]
                logger.debug(f"Cache evicted: {oldest_key}")
    
    def clear(self):
        """Clear all cache."""
        with self.lock:
            self.cache.clear()
    
    def cleanup_expired(self):
        """Remove all expired items."""
        with self.lock:
            now = datetime.now(timezone.utc)
            expired_keys = [
                key for key, item in self.cache.items()
                if (now - item['timestamp']).total_seconds() > self.ttl_seconds
            ]
            
            for key in expired_keys:
                del self.cache[key]
            
            if expired_keys:
                logger.info(f"Cache cleanup: {len(expired_keys)} expired items removed")

# Replace global CACHE
CACHE = {
    'backtest': LRUCache(max_size=50, ttl_seconds=300),
    'market': LRUCache(max_size=100, ttl_seconds=180),
    'ml_performance': LRUCache(max_size=50, ttl_seconds=300)
}

# Scheduled cleanup job (every 10 minutes)
async def cache_cleanup_job(context):
    """Periodic cache cleanup."""
    try:
        for cache_type, cache in CACHE.items():
            cache.cleanup_expired()
        logger.debug("‚úÖ Cache cleanup completed")
    except Exception as e:
        logger.error(f"Cache cleanup error: {e}")

# In scheduler setup (line ~13300)
scheduler.add_job(
    cache_cleanup_job,
    'interval',
    minutes=10
)
```

**Steps to Implement:**
1. Create LRUCache class
2. Replace global CACHE dicts
3. Update get_cached() and set_cache() functions
4. Add cleanup job to scheduler
5. Test cache size limits
6. Monitor memory usage

**Testing:**
1. Generate 100+ cache entries
2. Verify oldest are evicted
3. Check expired items are removed
4. Monitor memory usage

**–ë–µ–ª–µ–∂–∫–∏:**
- LRU: Least Recently Used eviction
- Thread-safe implementation
- Periodic cleanup –∑–∞ expired items

---

(Continue with LOW priority issues...)

---

## üîµ LOW PRIORITY ISSUES

### P4: Unused Feature Flags

**ID:** P4  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** LOW  

**–û–ø–∏—Å–∞–Ω–∏–µ:** –ù—è–∫–æ–∏ feature flags –Ω–µ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞—Ç.

**Flags:**
- `use_ict_enhancer: false` ‚Üí ICT Enhancement Layer –Ω–µ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞
- `use_archive: false` ‚Üí –∞—Ä—Ö–∏–≤–∏—Ä–∞–Ω–µ –∏–∑–∫–ª—é—á–µ–Ω–æ

**–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:** –ê–∫—Ç–∏–≤–∏—Ä–∞–π –∏–ª–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–∞–π –∑–∞—â–æ —Å–∞ disabled.

---

### P7: Chart Generation Failure Handling

**ID:** P7  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** LOW  

**–û–ø–∏—Å–∞–Ω–∏–µ:** Chart generation –µ –≤ try/catch –Ω–æ –Ω—è–º–∞ fallback visualization.

**–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:** –î–æ–±–∞–≤–∏ —Ç–µ–∫—Å—Ç–æ–≤–∞ visualization fallback (ASCII art chart).

---

### P9: Entry Zone Validation Duplication

**ID:** P9  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** LOW  

**–û–ø–∏—Å–∞–Ω–∏–µ:** Entry zone validation –∏ –≤ ICT engine –∏ –≤ signal_helpers.

**–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:** –ö–æ–Ω—Å–æ–ª–∏–¥–∏—Ä–∞–π validation –≤ –µ–¥–Ω–æ –º—è—Å—Ç–æ (ICT engine).

---

### P11: Conditional Imports

**ID:** P11  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** LOW  

**–û–ø–∏—Å–∞–Ω–∏–µ:** Conditional imports —Å try/except –Ω–∞–≤—Å—è–∫—ä–¥–µ.

**–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:** –¶–µ–Ω—Ç—Ä–∞–ª–µ–Ω module loader —Å dependency injection.

---

### P12: ICT Engine Hardcoded Config

**ID:** P12  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** LOW  

**–û–ø–∏—Å–∞–Ω–∏–µ:** ICT config –µ hardcoded –≤ DEFAULT_CONFIG dict.

**–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:** Load –æ—Ç external config file (config/ict_config.json).

---

### P14: BASE_PATH Detection

**ID:** P14  
**Status:** Open  
**–ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç:** LOW  

**–û–ø–∏—Å–∞–Ω–∏–µ:** Path detection –º–æ–∂–µ –¥–∞ fallback –∫—ä–º wrong directory.

**–ü—Ä–µ–ø–æ—Ä—ä–∫–∞:** –î–æ–±–∞–≤–∏ explicit path validation & error.

---

## üìä SUMMARY BY PRIORITY

### HIGH Priority (3 issues):
- P1: Auto-Signal Function Missing
- P6: Daily Loss Limit Not Enforced
- P15: Not All Commands Secured

### MEDIUM Priority (8 issues):
- P2: Monolithic bot.py Structure
- P3: Admin Module Hardcoded Paths
- P5: ML Model Not Auto-Training
- P8: Cooldown System Incomplete
- P10: Scheduler Jobs Without Error Handling
- P13: Global Cache Without Cleanup

### LOW Priority (4 issues):
- P4: Unused Feature Flags
- P7: Chart Generation Failure Handling
- P9: Entry Zone Validation Duplication
- P11: Conditional Imports
- P12: ICT Engine Hardcoded Config
- P14: BASE_PATH Detection

---

## üéØ RECOMMENDED ACTION PLAN

### Phase 1: Critical Fixes (Week 1)
1. P1: Implement `send_alert_signal()` function
2. P6: Add daily loss limit check
3. P15: Apply security decorators to all commands

### Phase 2: Stability Improvements (Week 2-3)
4. P10: Add error handling to scheduler jobs
5. P8: Unify cooldown system
6. P3: Fix admin module paths
7. P13: Implement LRU cache

### Phase 3: Quality Improvements (Week 4-6)
8. P5: Add ML auto-training pipeline
9. P9: Consolidate validation logic
10. P7: Add chart fallback

### Phase 4: Long-term (Month 2-3)
11. P2: Refactor bot.py into modules
12. P12: Extract ICT config to file
13. Improve test coverage

---

**–ö—Ä–∞–π –Ω–∞ tracking document.**

_–í—Å–∏—á–∫–∏ –ø—Ä–æ–±–ª–µ–º–∏ —Å–∞ –≤ —Å—Ç–∞—Ç—É—Å "Open" - –∏–∑—á–∞–∫–≤–∞—Ç —Ä–µ—à–µ–Ω–∏—è._  
_–î–æ–∫—É–º–µ–Ω—Ç—ä—Ç —â–µ —Å–µ –∞–∫—Ç—É–∞–ª–∏–∑–∏—Ä–∞ –ø—Ä–∏ –ø—Ä–æ–º–µ–Ω–∏._
